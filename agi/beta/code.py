# agi

```json
{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "#!/usr/bin/env python3\n\"\"\"\nAGI Core Module\n实现真正意义上的通用人工智能核心功能\n使用OpenAI API作为底层模型\n\"\"\"\n\nimport os\nimport json\nimport logging\nfrom typing import Dict, List, Any, Optional, Callable\nfrom datetime import datetime\nfrom dataclasses import dataclass, asdict\nimport openai\nfrom openai import OpenAI\n\n# 配置日志\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass AGIConfig:\n    \"\"\"AGI配置类\"\"\"\n    api_key: str = os.getenv(\"OPENAI_API_KEY\", \"\")\n    model: str = \"gpt-4-turbo-preview\"\n    temperature: float = 0.7\n    max_tokens: int = 2000\n    system_prompt: str = \"你是一个通用人工智能助手，能够处理各种复杂任务，具备推理、学习和解决问题的能力。\"\n    memory_size: int = 1000  # 记忆容量\n    enable_long_term_memory: bool = True\n    enable_self_reflection: bool = True\n    enable_learning: bool = True\n\n\nclass MemorySystem:\n    \"\"\"记忆系统，用于存储和检索AGI的经验和知识\"\"\"\n    \n    def __init__(self, max_size: int = 1000):\n        self.max_size = max_size\n        self.short_term_memory: List[Dict] = []\n        self.long_term_memory: List[Dict] = []\n        self.memory_index: Dict[str, List[int]] = {}\n        \n    def add_memory(self, content: str, memory_type: str = \"conversation\", \n                   metadata: Optional[Dict] = None) -> str:\n        \"\"\"添加记忆\"\"\"\n        memory_id = f\"mem_{datetime.now().timestamp()}_{len(self.short_term_memory)}\"\n        memory_entry = {\n            \"id\": memory_id,\n            \"content\": content,\n            \"type\": memory_type,\n            \"timestamp\": datetime.now().isoformat(),\n            \"metadata\": metadata or {}\n        }\n        \n        self.short_term_memory.append(memory_entry)\n        \n        # 如果短期记忆超过限制，将最旧的记忆转移到长期记忆\n        if len(self.short_term_memory) > self.max_size // 2:\n            old_memory = self.short_term_memory.pop(0)\n            self.long_term_memory.append(old_memory)\n            \n        # 更新索引\n        self._update_index(memory_entry)\n        \n        return memory_id\n    \n    def _update_index(self, memory_entry: Dict):\n        \"\"\"更新记忆索引\"\"\"\n        # 简单的关键词提取（实际应用中可以使用更复杂的NLP技术）\n        keywords = self._extract_keywords(memory_entry[\"content\"])\n        for keyword in keywords:\n            if keyword not in self.memory_index:\n                self.memory_index[keyword] = []\n            self.memory_index[keyword].append(len(self.short_term_memory) - 1)\n    \n    def _extract_keywords(self, text: str) -> List[str]:\n        \"\"\"提取关键词\"\"\"\n        # 这里使用简单的实现，实际可以使用NLP库\n        words = text.lower().split()\n        # 过滤常见停用词\n        stop_words = {\"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"in\", \"on\", \"at\", \"to\", \"for\", \"of\", \"with\"}\n        keywords = [word for word in words if word not in stop_words and len(word) > 3]\n        return keywords[:10]  # 限制关键词数量\n    \n    def retrieve_relevant_memories(self, query: str, limit: int = 5) -> List[Dict]:\n        \"\"\"检索相关记忆\"\"\"\n        query_keywords = self._extract_keywords(query)\n        relevant_indices = set()\n        \n        for keyword in query_keywords:\n            if keyword in self.memory_index:\n                relevant_indices.update(self.memory_index[keyword])\n        \n        # 获取相关记忆\n        relevant_memories = []\n        for idx in list(relevant_indices)[:limit]:\n            if idx < len(self.short_term_memory):\n                relevant_memories.append(self.short_term_memory[idx])\n        \n        # 如果没有找到相关记忆，返回最近的记忆\n        if not relevant_memories and self.short_term_memory:\n            relevant_memories = self.short_term_memory[-limit:]\n        \n        return relevant_memories\n    \n    def get_context(self, query: str) -> str:\n        \"\"\"获取上下文信息\"\"\"\n        relevant_memories = self.retrieve_relevant_memories(query)\n        if not relevant_memories:\n            return \"\"\n        \n        context_parts = [\"相关记忆：\"]\n        for memory in relevant_memories:\n            context_parts.append(f\"- {memory['content']} ({memory['timestamp']})\")\n        \n        return \"\\n\".join(context_parts)\n\n\nclass ReasoningEngine:\n    \"\"\"推理引擎，处理复杂推理任务\"\"\"\n    \n    def __init__(self, client: OpenAI, model: str = \"gpt-4-turbo-preview\"):\n        self.client = client\n        self.model = model\n        \n    def chain_of_thought(self, prompt: str, max_steps: int = 5) -> str:\n        \"\"\"链式思考推理\"\"\"\n        reasoning_prompt = f\"\"\"请逐步推理以下问题。思考步骤：\n        \n        问题：{prompt}\n        \n        请一步一步地思考，最后给出答案。\"\"\"\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"你是一个擅长逐步推理的AI助手。\"},\n                    {\"role\": \"user\", \"content\": reasoning_prompt}\n                ],\n                temperature=0.3,  # 降低温度以获得更确定的推理\n                max_tokens=1000\n            )\n            return response.choices[0].message.content\n        except Exception as e:\n            logger.error(f\"推理过程中出错: {e}\")\n            return f\"推理失败: {str(e)}\"\n    \n    def reflective_thinking(self, problem: str, previous_solution: str) -> str:\n        \"\"\"反思性思考，评估和改进之前的解决方案\"\"\"\n        reflection_prompt = f\"\"\"请反思以下问题和解决方案：\n        \n        问题：{problem}\n        之前的解决方案：{previous_solution}\n        \n        请分析：\n        1. 这个解决方案的优点是什么？\n        2. 这个解决方案的缺点或不足是什么？\n        3. 如何改进这个解决方案？\n        4. 给出改进后的解决方案。\"\"\"\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"你是一个擅长批判性思考和反思的AI助手。\"},\n                    {\"role\": \"user\", \"content\": reflection_prompt}\n                ],\n                temperature=0.5\n            )\n            return response.choices[0].message.content\n        except Exception as e:\n            logger.error(f\"反思过程中出错: {e}\")\n            return f\"反思失败: {str(e)}\"\n\n\nclass LearningModule:\n    \"\"\"学习模块，实现AGI的学习能力\"\"\"\n    \n    def __init__(self, memory_system: MemorySystem):\n        self.memory = memory_system\n        self.learned_concepts: Dict[str, Dict] = {}\n        \n    def learn_from_interaction(self, query: str, response: str, feedback: Optional[str] = None):\n        \"\"\"从交互中学习\"\"\"\n        # 记录交互\n        interaction_summary = f\"用户询问: {query}\\nAI回答: {response}\"\n        if feedback:\n            interaction_summary += f\"\\n反馈: {feedback}\"\n        \n        self.memory.add_memory(\n            content=interaction_summary,\n            memory_type=\"learning\",\n            metadata={\n                \"query\": query,\n                \"response\": response,\n                \"feedback\": feedback,\n                \"learning_timestamp\": datetime.now().isoformat()\n            }\n        )\n        \n        # 提取可能的概念\n        self._extract_concepts(query, response)\n        \n    def _extract_concepts(self, query: str, response: str):\n        \"\"\"从交互中提取概念\"\"\"\n        # 这里可以实现更复杂的概念提取逻辑\n        # 目前是简化版本\n        concepts = self._identify_key_concepts(f\"{query} {response}\")\n        \n        for concept in concepts:\n            if concept not in self.learned_concepts:\n                self.learned_concepts[concept] = {\n                    \"first_encountered\": datetime.now().isoformat(),\n                    \"encounter_count\": 1,\n                    \"examples\": [f\"Q: {query}\\nA: {response}\"]\n                }\n            else:\n                self.learned_concepts[concept][\"encounter_count\"] += 1\n                self.learned_concepts[concept][\"examples\"].append(f\"Q: {query}\\nA: {response}\")\n                \n    def _identify_key_concepts(self, text: str) -> List[str]:\n        \"\"\"识别关键概念\"\"\"\n        # 简化实现，实际可以使用NLP技术\n        words = text.lower().split()\n        # 过滤并返回可能的概念（长度较长的单词）\n        concepts = [word for word in words if len(word) > 6 and word.isalpha()]\n        return list(set(concepts))[:5]  # 限制数量\n    \n    def get_learned_concepts(self) -> Dict[str, Dict]:\n        \"\"\"获取学习到的概念\"\"\"\n        return self.learned_concepts\n\n\nclass AGISystem:\n    \"\"\"主AGI系统类\"\"\"\n    \n    def __init__(self, config: Optional[AGIConfig] = None):\n        self.config = config or AGIConfig()\n        \n        # 初始化OpenAI客户端\n        self.client = OpenAI(api_key=self.config.api_key)\n        \n        # 初始化各子系统\n        self.memory = MemorySystem(max_size=self.config.memory_size)\n        self.reasoning_engine = ReasoningEngine(self.client, self.config.model)\n        self.learning_module = LearningModule(self.memory)\n        \n        # 会话历史\n        self.conversation_history: List[Dict] = []\n        \n        logger.info(\"AGI系统初始化完成\")\n    \n    def process_query(self, query: str, use_reasoning: bool = True) -> str:\n        \"\"\"处理用户查询\"\"\"\n        logger.info(f\"处理查询: {query}\")\n        \n        # 1. 检索相关记忆\n        context = self.memory.get_context(query)\n        \n        # 2. 构建系统提示\n        system_prompt = self.config.system_prompt\n        if context:\n            system_prompt += f\"\\n\\n{context}\"\n        \n        # 3. 如果需要，进行推理\n        if use_reasoning and self._requires_reasoning(query):\n            logger.info(\"启动推理引擎\")\n            reasoning_result = self.reasoning_engine.chain_of_thought(query)\n            system_prompt += f\"\\n\\n推理过程：{reasoning_result}\"\n        \n        # 4. 构建消息历史\n        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n        \n        # 添加最近的对话历史\n        recent_history = self.conversation_history[-10:]  # 最近10条\n        for msg in recent_history:\n            messages.append(msg)\n        \n        # 添加当前查询\n        messages.append({\"role\": \"user\", \"content\": query})\n        \n        # 5. 调用OpenAI API\n        try:\n            response = self.client.chat.completions.create(\n                model=self.config.model,\n                messages=messages,\n                temperature=self.config.temperature,\n                max_tokens=self.config.max_tokens\n            )\n            \n            ai_response = response.choices[0].message.content\n            \n            # 6. 记录交互\n            self.conversation_history.append({\"role\": \"user\", \"content\": query})\n            self.conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n            \n            # 7. 学习\n            self.learning_module.learn_from_interaction(query, ai_response)\n            \n            # 8. 添加到记忆\n            self.memory.add_memory(\n                content=f\"用户: {query}\\nAI: {ai_response}\",\n                memory_type=\"conversation\"\n            )\n            \n            # 9. 如果启用自我反思，进行反思\n            if self.config.enable_self_reflection and len(self.conversation_history) % 5 == 0:\n                self._self_reflect()\n            \n            return ai_response\n            \n        except Exception as e:\n            logger.error(f\"处理查询时出错: {e}\")\n            return f\"抱歉，处理您的请求时出现错误: {str(e)}\"\n    \n    def _requires_reasoning(self, query: str) -> bool:\n        \"\"\"判断查询是否需要推理\"\"\"\n        reasoning_keywords = [\"为什么\", \"如何\", \"解释\", \"分析\", \"比较\", \"推理\", \"思考\", \"解决\", \"计算\"]\n        query_lower = query.lower()\n        return any(keyword in query_lower for keyword in reasoning_keywords)\n    \n    def _self_reflect(self):\n        \"\"\"自我反思\"\"\"\n        if len(self.conversation_history) < 4:\n            return\n        \n        # 获取最近的对话进行反思\n        recent_dialogue = \"\\n\".join([\n            f\"{msg['role']}: {msg['content']}\" \n            for msg in self.conversation_history[-4:]\n        ])\n        \n        reflection = self.reasoning_engine.reflective_thinking(\n            \"最近的对话表现\",\n            recent_dialogue\n        )\n        \n        # 记录反思结果\n        self.memory.add_memory(\n            content=f\"自我反思:\\n{reflection}\",\n            memory_type=\"reflection\"\n        )\n        \n        logger.info(\"完成自我反思\")\n    \n    def get_system_status(self) -> Dict[str, Any]:\n        \"\"\"获取系统状态\"\"\"\n        return {\n            \"config\": asdict(self.config),\n            \"memory_stats\": {\n                \"short_term_memory_count\": len(self.memory.short_term_memory),\n                \"long_term_memory_count\": len(self.memory.long_term_memory),\n                \"memory_index_size\": len(self.memory.memory_index)\n            },\n            \"learning_stats\": {\n                \"learned_concepts_count\": len(self.learning_module.learned_concepts),\n                \"conversation_history_count\": len(self.conversation_history)\n            }\n        }\n    \n    def save_state(self, filepath: str):\n        \"\"\"保存系统状态\"\"\"\n        state = {\n            \"config\": asdict(self.config),\n            \"conversation_history\": self.conversation_history,\n            \"memory\": {\n                \"short_term\": self.memory.short_term_memory,\n                \"long_term\": self.memory.long_term_memory\n            },\n            \"learned_concepts\": self.learning_module.learned_concepts,\n            \"save_timestamp\": datetime.now().isoformat()\n        }\n        \n        with open(filepath, 'w', encoding='utf-8') as f:\n            json.dump(state, f, ensure_ascii=False, indent=2)\n        \n        logger.info(f\"系统状态已保存到: {filepath}\")\n    \n    def load_state(self, filepath: str):\n        \"\"\"加载系统状态\"\"\"\n        try:\n            with open(filepath, 'r', encoding='utf-8') as f:\n                state