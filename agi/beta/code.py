# agi

{
    "files": [
        {
            "filename": "README.md",
            "content": "# AGI (Artificial General Intelligence) Project\n\n## Overview\nThis project aims to implement an Artificial General Intelligence system using OpenAI API as the underlying model interface. The architecture is designed to be modular, scalable, and capable of performing a wide range of cognitive tasks.\n\n## Architecture Components\n- **Core Engine**: Main processing unit that orchestrates different modules\n- **Memory System**: Long-term and short-term memory for context retention\n- **Task Manager**: Handles task decomposition and prioritization\n- **Learning Module**: Adapts and improves performance over time\n- **API Interface**: Standardized interface to OpenAI models\n- **Safety Module**: Ensures ethical and safe behavior\n\n## Key Features\n- Autonomous learning and adaptation\n- Multi-modal reasoning\n- Goal-oriented behavior\n- Self-improvement mechanisms\n- Safety and alignment protocols\n\n## Technologies Used\n- Python 3.9+\n- OpenAI API\n- Redis (for memory management)\n- PostgreSQL (for persistent storage)\n- Docker (for containerization)"
        },
        {
            "filename": "agi/core/engine.py",
            "content": "# agi/core/engine.py\nfrom abc import ABC, abstractmethod\nimport logging\nfrom typing import Any, Dict, List, Optional\nfrom agi.core.memory import MemorySystem\nfrom agi.core.task_manager import TaskManager\nfrom agi.core.api_interface import APIInterface\nfrom agi.core.safety_module import SafetyModule\n\n\nclass AIGCoreEngine(ABC):\n    \"\"\"\n    Abstract base class for the core AGI engine.\n    This engine orchestrates all components of the AGI system.\n    \"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.memory_system = MemorySystem(config.get('memory_config', {}))\n        self.task_manager = TaskManager(config.get('task_config', {}))\n        self.api_interface = APIInterface(config.get('api_config', {}))\n        self.safety_module = SafetyModule(config.get('safety_config', {}))\n        \n    @abstractmethod\n    def process_input(self, input_data: Any) -> Any:\n        \"\"\"\n        Process input data through the AGI system.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def execute_task(self, task: Dict[str, Any]) -> Any:\n        \"\"\"\n        Execute a specific task using the AGI components.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def learn_from_experience(self, experience: Dict[str, Any]) -> None:\n        \"\"\"\n        Learn from a given experience and update internal models.\n        \"\"\"\n        pass\n        \n    def run_cycle(self) -> None:\n        \"\"\"\n        Run one full cycle of the AGI system.\n        \"\"\"\n        # Get current tasks\n        active_tasks = self.task_manager.get_active_tasks()\n        \n        for task in active_tasks:\n            # Check safety before execution\n            if not self.safety_module.is_safe_to_execute(task):\n                self.logger.warning(f\"Task {task['id']} failed safety check\")\n                continue\n            \n            # Execute the task\n            result = self.execute_task(task)\n            \n            # Store result in memory\n            self.memory_system.store_result(task['id'], result)\n            \n            # Learn from this experience\n            experience = {\n                'task': task,\n                'result': result,\n                'context': self.memory_system.get_recent_context()\n            }\n            self.learn_from_experience(experience)\n            \n            # Update task status\n            self.task_manager.mark_completed(task['id'])\n\n\nclass AdvancedAGICoreEngine(AIGCoreEngine):\n    \"\"\"\n    Concrete implementation of the AGI core engine with advanced capabilities.\n    \"\"\"\n    \n    def process_input(self, input_data: Any) -> Any:\n        # Validate input against safety constraints\n        if not self.safety_module.validate_input(input_data):\n            raise ValueError(\"Input violates safety constraints\")\n        \n        # Parse input and determine appropriate action\n        parsed_input = self._parse_input(input_data)\n        \n        # Add to task queue\n        task_id = self.task_manager.add_task(parsed_input)\n        \n        # Process the task\n        return self.execute_task({'id': task_id, **parsed_input})\n        \n    def execute_task(self, task: Dict[str, Any]) -> Any:\n        # Retrieve relevant memories\n        context = self.memory_system.retrieve_relevant_memories(task)\n        \n        # Prepare prompt with context and task details\n        prompt = self._build_prompt(context, task)\n        \n        # Get response from API\n        response = self.api_interface.generate_response(prompt)\n        \n        # Validate response\n        validated_response = self.safety_module.validate_output(response)\n        \n        return validated_response\n        \n    def learn_from_experience(self, experience: Dict[str, Any]) -> None:\n        # Analyze the experience\n        insights = self._analyze_experience(experience)\n        \n        # Update internal models/models\n        self._update_models(insights)\n        \n        # Store experience in long-term memory\n        self.memory_system.store_experience(experience)\n        \n    def _parse_input(self, input_data: Any) -> Dict[str, Any]:\n        # Convert input to structured task\n        return {\n            'type': 'general_query',\n            'content': str(input_data),\n            'priority': 1\n        }\n        \n    def _build_prompt(self, context: Any, task: Dict[str, Any]) -> str:\n        # Construct a comprehensive prompt\n        prompt_parts = []\n        \n        if context:\n            prompt_parts.append(f\"Previous context: {context}\")\n        \n        prompt_parts.append(f\"Current task: {task['content']}\")\n        prompt_parts.append(\"Provide a thoughtful, accurate, and safe response.\")\n        \n        return \"\\n\".join(prompt_parts)\n        \n    def _analyze_experience(self, experience: Dict[str, Any]) -> Dict[str, Any]:\n        # Analyze what was learned from this experience\n        # This would typically involve more sophisticated analysis\n        return {\n            'success': True,\n            'learnings': [],\n            'improvements': []\n        }\n        \n    def _update_models(self, insights: Dict[str, Any]) -> None:\n        # Update internal models based on insights\n        # In a real implementation, this would update neural networks or other models\n        self.logger.info(f\"Model updated with insights: {list(insights.keys())}\")"
        },
        {
            "filename": "agi/core/memory.py",
            "content": "# agi/core/memory.py\nfrom abc import ABC, abstractmethod\nimport logging\nfrom typing import Any, Dict, List, Optional\nimport redis\nimport json\n\n\nclass MemorySystem(ABC):\n    \"\"\"\n    Abstract base class for the AGI's memory system.\n    Handles both short-term and long-term memory.\n    \"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.logger = logging.getLogger(self.__class__.__name__)\n        \n    @abstractmethod\n    def store_result(self, task_id: str, result: Any) -> None:\n        \"\"\"\n        Store the result of a completed task.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def retrieve_relevant_memories(self, task: Dict[str, Any]) -> Any:\n        \"\"\"\n        Retrieve memories relevant to the current task.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def get_recent_context(self) -> Any:\n        \"\"\"\n        Get recent context from memory.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def store_experience(self, experience: Dict[str, Any]) -> None:\n        \"\"\"\n        Store an experience in long-term memory.\n        \"\"\"\n        pass\n\n\nclass RedisMemorySystem(MemorySystem):\n    \"\"\"\n    Concrete implementation of memory system using Redis.\n    \"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.redis_client = redis.Redis(\n            host=config.get('host', 'localhost'),\n            port=config.get('port', 6379),\n            db=config.get('db', 0)\n        )\n        \n        # Keys for different memory types\n        self.short_term_key = 'agi:short_term_memory'\n        self.long_term_key = 'agi:long_term_memory'\n        self.task_results_key = 'agi:task_results'\n        \n    def store_result(self, task_id: str, result: Any) -> None:\n        try:\n            self.redis_client.hset(\n                self.task_results_key,\n                task_id,\n                json.dumps(result)\n            )\n            \n            # Also add to short-term memory\n            self._add_to_short_term(result)\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to store result for task {task_id}: {e}\")\n            \n    def retrieve_relevant_memories(self, task: Dict[str, Any]) -> Any:\n        try:\n            # For now, return recent short-term memories\n            recent_memories = self._get_recent_short_term()\n            \n            # In a real implementation, this would use semantic search\n            # to find memories most relevant to the task\n            return recent_memories\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to retrieve memories: {e}\")\n            return None\n            \n    def get_recent_context(self) -> Any:\n        try:\n            return self._get_recent_short_term()\n        except Exception as e:\n            self.logger.error(f\"Failed to get recent context: {e}\")\n            return None\n            \n    def store_experience(self, experience: Dict[str, Any]) -> None:\n        try:\n            # Add timestamp to experience\n            experience_with_time = {**experience, 'timestamp': time.time()}\n            \n            # Store in long-term memory\n            self.redis_client.lpush(\n                self.long_term_key,\n                json.dumps(experience_with_time)\n            )\n            \n            # Keep only the most recent N experiences\n            self.redis_client.ltrim(self.long_term_key, 0, 999)  # Keep last 1000\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to store experience: {e}\")\n            \n    def _add_to_short_term(self, item: Any) -> None:\n        \"\"\"Add an item to short-term memory.\"\"\"\n        try:\n            item_with_time = {'data': item, 'timestamp': time.time()}\n            self.redis_client.lpush(\n                self.short_term_key,\n                json.dumps(item_with_time)\n            )\n            \n            # Keep only the most recent items\n            self.redis_client.ltrim(self.short_term_key, 0, 99)  # Keep last 100\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to add to short-term memory: {e}\")\n            \n    def _get_recent_short_term(self) -> List[Any]:\n        \"\"\"Get recent items from short-term memory.\"\"\"\n        try:\n            items = self.redis_client.lrange(self.short_term_key, 0, -1)\n            return [json.loads(item) for item in items]\n        except Exception as e:\n            self.logger.error(f\"Failed to get short-term memory: {e}\")\n            return []\n\n\n# Import needed for timestamp functionality\nimport time"
        },
        {
            "filename": "agi/core/task_manager.py",
            "content": "# agi/core/task_manager.py\nfrom abc import ABC, abstractmethod\nimport logging\nimport heapq\nfrom typing import Any, Dict, List, Optional\nimport time\n\n\nclass TaskManager(ABC):\n    \"\"\"\n    Abstract base class for managing tasks in the AGI system.\n    Handles task queuing, prioritization, and execution tracking.\n    \"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.logger = logging.getLogger(self.__class__.__name__)\n        \n    @abstractmethod\n    def add_task(self, task: Dict[str, Any]) -> str:\n        \"\"\"\n        Add a new task to the system.\n        Returns the task ID.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def get_active_tasks(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get all active (ready to execute) tasks.\n        \"\"\"\n        pass\n        \n    @abstractmethod\n    def mark_completed(self, task_id: str) -> None:\n        \"\"\"\n        Mark a task as completed.\n        \"\"\"\n        pass\n\n\nclass PriorityQueueTaskManager(TaskManager):\n    \"\"\"\n    Task manager implementation using a priority queue.\n    \"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        \n        # Priority queue: (-priority, timestamp, task_id, task_data)\n        self.task_queue = []\n        \n        # Track task statuses\n        self.task_statuses = {}  # task_id -> status\n        \n        # Counter for generating unique task IDs\n        self.task_counter = 0\n        \n    def add_task(self, task: Dict[str, Any]) -> str:\n        # Generate unique task ID\n        self.task_counter += 1\n        task_id = f\"task_{int(time.time())}_{self.task_counter}\"\n        \n        # Set default priority if not provided\n        priority = task.get('priority', 1)\n        \n        # Create task entry\n        task_entry = {\n            'id': task_id,\n            'data': task,\n            'added_time': time.time(),\n            'status': 'pending'\n        }\n        \n        # Add to priority queue (negative priority for max-heap behavior)\n        heapq.heappush(\n            self.task_queue,\n            (-priority, task_entry['added_time'], task_id, task_entry)\n        )\n        \n        # Track status\n        self.task_statuses[task_id] = 'pending'\n        \n        self.logger.info(f\"Added task {task_id} with priority {priority}\")\n        \n        return task_id\n        \n    def get_active_tasks(self) -> List[Dict[str, Any]]:\n        # Return all pending tasks (in priority order)\n        active_tasks = []\n        \n        # Copy the queue to avoid modification during iteration\n        temp_queue = self.task_queue.copy()\n        \n        while temp_queue:\n            neg_priority, added_time, task_id, task_entry = heapq.heappop(temp_queue)\n            \n            # Only include tasks that are still pending\n            if self.task_statuses.get(task_id) == 'pending':\n                active_tasks.append(task_entry['data'])\n                \n                # Limit number of returned tasks to prevent overwhelming the system\n                if len(active_tasks) >= self.config.get('max_active_tasks', 5):\n                    break\n        \n        return active_tasks\n        \n    def mark_completed(self, task_id: str) -> None:\n        # Mark task as completed\n        self.task_statuses[task_id] = 'completed'\n        \n        self.logger.info(f\"Marked task {task_id} as completed\")\n        \n    def get_task_status(self, task_id: str) -> str:\n        \"\"\"Get the status of a specific task.\"\"\"\n        return self.task_statuses.get(task_id, 'unknown')\n        \n    def prioritize_task(self, task_id: str, new_priority: int) -> bool:\n        \"\"\"\n        Dynamically adjust the priority of an existing task.\n        \"\"\"\n        if task_id not in self.task_statuses:\n            return False\n            \n        if self.task_statuses[task_id] != 'pending':\n            return False  # Can't reprioritize non-pending tasks\n        \n        # Remove old entry by marking as processed (we'll handle this in get_active_tasks)\n        # Actually reprioritizing would require rebuilding the heap, which is expensive\n        # For now, just log the request\n        self.logger.info(f\"Priority adjustment requested for task {task_id}: {new_priority}\")\n        \n        return True"
        },
        {
            "filename": "agi/core/api_interface.py",
            "content": "# agi/core/api_interface.py\nfrom abc import ABC, abstractmethod\nimport logging\nimport openai\nimport time\nfrom typing import Any, Dict, List, Optional\n\n\nclass APIInterface(ABC):\n    \"\"\"\n    Abstract base class for interfacing with language models/APIs.\n    Provides a standardized way to interact with different models.\n    \"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.logger = logging.getLogger(self.__class__.__name__)\n        \n    @abstractmethod\n    def generate_response(self, prompt: str) -> str:\n        \"\"\"\n        Generate a response based on the given prompt.\n