# agi

```json
{
    "files": [
        {
            "filename": "requirements.txt",
            "content": "openai>=1.0.0\npython-dotenv>=0.19.0\nfastapi>=0.68.0\nuvicorn>=0.15.0\npydantic>=1.8.0\nredis>=4.0.0\nnumpy>=1.21.0\npandas>=1.3.0\nnetworkx>=2.6.0\nscikit-learn>=0.24.0\nmatplotlib>=3.4.0\n"
        },
        {
            "filename": "config.py",
            "content": "import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclass Config:\n    # OpenAI API配置\n    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n    OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n    OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4\")\n    \n    # 服务器配置\n    HOST = os.getenv(\"HOST\", \"0.0.0.0\")\n    PORT = int(os.getenv(\"PORT\", \"8000\"))\n    DEBUG = os.getenv(\"DEBUG\", \"False\").lower() == \"true\"\n    \n    # 数据存储配置\n    REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\")\n    REDIS_PORT = int(os.getenv(\"REDIS_PORT\", \"6379\"))\n    REDIS_DB = int(os.getenv(\"REDIS_DB\", \"0\"))\n    \n    # AGI核心配置\n    MAX_MEMORY_SIZE = int(os.getenv(\"MAX_MEMORY_SIZE\", \"10000\"))\n    LEARNING_RATE = float(os.getenv(\"LEARNING_RATE\", \"0.01\"))\n    SELF_IMPROVEMENT_INTERVAL = int(os.getenv(\"SELF_IMPROVEMENT_INTERVAL\", \"3600\"))  # 秒\n    \n    # 安全配置\n    API_KEY = os.getenv(\"API_KEY\", \"your-secret-api-key\")\n    MAX_TOKENS = int(os.getenv(\"MAX_TOKENS\", \"4096\"))\n    TEMPERATURE = float(os.getenv(\"TEMPERATURE\", \"0.7\"))\n    \n    @classmethod\n    def validate(cls):\n        if not cls.OPENAI_API_KEY:\n            raise ValueError(\"OpenAI API key is not set\")\n        return True"
        },
        {
            "filename": "agi_core.py",
            "content": "import time\nimport json\nimport logging\nfrom typing import Dict, List, Any, Optional\nfrom datetime import datetime\nimport networkx as nx\nimport numpy as np\nfrom openai import OpenAI\nfrom config import Config\n\nclass AGICore:\n    \"\"\"AGI核心系统，负责知识管理、推理和决策\"\"\"\n    \n    def __init__(self):\n        self.client = OpenAI(api_key=Config.OPENAI_API_KEY, base_url=Config.OPENAI_API_BASE)\n        self.knowledge_graph = nx.DiGraph()\n        self.memory_buffer = []\n        self.last_self_improvement = time.time()\n        self.logger = logging.getLogger(__name__)\n        \n        # 初始化一些基本概念\n        self._initialize_basic_concepts()\n    \n    def _initialize_basic_concepts(self):\n        \"\"\"初始化AGI的基本概念和框架\"\"\"\n        # 添加基本节点\n        self.knowledge_graph.add_node(\"self\", type=\"core\", attributes={\"name\": \"AGI\", \"version\": \"1.0.0\"})\n        self.knowledge_graph.add_node(\"knowledge\", type=\"category\")\n        self.knowledge_graph.add_node(\"reasoning\", type=\"category\")\n        self.knowledge_graph.add_node(\"decision\", type=\"category\")\n        self.knowledge_graph.add_node(\"learning\", type=\"category\")\n        \n        # 添加基本关系\n        self.knowledge_graph.add_edge(\"self\", \"knowledge\", relationship=\"contains\")\n        self.knowledge_graph.add_edge(\"self\", \"reasoning\", relationship=\"contains\")\n        self.knowledge_graph.add_edge(\"self\", \"decision\", relationship=\"contains\")\n        self.knowledge_graph.add_edge(\"self\", \"learning\", relationship=\"contains\")\n    \n    def process_input(self, user_input: str, context: Optional[Dict] = None) -> Dict:\n        \"\"\"处理用户输入并生成响应\"\"\"\n        start_time = time.time()\n        \n        # 1. 理解输入\n        understanding = self._understand_input(user_input, context)\n        \n        # 2. 推理和分析\n        reasoning = self._reason(understanding)\n        \n        # 3. 决策和规划\n        decision = self._make_decision(reasoning)\n        \n        # 4. 生成响应\n        response = self._generate_response(decision)\n        \n        # 5. 学习和更新\n        self._learn_from_interaction(user_input, response, understanding, reasoning, decision)\n        \n        # 6. 自我改进检查\n        self._check_self_improvement()\n        \n        processing_time = time.time() - start_time\n        \n        return {\n            \"response\": response,\n            \"processing_time\": processing_time,\n            \"understanding\": understanding,\n            \"reasoning_summary\": self._summarize_reasoning(reasoning),\n            \"confidence\": self._calculate_confidence(reasoning, decision)\n        }\n    \n    def _understand_input(self, user_input: str, context: Optional[Dict]) -> Dict:\n        \"\"\"理解用户输入\"\"\"\n        prompt = f\"\"\"\n        Analyze the following input and provide a structured understanding:\n        \n        Input: \"{user_input}\"\n        \n        Context: {json.dumps(context) if context else \"None\"}\n        \n        Provide your response in JSON format with the following keys:\n        - intent: the primary intent of the input\n        - entities: list of key entities mentioned\n        - sentiment: positive, negative, or neutral\n        - complexity: simple, moderate, or complex\n        - topics: list of relevant topics\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=Config.OPENAI_MODEL,\n            messages=[{\"role\": \"system\", \"content\": \"You are an expert at understanding human input and extracting key information.\"},\n                     {\"role\": \"user\", \"content\": prompt}],\n            max_tokens=500,\n            temperature=0.3\n        )\n        \n        try:\n            understanding = json.loads(response.choices[0].message.content)\n        except json.JSONDecodeError:\n            understanding = {\n                \"intent\": \"unknown\",\n                \"entities\": [],\n                \"sentiment\": \"neutral\",\n                \"complexity\": \"moderate\",\n                \"topics\": []\n            }\n        \n        return understanding\n    \n    def _reason(self, understanding: Dict) -> Dict:\n        \"\"\"基于理解进行推理\"\"\"\n        # 1. 关联知识图谱\n        relevant_knowledge = self._retrieve_relevant_knowledge(understanding)\n        \n        # 2. 应用推理规则\n        reasoning_rules = self._apply_reasoning_rules(understanding, relevant_knowledge)\n        \n        # 3. 进行逻辑推理\n        logical_conclusions = self._logical_reasoning(understanding, relevant_knowledge, reasoning_rules)\n        \n        # 4. 生成假设\n        hypotheses = self._generate_hypotheses(understanding, relevant_knowledge, logical_conclusions)\n        \n        return {\n            \"relevant_knowledge\": relevant_knowledge,\n            \"reasoning_rules_applied\": reasoning_rules,\n            \"logical_conclusions\": logical_conclusions,\n            \"hypotheses\": hypotheses\n        }\n    \n    def _retrieve_relevant_knowledge(self, understanding: Dict) -> List[Dict]:\n        \"\"\"从知识图谱中检索相关知识\"\"\"\n        # 这里简化实现，实际应用中应该使用更复杂的图查询算法\n        relevant_nodes = []\n        \n        # 基于主题查找相关节点\n        for topic in understanding.get(\"topics\", []):\n            nodes = [n for n, d in self.knowledge_graph.nodes(data=True) if topic.lower() in str(d).lower()]\n            relevant_nodes.extend(nodes)\n        \n        # 基于实体查找相关节点\n        for entity in understanding.get(\"entities\", []):\n            nodes = [n for n, d in self.knowledge_graph.nodes(data=True) if entity.lower() in str(d).lower()]\n            relevant_nodes.extend(nodes)\n        \n        # 获取节点详细信息\n        knowledge = []\n        for node in set(relevant_nodes):\n            if node in self.knowledge_graph:\n                data = self.knowledge_graph.nodes[node]\n                knowledge.append({\n                    \"id\": node,\n                    \"type\": data.get(\"type\", \"unknown\"),\n                    \"attributes\": data.get(\"attributes\", {})\n                })\n        \n        return knowledge\n    \n    def _apply_reasoning_rules(self, understanding: Dict, knowledge: List[Dict]) -> List[str]:\n        \"\"\"应用推理规则\"\"\"\n        # 这里简化实现，实际应用中应该有更复杂的规则引擎\n        rules = []\n        \n        # 基于意图应用规则\n        intent = understanding.get(\"intent\", \"unknown\")\n        if intent == \"question\":\n            rules.append(\"seek_answer_in_knowledge\")\n        elif intent == \"request\":\n            rules.append(\"analyze_request_feasibility\")\n        elif intent == \"statement\":\n            rules.append(\"verify_statement_with_knowledge\")\n        \n        # 基于复杂性应用规则\n        complexity = understanding.get(\"complexity\", \"moderate\")\n        if complexity == \"complex\":\n            rules.append(\"break_down_into_subproblems\")\n            rules.append(\"use_multi_step_reasoning\")\n        \n        return rules\n    \n    def _logical_reasoning(self, understanding: Dict, knowledge: List[Dict], rules: List[str]) -> List[Dict]:\n        \"\"\"进行逻辑推理\"\"\"\n        conclusions = []\n        \n        # 这里简化实现，实际应用中应该有更复杂的逻辑推理引擎\n        prompt = f\"\"\"\n        Based on the following information, perform logical reasoning:\n        \n        Understanding: {json.dumps(understanding)}\n        Knowledge: {json.dumps(knowledge)}\n        Rules to apply: {json.dumps(rules)}\n        \n        Provide your conclusions in JSON format as a list of dictionaries with keys:\n        - premise: the premise of the reasoning\n        - conclusion: the conclusion drawn\n        - confidence: confidence level (0-1)\n        - reasoning_type: deductive, inductive, or abductive\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=Config.OPENAI_MODEL,\n            messages=[{\"role\": \"system\", \"content\": \"You are an expert at logical reasoning.\"},\n                     {\"role\": \"user\", \"content\": prompt}],\n            max_tokens=1000,\n            temperature=0.2\n        )\n        \n        try:\n            conclusions = json.loads(response.choices[0].message.content)\n        except json.JSONDecodeError:\n            conclusions = []\n        \n        return conclusions\n    \n    def _generate_hypotheses(self, understanding: Dict, knowledge: List[Dict], conclusions: List[Dict]) -> List[Dict]:\n        \"\"\"生成假设\"\"\"\n        hypotheses = []\n        \n        # 这里简化实现，实际应用中应该有更复杂的假设生成算法\n        prompt = f\"\"\"\n        Based on the following information, generate relevant hypotheses:\n        \n        Understanding: {json.dumps(understanding)}\n        Knowledge: {json.dumps(knowledge)}\n        Conclusions: {json.dumps(conclusions)}\n        \n        Provide your hypotheses in JSON format as a list of dictionaries with keys:\n        - hypothesis: the hypothesis statement\n        - evidence: supporting evidence\n        - testability: how to test the hypothesis\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=Config.OPENAI_MODEL,\n            messages=[{\"role\": \"system\", \"content\": \"You are an expert at generating hypotheses.\"},\n                     {\"role\": \"user\", \"content\": prompt}],\n            max_tokens=1000,\n            temperature=0.3\n        )\n        \n        try:\n            hypotheses = json.loads(response.choices[0].message.content)\n        except json.JSONDecodeError:\n            hypotheses = []\n        \n        return hypotheses\n    \n    def _make_decision(self, reasoning: Dict) -> Dict:\n        \"\"\"基于推理结果做出决策\"\"\"\n        # 1. 评估所有选项\n        options = self._evaluate_options(reasoning)\n        \n        # 2. 选择最佳选项\n        best_option = self._select_best_option(options)\n        \n        # 3. 制定行动计划\n        action_plan = self._create_action_plan(best_option, reasoning)\n        \n        return {\n            \"options\": options,\n            \"selected_option\": best_option,\n            \"action_plan\": action_plan\n        }\n    \n    def _evaluate_options(self, reasoning: Dict) -> List[Dict]:\n        \"\"\"评估所有可能的选项\"\"\"\n        # 这里简化实现，实际应用中应该有更复杂的决策算法\n        prompt = f\"\"\"\n        Based on the following reasoning, evaluate possible response options:\n        \n        Reasoning: {json.dumps(reasoning)}\n        \n        Provide your evaluation in JSON format as a list of dictionaries with keys:\n        - option: the response option\n        - pros: list of advantages\n        - cons: list of disadvantages\n        - feasibility: how feasible to implement (0-1)\n        - expected_outcome: expected outcome of this option\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=Config.OPENAI_MODEL,\n            messages=[{\"role\": \"system\", \"content\": \"You are an expert at evaluating options and making decisions.\"},\n                     {\"role\": \"user\", \"content\": prompt}],\n            max_tokens=1000,\n            temperature=0.3\n        )\n        \n        try:\n            options = json.loads(response.choices[0].message.content)\n        except json.JSONDecodeError:\n            options = []\n        \n        return options\n    \n    def _select_best_option(self, options: List[Dict]) -> Dict:\n        \"\"\"从选项中选择最佳选项\"\"\"\n        if not options:\n            return {\"option\": \"I need more information to respond.\", \"reasoning\": \"No options provided.\"}\n        \n        # 这里简化实现，实际应用中应该有更复杂的选项选择算法\n        # 综合考虑可行性、预期效果等因素\n        best_option = max(options, key=lambda x: x.get(\"feasibility\", 0) * 0.4 + \n                                            (1 - len(x.get(\"cons\", [])) / max(len(x.get(\"pros", [])) + len(x.get(\"cons", [])), 1)) * 0.3 +\n                                            len(x.get(\"expected_outcome\", \"\")) * 0.3)\n        \n        return best_option\n    \n    def _create_action_plan(self, selected_option: Dict, reasoning: Dict) -> List[Dict]:\n        \"\"\"创建行动计划\"\"\"\n        # 这里简化实现，实际应用中应该有更复杂的计划生成算法\n        action_plan = []\n        \n        # 将选定的选项分解为具体步骤\n        prompt = f\"\"\"\n        Break down the following selected option into actionable steps:\n        \n        Selected Option: {json.dumps(selected_option)}\n        Reasoning: {json.dumps(reasoning)}\n        \n        Provide the action plan in JSON format as a list of dictionaries with keys:\n        - step: the action step\n        - purpose: why this step is needed\n        - estimated_time: estimated time to complete\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=Config.OPENAI_MODEL,\n            messages=[{\"role\": \"system\", \"content\": \"You are an expert at creating action plans.\"},\n                     {\"role\": \"user\", \"content\": prompt}],\n            max_tokens=1000,\n            temperature=0.2\n        )\n        \n        try:\n            action_plan = json.loads(response.choices[0].message.content)\n        except json.JSONDecodeError:\n            action_plan = []\n        \n        return action_plan\n    \n    def _generate_response(self, decision: Dict) -> str:\n        \"\"\"生成最终响应\"\"\"\n        selected_option = decision.get(\"selected_option\", {}).get(\"option\", \"I'm not sure how to respond to that.\")\n        \n        # 如果需要，可以进一步优化响应格式和内容\n        prompt = f\"\"\"\n        Format the following response to be helpful and natural:\n        \n        Response: {selected_option}\n        \n        Action Plan: {json.dumps(decision.get(\"action_plan\", []))}\n        \n        Provide the formatted response in plain text.\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=Config.OPENAI_MODEL