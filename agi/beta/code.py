# agi

 ```json
{
  "files": [
    {
      "filename": "requirements.txt",
      "content": "openai>=1.0.0\npython-dotenv>=1.0.0\nnumpy>=1.24.0\npydantic>=2.0.0\ntiktoken>=0.5.0"
    },
    {
      "filename": ".env.example",
      "content": "# OpenAI API Configuration\nOPENAI_API_KEY=your_api_key_here\nOPENAI_MODEL=gpt-4\n\n# AGI Configuration\nMAX_ITERATIONS=10\nMEMORY_LIMIT=1000\nDEBUG_MODE=true"
    },
    {
      "filename": "config/settings.py",
      "content": "\"\"\"\nConfiguration module for AGI project\nHandles environment variables and global settings\n\"\"\"\nimport os\nfrom dotenv import load_dotenv\nfrom pydantic import Field\nfrom pydantic_settings import BaseSettings\n\n# Load environment variables from .env file\nload_dotenv()\n\n\nclass AGIConfig(BaseSettings):\n    \"\"\"Configuration class for AGI system\"\"\"\n    \n    # OpenAI Settings\n    openai_api_key: str = Field(default=os.getenv(\"OPENAI_API_KEY\"), description=\"OpenAI API Key\")\n    openai_model: str = Field(default=os.getenv(\"OPENAI_MODEL\", \"gpt-4\"), description=\"Model to use\")\n    \n    # AGI Behavior Settings\n    max_iterations: int = Field(default=int(os.getenv(\"MAX_ITERATIONS\", \"10\")), description=\"Max reasoning iterations\")\n    memory_limit: int = Field(default=int(os.getenv(\"MEMORY_LIMIT\", \"1000\")), description=\"Memory buffer size\")\n    debug_mode: bool = Field(default=os.getenv(\"DEBUG_MODE\", \"false\").lower() == \"true\", description=\"Debug output\")\n    \n    # System Prompt\n    system_prompt: str = Field(\n        default=\"\"\"You are an AGI (Artificial General Intelligence) system. \nYou have the ability to think step by step, use tools, and learn from past interactions.\nAlways reason through problems thoroughly before taking action.\nIf you need to use a tool, specify it clearly in your response.\"\"\",\n        description=\"Base system prompt\"\n    )\n    \n    class Config:\n        env_file = \".env\"\n\n\n# Global config instance\nconfig = AGIConfig()"
    },
    {
      "filename": "memory/short_term.py",
      "content": "\"\"\"\nShort-term memory implementation for AGI\nUses a simple buffer with relevance scoring\n\"\"\"\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime\nimport json\n\n\nclass MemoryEntry:\n    \"\"\"Single memory entry\"\"\"\n    def __init__(self, content: str, entry_type: str = \"observation\", importance: float = 1.0):\n        self.content = content\n        self.timestamp = datetime.now()\n        self.entry_type = entry_type  # observation, thought, action, result\n        self.importance = importance\n        self.access_count = 0\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"content\": self.content,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"type\": self.entry_type,\n            \"importance\": self.importance,\n            \"access_count\": self.access_count\n        }\n\n\nclass ShortTermMemory:\n    \"\"\"\n    Short-term memory buffer for AGI\n    Implements a sliding window with importance-based retention\n    \"\"\"\n    \n    def __init__(self, capacity: int = 100):\n        self.capacity = capacity\n        self.memories: List[MemoryEntry] = []\n        self.current_context: str = \"\"\n    \n    def add(self, content: str, entry_type: str = \"observation\", importance: float = 1.0) -> None:\n        \"\"\"Add a new memory entry\"\"\"\n        entry = MemoryEntry(content, entry_type, importance)\n        self.memories.append(entry)\n        \n        # If over capacity, remove least important oldest memories\n        if len(self.memories) > self.capacity:\n            self._consolidate_memories()\n    \n    def _consolidate_memories(self) -> None:\n        \"\"\"Remove old, low-importance memories when buffer is full\"\"\"\n        # Sort by importance (descending) and keep top 80%\n        self.memories.sort(key=lambda x: (x.importance, x.timestamp), reverse=True)\n        cutoff = int(self.capacity * 0.8)\n        self.memories = self.memories[:cutoff]\n    \n    def get_recent(self, n: int = 5) -> List[str]:\n        \"\"\"Get n most recent memories\"\"\"\n        recent = self.memories[-n:] if len(self.memories) >= n else self.memories\n        for mem in recent:\n            mem.access_count += 1\n        return [m.content for m in recent]\n    \n    def get_context_string(self) -> str:\n        \"\"\"Format memories as context string for LLM\"\"\"\n        if not self.memories:\n            return \"No previous context.\"\n        \n        context_parts = []\n        for mem in self.memories[-10:]:  # Last 10 memories\n            context_parts.append(f\"[{mem.entry_type.upper()}] {mem.content}\")\n        \n        return \"\\n\".join(context_parts)\n    \n    def clear(self) -> None:\n        \"\"\"Clear all memories\"\"\"\n        self.memories = []\n    \n    def summarize(self) -> str:\n        \"\"\"Create a summary of current memories (placeholder for more complex logic)\"\"\"\n        thoughts = [m.content for m in self.memories if m.entry_type == \"thought\"]\n        actions = [m.content for m in self.memories if m.entry_type == \"action\"]\n        \n        summary = f\"Thoughts: {len(thoughts)}, Actions: {len(actions)}\"\n        return summary"
    },
    {
      "filename": "tools/base.py",
      "content": "\"\"\"\nBase tool interface for AGI\nAll tools must inherit from BaseTool\n\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, Optional\n\n\nclass ToolResult:\n    \"\"\"Standardized tool execution result\"\"\"\n    def __init__(self, success: bool, data: Any, error: Optional[str] = None):\n        self.success = success\n        self.data = data\n        self.error = error\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"success\": self.success,\n            \"data\": self.data,\n            \"error\": self.error\n        }\n\n\nclass BaseTool