# agi

```json
{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "# agi_core.py\n# Advanced General Intelligence (AGI) Core Implementation\n# Uses OpenAI API for language model interactions\n\nimport os\nimport json\nimport time\nimport logging\nfrom typing import Dict, List, Any, Optional\nimport openai\nfrom datetime import datetime\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Set up OpenAI API key\nopenai.api_key = os.getenv('OPENAI_API_KEY')\nif not openai.api_key:\n    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")\n\nclass AGICore:\n    \"\"\"\n    The core class for the Advanced General Intelligence (AGI) system.\n    This system uses OpenAI's API to simulate reasoning, planning, and decision-making.\n    \"\"\"\n\n    def __init__(self, model: str = \"gpt-4-turbo\", max_tokens: int = 4096):\n        self.model = model\n        self.max_tokens = max_tokens\n        self.memory = {}\n        self.session_id = str(datetime.now().timestamp())\n        self.reasoning_steps = []\n        self.context_window = []\n        logger.info(f\"AGI Core initialized with model: {model}\")\n\n    def _generate_prompt(self, instruction: str, context: Optional[List[str]] = None) -> str:\n        \"\"\"\n        Generate a structured prompt for the LLM based on the instruction and context.\n        \"\"\"\n        if context is None:\n            context = []\n\n        prompt = f\"\"\"You are an advanced general intelligence agent tasked with solving complex problems.\n\nCurrent Task: {instruction}\n\nContext:\\n{\\n'. '.join(context)}\\n\\nInstructions:\\n1. Think step-by-step.\n2. Reason logically and thoroughly.\n3. Use your knowledge base effectively.\n4. If uncertain, ask clarifying questions.\n5. Provide clear, concise, and accurate responses.\n\nYour response should include:\n- A breakdown of your thought process\n- Any assumptions made\n- Your final answer or action plan\\n\"\"\"\n        return prompt\n\n    def _call_openai_api(self, prompt: str) -> Dict[str, Any]:\n        \"\"\"\n        Make a call to the OpenAI API with the given prompt.\n        \"\"\"\n        try:\n            response = openai.ChatCompletion.create(\n                model=self.model,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                max_tokens=self.max_tokens,\n                temperature=0.7,\n                top_p=1.0,\n                frequency_penalty=0.0,\n                presence_penalty=0.0,\n            )\n            return {\n                \"success\": True,\n                \"response\": response.choices[0].message.content,\n                \"usage\": response.usage\n            }\n        except Exception as e:\n            logger.error(f\"Error calling OpenAI API: {e}\")\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"response\": \"\",\n                \"usage\": {}\n            }\n\n    def reason(self, instruction: str, context: Optional[List[str]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Perform reasoning using the LLM to solve a problem.\n        \"\"\"\n        # Add to context window\n        self.context_window.append(f\"Task: {instruction}\")\n        if context:\n            self.context_window.extend(context)\n\n        # Generate prompt\n        prompt = self._generate_prompt(instruction, self.context_window)\n\n        # Call OpenAI API\n        result = self._call_openai_api(prompt)\n\n        if result[\"success\"]:\n            # Store reasoning step\n            reasoning_step = {\n                \"timestamp\": datetime.now().isoformat(),\n                \"instruction\": instruction,\n                \"context\": context,\n                \"response\": result[\"response\"],\n                \"tokens_used\": result[\"usage\"].get(\"total_tokens\", 0)\n            }\n            self.reasoning_steps.append(reasoning_step)\n\n            # Update memory\n            self._update_memory(instruction, result[\"response\"])\n\n            logger.info(f\"Reasoning completed successfully. Tokens used: {result['usage'].get('total_tokens', 0)}\")\n\n        else:\n            logger.error(f\"Reasoning failed: {result['error']}\")\n\n        return result\n\n    def _update_memory(self, query: str, response: str):\n        \"\"\"\n        Update internal memory with new information.\n        \"\"\"\n        # Simple memory storage - could be expanded with vector databases or retrieval systems\n        if query not in self.memory:\n            self.memory[query] = []\n        self.memory[query].append({\n            \"response\": response,\n            \"timestamp\": datetime.now().isoformat()\n        })\n\n    def retrieve_memory(self, query: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieve relevant memories based on a query.\n        \"\"\"\n        return self.memory.get(query, [])\n\n    def plan(self, goal: str) -> Dict[str, Any]:\n        \"\"\"\n        Generate a high-level plan to achieve a given goal.\n        \"\"\"\n        prompt = f\"\"\"You are an advanced planner. Create a detailed step-by-step plan to achieve the following goal:\n\nGoal: {goal}\n\nPlan must include:\n- Clear objectives\n- Required resources\n- Potential risks and mitigation strategies\n- Timeline estimates\n- Key milestones\n\nProvide your response in JSON format.\"\"\"\n\n        result = self._call_openai_api(prompt)\n        return result\n\n    def execute_plan(self, plan: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Execute a plan by breaking it into steps and reasoning through each.\n        \"\"\"\n        execution_results = []\n        for step in plan.get(\"steps\", []):\n            logger.info(f\"Executing step: {step}\")\n            result = self.reason(step)\n            execution_results.append({\n                \"step\": step,\n                \"result\": result\n            })\n        return {\"execution_results\": execution_results}\n\n    def get_session_summary(self) -> Dict[str, Any]:\n        \"\"\"\n        Return a summary of the current session.\n        \"\"\"\n        return {\n            \"session_id\": self.session_id,\n            \"reasoning_steps_count\": len(self.reasoning_steps),\n            \"memory_items\": len(self.memory),\n            \"last_updated\": datetime.now().isoformat(),\n            \"context_window_size\": len(self.context_window)\n        }\n\n    def save_state(self, filename: str):\n        \"\"\"\n        Save the current state of the AGI to a file.\n        \"\"\"\n        state = {\n            \"session_id\": self.session_id,\n            \"memory\": self.memory,\n            \"reasoning_steps\": self.reasoning_steps,\n            \"context_window\": self.context_window,\n            \"timestamp\": datetime.now().isoformat()\n        }\n        with open(filename, 'w') as f:\n            json.dump(state, f, indent=2)\n        logger.info(f\"AGI state saved to {filename}\")\n\n    def load_state(self, filename: str):\n        \"\"\"\n        Load the AGI state from a file.\n        \"\"\"\n        try:\n            with open(filename, 'r') as f:\n                state = json.load(f)\n            self.session_id = state[\"session_id\"]\n            self.memory = state[\"memory\"]\n            self.reasoning_steps = state[\"reasoning_steps\"]\n            self.context_window = state[\"context_window\"]\n            logger.info(f\"AGI state loaded from {filename}\")\n        except FileNotFoundError:\n            logger.warning(f\"State file {filename} not found.\")\n        except Exception as e:\n            logger.error(f\"Error loading state: {e}\")\n\n# Example usage and testing\nif __name__ == \"__main__\":\n    # Initialize AGI core\n    agi = AGICore(model=\"gpt-4-turbo\")\n\n    # Test reasoning\n    print(\"Testing reasoning...\")\n    result = agi.reason(\"What is the capital of France?\")\n    if result[\"success\"]:\n        print(f\"Response: {result['response']}\\n\")\n\n    # Test planning\n    print(\"Testing planning...\")\n    plan_result = agi.plan(\"Create a sustainable garden in an urban apartment\")\n    if plan_result[\"success\"]:\n        print(f\"Plan: {plan_result['response']}\\n\")\n\n    # Get session summary\n    print(\"Session Summary:\")\n    print(json.dumps(agi.get_session_summary(), indent=2))\n\n    # Save state\n    agi.save_state(\"agi_state.json\")"
        }
    ]
}
```