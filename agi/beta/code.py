# agi

```json
{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "#!/usr/bin/env python3\n\"\"\"\nAGI核心模块 - 实现通用人工智能的核心逻辑\n\n这个模块提供了AGI系统的基础架构，包括记忆管理、任务分解、\n推理引擎和OpenAI API集成等功能。\n\"\"\"\n\nimport json\nimport logging\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom dataclasses import dataclass, asdict\nfrom datetime import datetime\nimport openai\nfrom openai import OpenAI\n\n# 配置日志\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass MemoryItem:\n    \"\"\"记忆项数据结构\"\"\"\n    id: str\n    content: str\n    timestamp: datetime\n    importance: float  # 0-1的重要性评分\n    context: Dict[str, Any]\n    metadata: Dict[str, Any]\n\n\n@dataclass\nclass Task:\n    \"\"\"任务数据结构\"\"\"\n    id: str\n    description: str\n    status: str  # pending, in_progress, completed, failed\n    priority: int  # 1-5，1为最高优先级\n    subtasks: List['Task']\n    result: Optional[str] = None\n    created_at: datetime = None\n    updated_at: datetime = None\n\n    def __post_init__(self):\n        if self.created_at is None:\n            self.created_at = datetime.now()\n        if self.updated_at is None:\n            self.updated_at = datetime.now()\n\n\nclass MemorySystem:\n    \"\"\"记忆管理系统\"\"\"\n    \n    def __init__(self, max_memories: int = 1000):\n        self.memories: Dict[str, MemoryItem] = {}\n        self.max_memories = max_memories\n        self.memory_index = {}  # 简单的关键词索引\n        \n    def add_memory(self, content: str, importance: float = 0.5, \n                   context: Optional[Dict] = None) -> str:\n        \"\"\"添加新的记忆\"\"\"\n        memory_id = f\"mem_{len(self.memories)}_{datetime.now().timestamp()}\"\n        \n        memory_item = MemoryItem(\n            id=memory_id,\n            content=content,\n            timestamp=datetime.now(),\n            importance=importance,\n            context=context or {},\n            metadata={\"type\": \"general\"}\n        )\n        \n        self.memories[memory_id] = memory_item\n        self._update_index(memory_item)\n        \n        # 如果记忆过多，清理最不重要的\n        if len(self.memories) > self.max_memories:\n            self._cleanup_memories()\n        \n        logger.info(f\"Added memory: {memory_id}\")\n        return memory_id\n    \n    def retrieve_memories(self, query: str, limit: int = 10) -> List[MemoryItem]:\n        \"\"\"检索相关记忆\"\"\"\n        # 简单的关键词匹配检索\n        query_words = set(query.lower().split())\n        relevant_memories = []\n        \n        for memory in self.memories.values():\n            content_words = set(memory.content.lower().split())\n            if query_words & content_words:\n                relevant_memories.append(memory)\n        \n        # 按重要性排序\n        relevant_memories.sort(key=lambda x: x.importance, reverse=True)\n        return relevant_memories[:limit]\n    \n    def _update_index(self, memory: MemoryItem):\n        \"\"\"更新记忆索引\"\"\"\n        words = memory.content.lower().split()\n        for word in words:\n            if word not in self.memory_index:\n                self.memory_index[word] = []\n            self.memory_index[word].append(memory.id)\n    \n    def _cleanup_memories(self):\n        \"\"\"清理最不重要的记忆\"\"\"\n        memories_list = list(self.memories.values())\n        memories_list.sort(key=lambda x: x.importance)\n        \n        # 保留最重要的80%\n        keep_count = int(self.max_memories * 0.8)\n        to_remove = memories_list[:len(memories_list) - keep_count]\n        \n        for memory in to_remove:\n            del self.memories[memory.id]\n            \n        logger.info(f\"Cleaned up {len(to_remove)} memories\")\n\n\nclass TaskManager:\n    \"\"\"任务管理器\"\"\"\n    \n    def __init__(self):\n        self.tasks: Dict[str, Task] = {}\n        self.task_counter = 0\n    \n    def create_task(self, description: str, priority: int = 3) -> Task:\n        \"\"\"创建新任务\"\"\"\n        task_id = f\"task_{self.task_counter}\"\n        self.task_counter += 1\n        \n        task = Task(\n            id=task_id,\n            description=description,\n            status=\"pending\",\n            priority=priority,\n            subtasks=[],\n            created_at=datetime.now(),\n            updated_at=datetime.now()\n        )\n        \n        self.tasks[task_id] = task\n        logger.info(f\"Created task: {task_id} - {description}\")\n        return task\n    \n    def decompose_task(self, task: Task, model_client: Any) -> List[Task]:\n        \"\"\"使用AI模型分解复杂任务\"\"\"\n        prompt = f\"\"\"请将以下任务分解为更小的子任务：\n        任务：{task.description}\n        \n        请以JSON格式返回子任务列表，每个子任务包含description和priority字段。\n        示例格式：\n        {{\n            \"subtasks\": [\n                {{\"description\": \"子任务1\", \"priority\": 3}},\n                {{\"description\": \"子任务2\", \"priority\": 2}}\n            ]\n        }}\n        \"\"\"\n        \n        try:\n            response = model_client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"你是一个任务分解专家。\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.3\n            )\n            \n            result = response.choices[0].message.content\n            # 提取JSON部分\n            json_start = result.find('{')\n            json_end = result.rfind('}') + 1\n            json_str = result[json_start:json_end]\n            \n            subtasks_data = json.loads(json_str)\n            \n            subtasks = []\n            for subtask_data in subtasks_data.get(\"subtasks\", []):\n                subtask = self.create_task(\n                    description=subtask_data[\"description\"],\n                    priority=subtask_data.get(\"priority\", 3)\n                )\n                subtasks.append(subtask)\n            \n            task.subtasks = subtasks\n            task.updated_at = datetime.now()\n            \n            logger.info(f\"Decomposed task {task.id} into {len(subtasks)} subtasks\")\n            return subtasks\n            \n        except Exception as e:\n            logger.error(f\"Failed to decompose task: {e}\")\n            return []\n    \n    def get_next_task(self) -> Optional[Task]:\n        \"\"\"获取下一个要执行的任务（基于优先级）\"\"\"\n        pending_tasks = [t for t in self.tasks.values() if t.status == \"pending\"]\n        \n        if not pending_tasks:\n            return None\n        \n        # 按优先级排序（数字越小优先级越高）\n        pending_tasks.sort(key=lambda x: (x.priority, x.created_at))\n        return pending_tasks[0]\n    \n    def update_task_status(self, task_id: str, status: str, result: Optional[str] = None):\n        \"\"\"更新任务状态\"\"\"\n        if task_id in self.tasks:\n            task = self.tasks[task_id]\n            task.status = status\n            task.updated_at = datetime.now()\n            if result:\n                task.result = result\n            logger.info(f\"Updated task {task_id} status to {status}\")\n\n\nclass ReasoningEngine:\n    \"\"\"推理引擎\"\"\"\n    \n    def __init__(self, openai_api_key: str):\n        self.client = OpenAI(api_key=openai_api_key)\n        self.memory_system = MemorySystem()\n        self.task_manager = TaskManager()\n        \n    def process_query(self, query: str) -> Dict[str, Any]:\n        \"\"\"处理用户查询\"\"\"\n        logger.info(f\"Processing query: {query}\")\n        \n        # 1. 检索相关记忆\n        relevant_memories = self.memory_system.retrieve_memories(query)\n        memory_context = \"\\n\".join([m.content for m in relevant_memories[:3]])\n        \n        # 2. 创建任务\n        task = self.task_manager.create_task(query)\n        \n        # 3. 生成响应\n        prompt = f\"\"\"基于以下上下文和用户查询，生成一个深思熟虑的响应：\n        \n        相关记忆：\n        {memory_context}\n        \n        用户查询：{query}\n        \n        请提供一个全面、有帮助的响应。如果任务需要多个步骤，请解释你将如何分解它。\n        \"\"\"\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=\"gpt-4\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"你是一个通用人工智能助手，能够思考、学习和解决问题。\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.7,\n                max_tokens=1000\n            )\n            \n            ai_response = response.choices[0].message.content\n            \n            # 4. 存储记忆\n            self.memory_system.add_memory(\n                content=f\"用户查询：{query}\\nAI响应：{ai_response[:200]}...\",\n                importance=0.7,\n                context={\"query\": query, \"response_length\": len(ai_response)}\n            )\n            \n            # 5. 分析是否需要任务分解\n            if self._needs_decomposition(query, ai_response):\n                subtasks = self.task_manager.decompose_task(task, self.client)\n                ai_response += f\"\\n\\n我已经将这个任务分解为 {len(subtasks)} 个子任务。\"\n            \n            # 更新任务状态\n            self.task_manager.update_task_status(task.id, \"completed\", ai_response)\n            \n            return {\n                \"response\": ai_response,\n                \"task_id\": task.id,\n                \"memories_used\": len(relevant_memories),\n                \"requires_followup\": len(task.subtasks) > 0\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error processing query: {e}\")\n            return {\n                \"response\": f\"抱歉，处理查询时出现错误：{str(e)}\",\n                \"error\": True\n            }\n    \n    def _needs_decomposition(self, query: str, response: str) -> bool:\n        \"\"\"判断任务是否需要分解\"\"\"\n        # 简单的启发式规则\n        complex_indicators = [\n            \"步骤\", \"首先\", \"然后\", \"最后\",\n            \"多个\", \"复杂\", \"分解\", \"子任务\",\n            \"需要\", \"计划\", \"安排\"\n        ]\n        \n        query_lower = query.lower()\n        response_lower = response.lower()\n        \n        # 检查查询或响应中是否包含复杂任务指示词\n        for indicator in complex_indicators:\n            if indicator in query_lower or indicator in response_lower:\n                return True\n        \n        # 检查查询长度（较长的查询可能更复杂）\n        if len(query.split()) > 15:\n            return True\n        \n        return False\n    \n    def execute_task(self, task_id: str) -> Dict[str, Any]:\n        \"\"\"执行特定任务\"\"\"\n        if task_id not in self.task_manager.tasks:\n            return {\"error\": f\"任务 {task_id} 不存在\"}\n        \n        task = self.task_manager.tasks[task_id]\n        \n        # 如果有子任务，先执行子任务\n        if task.subtasks:\n            results = []\n            for subtask in task.subtasks:\n                if subtask.status == \"pending\":\n                    result = self.execute_task(subtask.id)\n                    results.append(result)\n            \n            # 汇总子任务结果\n            summary = self._summarize_subtask_results(results, task)\n            self.task_manager.update_task_status(task_id, \"completed\", summary)\n            return {\"task_id\": task_id, \"result\": summary, \"subtasks_completed\": len(results)}\n        \n        # 执行单个任务\n        return self.process_query(task.description)\n    \n    def _summarize_subtask_results(self, results: List[Dict], parent_task: Task) -> str:\n        \"\"\"汇总子任务结果\"\"\"\n        prompt = f\"\"\"请汇总以下子任务的执行结果：\n        \n        父任务：{parent_task.description}\n        \n        子任务结果：\n        {json.dumps(results, ensure_ascii=False, indent=2)}\n        \n        请提供一个简洁的总结报告。\n        \"\"\"\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"你是一个任务总结专家。\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.3\n            )\n            \n            return response.choices[0].message.content\n        except Exception as e:\n            return f\"子任务执行完成，但总结时出错：{str(e)}\"\n\n\nclass AGISystem:\n    \"\"\"AGI主系统\"\"\"\n    \n    def __init__(self, openai_api_key: str):\n        \"\"\"初始化AGI系统\"\"\"\n        self.reasoning_engine = ReasoningEngine(openai_api_key)\n        self.conversation_history = []\n        \n    def chat(self, user_input: str) -> str:\n        \"\"\"与AGI系统对话\"\"\"\n        # 添加到对话历史\n        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n        \n        # 处理查询\n        result = self.reasoning_engine.process_query(user_input)\n        \n        # 获取响应\n        response = result.get(\"response\", \"抱歉，我没有得到响应。\")\n        \n        # 添加到对话历史\n        self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n        \n        # 如果有关联任务，添加到响应中\n        if \"task_id\" in result and result.get(\"requires_followup\", False):\n            response += f\"\\n\\n（任务ID: {result['task_id']} 已创建，包含子任务需要执行）\"\n        \n        return response\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"获取系统状态\"\"\"\n        return {\n            \"memory_count\": len(self.reasoning_engine.memory_system.memories),\n            \"task_count\": len(self.reasoning_engine.task_manager.tasks),\n            \"conversation_turns\": len(self.conversation_history),\n            \"pending_tasks\": len([t for t in self.reasoning_engine.task_manager.tasks.values() \n                                  if t.status == \"pending\"])\n        }\n\n\ndef main():\n    \"\"\"主函数 - 示例用法\"\"\"\n    import os\n    \n    # 从环境变量获取API密钥\n    api_key = os.getenv(\"OPENAI_API_KEY\")\n    if not api_key:\n        print(\"请设置OPENAI_API_KEY环境变量\")\n        return\n    \n    # 创建AGI系统\n    agi = AGISystem(api_key)\n    \n    print(\"AGI系统已启动！输入'quit'退出，'status'查看状态，'execute <task_id>'执行任务\")\n    print(\"=\" * 50)\n    \n    while True:\n        try:\n            user_input = input(\"\\