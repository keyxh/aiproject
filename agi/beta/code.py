# agi

```json
{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "#!/usr/bin/env python3\n\"\"\"\nAGI Core Module - 实现通用人工智能核心功能\n\n这个模块提供了AGI系统的核心功能，包括：\n1. 与OpenAI API的交互\n2. 记忆管理\n3. 目标导向的任务执行\n4. 自我反思和改进\n\"\"\"\n\nimport os\nimport json\nimport time\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom datetime import datetime\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\nimport openai\nfrom openai import OpenAI\nimport logging\nfrom logging.handlers import RotatingFileHandler\n\n# 配置日志\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        RotatingFileHandler('agi.log', maxBytes=10485760, backupCount=5),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n\nclass TaskStatus(Enum):\n    \"\"\"任务状态枚举\"\"\"\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n\n@dataclass\nclass MemoryItem:\n    \"\"\"记忆项数据结构\"\"\"\n    id: str\n    content: str\n    timestamp: float\n    importance: float  # 0-1的重要性评分\n    tags: List[str]\n    metadata: Dict[str, Any]\n\n\n@dataclass\nclass Task:\n    \"\"\"任务数据结构\"\"\"\n    id: str\n    description: str\n    status: TaskStatus\n    priority: int  # 1-10，越高越优先\n    created_at: float\n    updated_at: float\n    result: Optional[str] = None\n    subtasks: List['Task'] = None\n    \n    def __post_init__(self):\n        if self.subtasks is None:\n            self.subtasks = []\n\n\nclass AGICore:\n    \"\"\"AGI核心类\"\"\"\n    \n    def __init__(self, api_key: str = None, model: str = \"gpt-4\"):\n        \"\"\"\n        初始化AGI核心\n        \n        Args:\n            api_key: OpenAI API密钥，如果为None则从环境变量读取\n            model: 使用的模型名称\n        \"\"\"\n        self.api_key = api_key or os.getenv(\"OPENAI_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"OpenAI API key is required\")\n        \n        self.client = OpenAI(api_key=self.api_key)\n        self.model = model\n        \n        # 记忆系统\n        self.memory: Dict[str, MemoryItem] = {}\n        self.memory_limit = 1000  # 最大记忆数量\n        \n        # 任务系统\n        self.tasks: Dict[str, Task] = {}\n        self.current_task: Optional[Task] = None\n        \n        # 系统提示词\n        self.system_prompt = \"\"\"你是一个通用人工智能（AGI）。你的目标是理解并完成用户的任务，\n同时不断学习和改进自己。你可以：\n1. 分析复杂问题并分解为子任务\n2. 从记忆中检索相关信息\n3. 执行具体操作\n4. 反思结果并改进方法\n5. 学习新知识和技能\n\n请以理性、系统化的方式思考问题，并清晰地展示你的思考过程。\"\"\"\n        \n        # 对话历史\n        self.conversation_history: List[Dict[str, str]] = [\n            {\"role\": \"system\", \"content\": self.system_prompt}\n        ]\n        \n        logger.info(f\"AGI Core initialized with model: {model}\")\n    \n    def think(self, prompt: str, context: List[Dict[str, str]] = None) -> str:\n        \"\"\"\n        核心思考函数，与LLM交互\n        \n        Args:\n            prompt: 用户输入\n            context: 额外的上下文信息\n            \n        Returns:\n            LLM的响应\n        \"\"\"\n        try:\n            messages = self.conversation_history.copy()\n            \n            if context:\n                messages.extend(context)\n            \n            messages.append({\"role\": \"user\", \"content\": prompt})\n            \n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=messages,\n                temperature=0.7,\n                max_tokens=2000\n            )\n            \n            result = response.choices[0].message.content\n            \n            # 更新对话历史\n            self.conversation_history.append({\"role\": \"user\", \"content\": prompt})\n            self.conversation_history.append({\"role\": \"assistant\", \"content\": result})\n            \n            # 保持对话历史长度\n            if len(self.conversation_history) > 20:\n                self.conversation_history = [\n                    self.conversation_history[0],  # 保留系统提示\n                    *self.conversation_history[-18:]\n                ]\n            \n            logger.info(f\"Thought generated: {result[:100]}...\")\n            return result\n            \n        except Exception as e:\n            logger.error(f\"Error in think function: {e}\")\n            return f\"思考过程中出现错误: {str(e)}\"\n    \n    def add_memory(self, content: str, importance: float = 0.5, \n                  tags: List[str] = None, metadata: Dict[str, Any] = None) -> str:\n        \"\"\"\n        添加记忆\n        \n        Args:\n            content: 记忆内容\n            importance: 重要性评分 (0-1)\n            tags: 标签列表\n            metadata: 元数据\n            \n        Returns:\n            记忆ID\n        \"\"\"\n        memory_id = f\"memory_{len(self.memory)}_{int(time.time())}\"\n        \n        memory_item = MemoryItem(\n            id=memory_id,\n            content=content,\n            timestamp=time.time(),\n            importance=importance,\n            tags=tags or [],\n            metadata=metadata or {}\n        )\n        \n        self.memory[memory_id] = memory_item\n        \n        # 如果超过限制，删除最不重要的记忆\n        if len(self.memory) > self.memory_limit:\n            self._prune_memory()\n        \n        logger.info(f\"Memory added: {memory_id}\")\n        return memory_id\n    \n    def _prune_memory(self):\n        \"\"\"修剪记忆，删除最不重要的记忆\"\"\"\n        # 按重要性排序\n        sorted_memories = sorted(\n            self.memory.items(), \n            key=lambda x: x[1].importance\n        )\n        \n        # 删除最不重要的10%的记忆\n        to_remove = int(len(sorted_memories) * 0.1)\n        for memory_id, _ in sorted_memories[:to_remove]:\n            del self.memory[memory_id]\n        \n        logger.info(f\"Pruned {to_remove} memories\")\n    \n    def retrieve_memories(self, query: str, limit: int = 5) -> List[MemoryItem]:\n        \"\"\"\n        检索相关记忆\n        \n        Args:\n            query: 查询字符串\n            limit: 返回的最大数量\n            \n        Returns:\n            相关记忆列表\n        \"\"\"\n        # 简单实现：基于关键词匹配\n        # 在实际应用中，可以使用向量数据库进行语义搜索\n        query_words = set(query.lower().split())\n        \n        scored_memories = []\n        \n        for memory in self.memory.values():\n            score = 0\n            content_words = set(memory.content.lower().split())\n            \n            # 计算关键词匹配分数\n            common_words = query_words.intersection(content_words)\n            score += len(common_words) * 0.3\n            \n            # 考虑重要性\n            score += memory.importance * 0.2\n            \n            # 考虑时间衰减（越新的记忆越重要）\n            time_decay = 1 / (1 + (time.time() - memory.timestamp) / 86400)  # 按天衰减\n            score += time_decay * 0.1\n            \n            if score > 0:\n                scored_memories.append((score, memory))\n        \n        # 按分数排序并返回前limit个\n        scored_memories.sort(key=lambda x: x[0], reverse=True)\n        return [memory for _, memory in scored_memories[:limit]]\n    \n    def create_task(self, description: str, priority: int = 5) -> str:\n        \"\"\"\n        创建新任务\n        \n        Args:\n            description: 任务描述\n            priority: 优先级 (1-10)\n            \n        Returns:\n            任务ID\n        \"\"\"\n        task_id = f\"task_{len(self.tasks)}_{int(time.time())}\"\n        \n        task = Task(\n            id=task_id,\n            description=description,\n            status=TaskStatus.PENDING,\n            priority=priority,\n            created_at=time.time(),\n            updated_at=time.time()\n        )\n        \n        self.tasks[task_id] = task\n        logger.info(f\"Task created: {task_id} - {description}\")\n        return task_id\n    \n    def decompose_task(self, task_id: str) -> List[str]:\n        \"\"\"\n        分解任务为子任务\n        \n        Args:\n            task_id: 任务ID\n            \n        Returns:\n            子任务ID列表\n        \"\"\"\n        if task_id not in self.tasks:\n            raise ValueError(f\"Task {task_id} not found\")\n        \n        task = self.tasks[task_id]\n        \n        # 使用LLM分析任务并分解\n        prompt = f\"\"\"请分析以下任务，并将其分解为具体的子任务。\n        任务：{task.description}\n        \n        请以JSON格式返回子任务列表，每个子任务包含：\n        1. description: 子任务描述\n        2. priority: 子任务优先级 (1-10)\n        \"\"\"\n        \n        response = self.think(prompt)\n        \n        try:\n            # 尝试解析JSON响应\n            import re\n            json_match = re.search(r'\\[.*\\]', response, re.DOTALL)\n            if json_match:\n                subtasks_data = json.loads(json_match.group())\n            else:\n                # 如果找不到JSON，尝试直接解析\n                subtasks_data = json.loads(response)\n            \n            subtask_ids = []\n            for subtask_data in subtasks_data:\n                subtask_id = self.create_task(\n                    description=subtask_data['description'],\n                    priority=subtask_data.get('priority', task.priority)\n                )\n                self.tasks[subtask_id].status = TaskStatus.PENDING\n                task.subtasks.append(self.tasks[subtask_id])\n                subtask_ids.append(subtask_id)\n            \n            logger.info(f\"Task {task_id} decomposed into {len(subtask_ids)} subtasks\")\n            return subtask_ids\n            \n        except Exception as e:\n            logger.error(f\"Failed to decompose task: {e}\")\n            return []\n    \n    def execute_task(self, task_id: str) -> str:\n        \"\"\"\n        执行任务\n        \n        Args:\n            task_id: 任务ID\n            \n        Returns:\n            执行结果\n        \"\"\"\n        if task_id not in self.tasks:\n            raise ValueError(f\"Task {task_id} not found\")\n        \n        task = self.tasks[task_id]\n        task.status = TaskStatus.IN_PROGRESS\n        task.updated_at = time.time()\n        \n        self.current_task = task\n        \n        logger.info(f\"Executing task: {task_id} - {task.description}\")\n        \n        # 检索相关记忆\n        relevant_memories = self.retrieve_memories(task.description)\n        memory_context = \"\"\n        if relevant_memories:\n            memory_context = \"\\n相关记忆：\"\n            for memory in relevant_memories:\n                memory_context += f\"\\n- {memory.content}\"\n        \n        # 构建执行提示\n        prompt = f\"\"\"请执行以下任务：\n        任务：{task.description}\n        {memory_context}\n        \n        请详细描述你的执行步骤和结果。\"\"\"\n        \n        # 执行任务\n        result = self.think(prompt)\n        \n        # 更新任务状态\n        task.status = TaskStatus.COMPLETED\n        task.result = result\n        task.updated_at = time.time()\n        \n        # 将执行结果添加到记忆\n        self.add_memory(\n            content=f\"执行任务：{task.description}\\n结果：{result}\",\n            importance=0.7,\n            tags=[\"task_execution\", task_id],\n            metadata={\"task_id\": task_id, \"timestamp\": time.time()}\n        )\n        \n        logger.info(f\"Task {task_id} completed\")\n        return result\n    \n    def reflect(self) -> str:\n        \"\"\"\n        自我反思，分析最近的执行并改进\n        \n        Returns:\n            反思结果\n        \"\"\"\n        # 获取最近完成的任务\n        recent_tasks = [\n            task for task in self.tasks.values() \n            if task.status == TaskStatus.COMPLETED and \n               time.time() - task.updated_at < 3600  # 最近1小时\n        ]\n        \n        if not recent_tasks:\n            return \"没有最近完成的任务可供反思\"\n        \n        task_summaries = []\n        for task in recent_tasks[:3]:  # 最多分析3个任务\n            task_summaries.append(f\"任务：{task.description}\\n结果：{task.result[:200]}...\")\n        \n        prompt = f\"\"\"请分析以下最近完成的任务，并提出改进建议：\n        \n        {chr(10).join(task_summaries)}\n        \n        请思考：\n        1. 哪些地方做得好？\n        2. 哪些地方可以改进？\n        3. 有什么可以学习的经验教训？\n        4. 如何优化未来的任务执行？\"\"\"\n        \n        reflection = self.think(prompt)\n        \n        # 将反思结果添加到记忆\n        self.add_memory(\n            content=f\"自我反思：{reflection}\",\n            importance=0.8,\n            tags=[\"reflection\", \"improvement\"],\n            metadata={\"timestamp\": time.time(), \"type\": \"self_reflection\"}\n        )\n        \n        logger.info(\"Self-reflection completed\")\n        return reflection\n    \n    def save_state(self, filepath: str = \"agi_state.json\"):\n        \"\"\"保存AGI状态到文件\"\"\"\n        state = {\n            \"memory\": [asdict(memory) for memory in self.memory.values()],\n            \"tasks\": [asdict(task) for task in self.tasks.values()],\n            \"conversation_history\": self.conversation_history,\n            \"model\": self.model,\n            \"timestamp\": time.time()\n        }\n        \n        with open(filepath, 'w', encoding='utf-8') as f:\n            json.dump(state, f, ensure_ascii=False, indent=2)\n        \n        logger.info(f\"State saved to {filepath}\")\n    \n    def load_state(self, filepath: str = \"agi_state.json\"):\n        \"\"\"从文件加载AGI状态\"\"\"\n        try:\n            with open(filepath, 'r', encoding='utf-8') as f:\n                state = json.load(f)\n            \n            # 加载记忆\n            self.memory.clear()\n            for memory_dict in state.get(\"memory\", []):\n                memory_item = MemoryItem(**memory_dict)\n                self.memory[memory_item.id] = memory_item\n            \n            # 加载任务\n            self.tasks.clear()\n            for task_dict in state.get(\"tasks\", []):\n                # 转换状态字符串为枚举\n                task_dict[\"status\"] = TaskStatus(task_dict[\"status\"])\n                task = Task(**task_dict)\n                self.tasks[task.id] = task\n            \n            # 加载对话历史\n