# agi

```json
{
    "files": [
        {
            "filename": "agi_agent.py",
            "content": "#!/usr/bin/env python3\n\"\"\"\nAGI Agent - 初级工程师实现的基础AGI代理\n\n这个模块实现了一个基于OpenAI API的基础AGI代理，包含对话、任务执行和记忆功能。\n\"\"\"\n\nimport os\nimport json\nimport logging\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\n\nimport openai\nfrom dotenv import load_dotenv\n\n# 加载环境变量\nload_dotenv()\n\n# 配置日志\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n\nclass AGIAgent:\n    \"\"\"基础AGI代理类\"\"\"\n    \n    def __init__(self, model: str = \"gpt-4\", max_history: int = 10):\n        \"\"\"\n        初始化AGI代理\n        \n        Args:\n            model: OpenAI模型名称\n            max_history: 最大对话历史记录数\n        \"\"\"\n        self.model = model\n        self.max_history = max_history\n        self.conversation_history = []\n        self.memory = []\n        \n        # 初始化OpenAI客户端\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        if not api_key:\n            raise ValueError(\"请设置OPENAI_API_KEY环境变量\")\n        \n        self.client = openai.OpenAI(api_key=api_key)\n        logger.info(f\"AGI代理初始化完成，使用模型: {model}\")\n    \n    def add_to_memory(self, content: str, memory_type: str = \"conversation\") -> None:\n        \"\"\"\n        添加记忆\n        \n        Args:\n            content: 记忆内容\n            memory_type: 记忆类型\n        \"\"\"\n        memory_entry = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"content\": content,\n            \"type\": memory_type\n        }\n        self.memory.append(memory_entry)\n        \n        # 限制记忆大小\n        if len(self.memory) > 100:\n            self.memory = self.memory[-100:]\n    \n    def get_relevant_memories(self, query: str, limit: int = 5) -> List[Dict]:\n        \"\"\"\n        获取相关记忆（基础实现）\n        \n        Args:\n            query: 查询内容\n            limit: 返回的记忆数量限制\n            \n        Returns:\n            相关记忆列表\n        \"\"\"\n        # 简单的关键词匹配实现\n        # 在实际项目中可以改为向量搜索\n        query_lower = query.lower()\n        relevant = []\n        \n        for memory in reversed(self.memory):\n            if query_lower in memory[\"content\"].lower():\n                relevant.append(memory)\n                if len(relevant) >= limit:\n                    break\n        \n        return relevant\n    \n    def process_with_llm(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        使用LLM处理消息\n        \n        Args:\n            messages: 消息列表\n            \n        Returns:\n            LLM的回复\n        \"\"\"\n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=messages,\n                temperature=0.7,\n                max_tokens=1000\n            )\n            return response.choices[0].message.content\n        except Exception as e:\n            logger.error(f\"调用OpenAI API失败: {e}\")\n            return \"抱歉，处理请求时出现了错误。\"\n    \n    def think_and_respond(self, user_input: str) -> str:\n        \"\"\"\n        思考并回复用户输入\n        \n        Args:\n            user_input: 用户输入\n            \n        Returns:\n            代理的回复\n        \"\"\"\n        # 1. 添加用户输入到对话历史\n        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n        \n        # 2. 获取相关记忆\n        relevant_memories = self.get_relevant_memories(user_input)\n        \n        # 3. 构建系统提示\n        system_prompt = \"\"\"你是一个AGI（通用人工智能）代理。你的目标是帮助用户解决各种问题，\n        并展现出理解、学习和适应的能力。请基于对话历史和记忆提供有帮助的回答。\n        \n        当前对话历史（最近对话）：\n        {conversation_history}\n        \n        相关记忆：\n        {relevant_memories}\n        \"\"\"\n        \n        # 准备对话历史字符串\n        history_str = \"\\n\".join([\n            f\"{msg['role']}: {msg['content']}\" \n            for msg in self.conversation_history[-self.max_history:]\n        ])\n        \n        # 准备记忆字符串\n        memories_str = \"\\n\".join([\n            f\"[{mem['timestamp']}] {mem['content']}\" \n            for mem in relevant_memories\n        ]) if relevant_memories else \"无相关记忆\"\n        \n        system_prompt = system_prompt.format(\n            conversation_history=history_str,\n            relevant_memories=memories_str\n        )\n        \n        # 4. 构建消息列表\n        messages = [\n            {\"role\": \"system\", \"content\": system_prompt},\n            *self.conversation_history[-self.max_history:]\n        ]\n        \n        # 5. 调用LLM\n        response = self.process_with_llm(messages)\n        \n        # 6. 添加回复到对话历史和记忆\n        self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n        self.add_to_memory(f\"用户: {user_input}\\n助手: {response}\")\n        \n        # 7. 限制对话历史大小\n        if len(self.conversation_history) > self.max_history * 2:\n            self.conversation_history = self.conversation_history[-self.max_history * 2:]\n        \n        logger.info(f\"处理用户输入: {user_input[:50]}...\")\n        return response\n    \n    def execute_task(self, task_description: str) -> Dict[str, Any]:\n        \"\"\"\n        执行任务\n        \n        Args:\n            task_description: 任务描述\n            \n        Returns:\n            任务执行结果\n        \"\"\"\n        logger.info(f\"开始执行任务: {task_description}\")\n        \n        # 任务规划\n        planning_prompt = f\"\"\"你是一个任务执行专家。请将以下任务分解为步骤，并说明如何执行：\n        \n        任务: {task_description}\n        \n        请以JSON格式返回，包含以下字段:\n        1. task_name: 任务名称\n        2. steps: 步骤列表\n        3. expected_output: 预期输出\n        4. difficulty: 任务难度（简单/中等/困难）\n        \"\"\"\n        \n        planning_response = self.process_with_llm([\n            {\"role\": \"system\", \"content\": \"你是一个任务规划专家。\"},\n            {\"role\": \"user\", \"content\": planning_prompt}\n        ])\n        \n        # 尝试解析JSON响应\n        try:\n            task_plan = json.loads(planning_response)\n        except json.JSONDecodeError:\n            # 如果解析失败，创建基础任务计划\n            task_plan = {\n                \"task_name\": task_description[:50],\n                \"steps\": [\"分析任务\", \"执行任务\", \"验证结果\"],\n                \"expected_output\": \"完成任务目标\",\n                \"difficulty\": \"中等\"\n            }\n        \n        # 任务执行\n        execution_prompt = f\"\"\"基于以下任务计划，请执行任务:\n        \n        任务计划: {json.dumps(task_plan, ensure_ascii=False, indent=2)}\n        \n        请提供详细的执行过程和结果。\n        \"\"\"\n        \n        execution_result = self.process_with_llm([\n            {\"role\": \"system\", \"content\": \"你是一个任务执行专家。\"},\n            {\"role\": \"user\", \"content\": execution_prompt}\n        ])\n        \n        # 构建结果\n        result = {\n            \"task_description\": task_description,\n            \"plan\": task_plan,\n            \"execution_result\": execution_result,\n            \"timestamp\": datetime.now().isoformat(),\n            \"status\": \"completed\"\n        }\n        \n        # 添加到记忆\n        self.add_to_memory(\n            f\"任务执行: {task_description}\\n结果: {execution_result[:200]}...\",\n            \"task_execution\"\n        )\n        \n        logger.info(f\"任务执行完成: {task_description[:50]}...\")\n        return result\n    \n    def learn_from_interaction(self, feedback: str) -> str:\n        \"\"\"\n        从交互中学习\n        \n        Args:\n            feedback: 用户反馈\n            \n        Returns:\n            学习结果\n        \"\"\"\n        learning_prompt = f\"\"\"基于以下反馈，请总结你学到了什么，以及如何改进:\n        \n        反馈: {feedback}\n        \n        请以JSON格式返回，包含以下字段:\n        1. key_learnings: 关键学习点列表\n        2. improvements: 改进计划列表\n        3. confidence_change: 信心变化（增加/不变/减少）\n        \"\"\"\n        \n        learning_response = self.process_with_llm([\n            {\"role\": \"system\", \"content\": \"你是一个善于学习和改进的AI助手。\"},\n            {\"role\": \"user\", \"content\": learning_prompt}\n        ])\n        \n        # 尝试解析JSON响应\n        try:\n            learning_result = json.loads(learning_response)\n        except json.JSONDecodeError:\n            learning_result = {\n                \"key_learnings\": [\"理解用户反馈的重要性\"],\n                \"improvements\": [\"更好地理解用户需求\"],\n                \"confidence_change\": \"不变\"\n            }\n        \n        # 添加到记忆\n        self.add_to_memory(\n            f\"学习反馈: {feedback}\\n学习结果: {json.dumps(learning_result)}\",\n            \"learning\"\n        )\n        \n        return f\"已从反馈中学习: {learning_result}\"\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"\n        获取代理状态\n        \n        Returns:\n            代理状态信息\n        \"\"\"\n        return {\n            \"model\": self.model,\n            \"conversation_history_count\": len(self.conversation_history),\n            \"memory_count\": len(self.memory),\n            \"last_interaction\": self.conversation_history[-1][\"content\"] if self.conversation_history else \"无\",\n            \"timestamp\": datetime.now().isoformat()\n        }\n\n\nif __name__ == \"__main__\":\n    \"\"\"示例用法\"\"\"\n    # 创建AGI代理\n    agent = AGIAgent(model=\"gpt-3.5-turbo\", max_history=5)\n    \n    # 测试对话\n    print(\"AGI代理测试对话（输入'退出'结束）:\\n\")\n    \n    while True:\n        user_input = input(\"你: \")\n        if user_input.lower() == '退出':\n            print(\"再见！\")\n            break\n        \n        response = agent.think_and_respond(user_input)\n        print(f\"AGI: {response}\\n\")\n"
        },
        {
            "filename": "requirements.txt",
            "content": "# AGI项目依赖\nopenai>=1.3.0\npython-dotenv>=1.0.0\n"
        },
        {
            "filename": ".env.example",
            "content": "# OpenAI API配置\nOPENAI_API_KEY=your_openai_api_key_here\n\n# 可选的其他配置\n# AGI_MODEL=gpt-4\n# MAX_HISTORY=10\n"
        },
        {
            "filename": "main.py",
            "content": "#!/usr/bin/env python3\n\"\"\"\nAGI主程序 - 初级工程师实现\n\n这个程序展示如何使用AGI代理进行对话、任务执行和学习。\n\"\"\"\n\nimport sys\nimport json\nfrom typing import Dict, Any\n\nfrom agi_agent import AGIAgent\n\n\ndef print_divider(title: str = \"\") -> None:\n    \"\"\"打印分隔线\"\"\"\n    if title:\n        print(f\"\\n{'='*60}\")\n        print(f\"{title.center(60)}\")\n        print(f\"{'='*60}\\n\")\n    else:\n        print(f\"\\n{'='*60}\\n\")\n\n\ndef interactive_mode(agent: AGIAgent) -> None:\n    \"\"\"交互模式\"\"\"\n    print_divider(\"AGI交互模式\")\n    print(\"欢迎使用AGI代理！输入以下命令：\")\n    print(\"  1. '任务 [描述]' - 执行任务\")\n    print(\"  2. '学习 [反馈]' - 从反馈中学习\")\n    print(\"  3. '状态' - 查看代理状态\")\n    print(\"  4. '退出' - 结束程序\")\n    print(\"  其他输入将作为普通对话处理\")\n    print_divider()\n    \n    while True:\n        try:\n            user_input = input(\"你: \").strip()\n            \n            if not user_input:\n                continue\n                \n            if user_input.lower() == '退出':\n                print(\"感谢使用AGI代理！\")\n                break\n                \n            elif user_input.lower() == '状态':\n                status = agent.get_status()\n                print_divider(\"代理状态\")\n                print(json.dumps(status, ensure_ascii=False, indent=2))\n                \n            elif user_input.startswith('任务 '):\n                task_description = user_input[3:].strip()\n                print_divider(\"任务执行\")\n                print(f\"执行任务: {task_description}\")\n                result = agent.execute_task(task_description)\n                print(f\"任务完成！结果:\\n\")\n                print(f\"计划: {result['plan']['task_name']}\")\n                print(f\"执行结果: {result['execution_result'][:200]}...\")\n                \n            elif user_input.startswith('学习 '):\n                feedback = user_input[3:].strip()\n                print_divider(\"学习反馈\")\n                print(f\"学习反馈: {feedback}\")\n                result = agent.learn_from_interaction(feedback)\n                print(f\"学习结果: {result}\")\n                \n            else:\n                # 普通对话\n                response = agent.think_and_respond(user_input)\n                print(f\"AGI: {response}\")\n                \n        except KeyboardInterrupt:\n           