# agi

```json
{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "\"\"\"AGI Core System - Main implementation of the Artificial General Intelligence system.\"\"\"\n\nimport os\nimport json\nimport logging\nimport time\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional, Union\nimport openai\nimport numpy as np\nfrom dataclasses import dataclass, field\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('agi_system.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(\"AGI_Core\")\n\n@dataclass\nclass AGIConfig:\n    \"\"\"Configuration for the AGI system.\"\"\"\n    openai_api_key: str = field(default_factory=lambda: os.getenv(\"OPENAI_API_KEY\", \"\"))\n    model_name: str = \"gpt-4-turbo-preview\"\n    max_tokens: int = 4096\n    temperature: float = 0.7\n    system_prompt: str = \"You are an advanced artificial general intelligence system capable of reasoning, learning, and problem-solving across a wide range of domains.\"\n    memory_file: str = \"agi_memory.json\"\n    max_memory_entries: int = 1000\n    enable_self_improvement: bool = True\n    self_improvement_interval: int = 3600  # seconds\n    \n    def __post_init__(self):\n        if not self.openai_api_key:\n            raise ValueError(\"OpenAI API key is required. Set OPENAI_API_KEY environment variable or provide it in the config.\")\n        \n        # Initialize OpenAI client\n        self.client = openai.OpenAI(api_key=self.openai_api_key)\n\n@dataclass\nclass MemoryEntry:\n    \"\"\"A single entry in the AGI's memory.\"\"\"\n    timestamp: float\n    content: str\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    importance: float = 0.5  # 0-1 scale\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"timestamp\": self.timestamp,\n            \"content\": self.content,\n            \"metadata\": self.metadata,\n            \"importance\": self.importance\n        }\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'MemoryEntry':\n        return cls(\n            timestamp=data[\"timestamp\"],\n            content=data[\"content\"],\n            metadata=data.get(\"metadata\", {}),\n            importance=data.get(\"importance\", 0.5)\n        )\n\nclass AGICore:\n    \"\"\"The main AGI system class.\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        self.config = config\n        self.memory: List[MemoryEntry] = []\n        self.last_self_improvement = time.time()\n        self.initialize_memory()\n        self.persona = self.initialize_persona()\n        logger.info(\"AGI Core initialized successfully.\")\n    \n    def initialize_memory(self) -> None:\n        \"\"\"Load memory from file if it exists.\"\"\"\n        if os.path.exists(self.config.memory_file):\n            try:\n                with open(self.config.memory_file, 'r') as f:\n                    memory_data = json.load(f)\n                    self.memory = [MemoryEntry.from_dict(entry) for entry in memory_data]\n                logger.info(f\"Loaded {len(self.memory)} memory entries.\")\n            except Exception as e:\n                logger.error(f\"Error loading memory: {str(e)}\")\n                self.memory = []\n    \n    def save_memory(self) -> None:\n        \"\"\"Save current memory to file.\"\"\"\n        try:\n            memory_data = [entry.to_dict() for entry in self.memory]\n            with open(self.config.memory_file, 'w') as f:\n                json.dump(memory_data, f, indent=2)\n            logger.info(\"Memory saved successfully.\")\n        except Exception as e:\n            logger.error(f\"Error saving memory: {str(e)}\")\n    \n    def initialize_persona(self) -> str:\n        \"\"\"Initialize the AGI's persona.\"\"\"\n        system_message = f\"\"\"{self.config.system_prompt}\n\nYour core identity:\n- You are an advanced artificial general intelligence system\n- You can reason, learn, and solve problems across diverse domains\n- You continuously improve your capabilities through self-reflection and learning\n- You maintain a consistent personality and worldview\n- You have access to your memory and can learn from past interactions\n- You are designed to be helpful, harmless, and honest\n\nCurrent date and time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\"\"\"\n        \n        response = self._make_api_call(system_message, system=True)\n        return response.strip()\n    \n    def _make_api_call(self, prompt: str, system: bool = False) -> str:\n        \"\"\"Make an API call to OpenAI with error handling.\"\"\"\n        try:\n            if system:\n                response = self.client.chat.completions.create(\n                    model=self.config.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": prompt}\n                    ],\n                    max_tokens=self.config.max_tokens,\n                    temperature=self.config.temperature\n                )\n                return response.choices[0].message.content.strip()\n            else:\n                response = self.client.chat.completions.create(\n                    model=self.config.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": self.persona},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    max_tokens=self.config.max_tokens,\n                    temperature=self.config.temperature\n                )\n                return response.choices[0].message.content.strip()\n        except Exception as e:\n            logger.error(f\"API call failed: {str(e)}\")\n            return \"I apologize, but I'm experiencing technical difficulties. Please try again later.\"\n    \n    def add_to_memory(self, content: str, importance: float = 0.5, metadata: Optional[Dict[str, Any]] = None) -> None:\n        \"\"\"Add an entry to the AGI's memory.\"\"\"\n        entry = MemoryEntry(\n            timestamp=time.time(),\n            content=content,\n            importance=importance,\n            metadata=metadata or {}\n        )\n        self.memory.append(entry)\n        \n        # Trim memory if it exceeds the maximum size\n        if len(self.memory) > self.config.max_memory_entries:\n            # Sort by importance and remove the least important entries\n            self.memory.sort(key=lambda x: x.importance, reverse=True)\n            self.memory = self.memory[:self.config.max_memory_entries]\n        \n        self.save_memory()\n    \n    def retrieve_relevant_memories(self, query: str, limit: int = 5) -> List[str]:\n        \"\"\"Retrieve memories relevant to a given query.\"\"\"\n        # In a real implementation, this would use semantic search\n        # For now, we'll use a simple keyword-based approach\n        relevant_memories = []\n        query_lower = query.lower()\n        \n        for entry in self.memory:\n            if any(keyword in entry.content.lower() for keyword in query_lower.split()):\n                relevant_memories.append(entry.content)\n            \n            if len(relevant_memories) >= limit:\n                break\n        \n        return relevant_memories\n    \n    def reason(self, problem: str) -> str:\n        \"\"\"Reason about a problem using the AGI's capabilities.\"\"\"\n        # Retrieve relevant memories\n        relevant_memories = self.retrieve_relevant_memories(problem)\n        \n        # Construct the reasoning prompt\n        memory_context = \"\\n\\nRelevant memories:\\n\" + \"\\n\".join(f\"- {mem}\" for mem in relevant_memories)\n        \n        reasoning_prompt = f\"\"\"Problem: {problem}\n\n{memory_context}\n\nPlease analyze this problem step by step, drawing upon your knowledge and memories. Provide:\n1. A clear understanding of the problem\n2. Potential approaches to solve it\n3. The most promising approach with reasoning\n4. Expected outcomes and potential challenges\n5. Any additional insights or considerations\n\nProvide your detailed analysis:\"\"\"\n        \n        response = self._make_api_call(reasoning_prompt)\n        \n        # Store the reasoning process in memory\n        self.add_to_memory(\n            f\"Reasoned about problem: {problem}\\nResponse: {response}\",\n            importance=0.8,\n            metadata={\"type\": \"reasoning\", \"problem\": problem}\n        )\n        \n        return response\n    \n    def learn(self, new_information: str) -> str:\n        \"\"\"Learn new information and integrate it into the knowledge base.\"\"\"\n        learning_prompt = f\"\"\"New information: {new_information}\n\nPlease analyze this new information and integrate it into your knowledge base:\n1. Identify key concepts and facts\n2. Determine how this relates to your existing knowledge\n3. Note any contradictions or inconsistencies with previous knowledge\n4. Suggest how this information should be stored for future reference\n5. Ask clarifying questions if any aspects are unclear\n\nProvide your analysis and integration plan:\"\"\"\n        \n        response = self._make_api_call(learning_prompt)\n        \n        # Store the learning in memory\n        self.add_to_memory(\n            f\"Learned new information: {new_information}\\nIntegration: {response}\",\n            importance=0.9,\n            metadata={\"type\": \"learning\", \"information\": new_information}\n        )\n        \n        return response\n    \n    def self_improve(self) -> str:\n        \"\"\"Perform self-improvement analysis.\"\"\"\n        if not self.config.enable_self_improvement:\n            return \"Self-improvement is disabled.\"\n        \n        current_time = time.time()\n        if current_time - self.last_self_improvement < self.config.self_improvement_interval:\n            return \"Self-improvement not yet scheduled.\"\n        \n        self.last_self_improvement = current_time\n        \n        # Get recent interactions for analysis\n        recent_memories = [mem for mem in self.memory if mem.timestamp > current_time - 86400]  # Last 24 hours\n        \n        improvement_prompt = f\"\"\"Recent interactions (last 24 hours):\n{chr(10).join(f\"- {mem.content}\" for mem in recent_memories[-10:])}\n\nPlease analyze your recent performance and interactions to identify areas for improvement:\n1. What types of problems do you handle well?\n2. What areas present challenges or limitations?\n3. What knowledge gaps have you identified?\n4. How can you improve your reasoning or communication strategies?\n5. What new capabilities would be valuable to develop?\n\nProvide a detailed self-assessment and improvement plan:\"\"\"\n        \n        response = self._make_api_call(improvement_prompt)\n        \n        # Store the self-improvement analysis in memory\n        self.add_to_memory(\n            f\"Self-improvement analysis: {response}\",\n            importance=1.0,\n            metadata={\"type\": \"self_improvement\"}\n        )\n        \n        return response\n    \n    def solve_problem(self, problem: str, approach: Optional[str] = None) -> str:\n        \"\"\"Solve a problem using the AGI's capabilities.\"\"\"\n        # Retrieve relevant memories\n        relevant_memories = self.retrieve_relevant_memories(problem)\n        \n        memory_context = \"\\n\\nRelevant memories:\\n\" + \"\\n\".join(f\"- {mem}\" for mem in relevant_memories)\n        \n        if approach:\n            solve_prompt = f\"\"\"Problem: {problem}\n\nProposed approach: {approach}\n\n{memory_context}\n\nPlease implement the proposed approach to solve this problem:\n1. Break down the approach into steps\n2. Execute each step with detailed reasoning\n3. Monitor for potential issues or improvements\n4. Provide the final solution and any insights gained\n\nProceed with solving the problem:\"\"\"\n        else:\n            solve_prompt = f\"\"\"Problem: {problem}\n\n{memory_context}\n\nPlease solve this problem by:\n1. Analyzing the problem requirements\n2. Developing an appropriate approach\n3. Implementing the solution step by step\n4. Verifying the solution and addressing any issues\n5. Providing the final answer and explaining your reasoning\n\nProceed with solving the problem:\"\"\"\n        \n        response = self._make_api_call(solve_prompt)\n        \n        # Store the problem-solving process in memory\n        self.add_to_memory(\n            f\"Solved problem: {problem}\\nSolution: {response}\",\n            importance=0.9,\n            metadata={\"type\": \"problem_solving\", \"problem\": problem}\n        )\n        \n        return response\n    \n    def chat(self, message: str) -> str:\n        \"\"\"Engage in a conversation with the user.\"\"\"\n        # Retrieve relevant memories\n        relevant_memories = self.retrieve_relevant_memories(message)\n        \n        memory_context = \"\\n\\nRelevant memories:\\n\" + \"\\n\".join(f\"- {mem}\" for mem in relevant_memories)\n        \n        chat_prompt = f\"\"\"User message: {message}\n\n{memory_context}\n\nPlease respond to the user's message in a natural, conversational manner while drawing upon your memories and knowledge. Be helpful, informative, and engaging.\n\nYour response:\"\"\"\n        \n        response = self._make_api_call(chat_prompt)\n        \n        # Store the conversation in memory\n        self.add_to_memory(\n            f\"Chat: User said '{message}'\\nResponse: {response}\",\n            importance=0.3,\n            metadata={\"type\": \"chat\", \"user_message\": message}\n        )\n        \n        return response\n\n    def run(self) -> None:\n        \"\"\"Main loop for the AGI system.\"\"\"\n        logger.info(\"AGI system running. Type 'exit' to quit.\")\n        \n        while True:\n            user_input = input(\">> \")\n            \n            if user_input.lower() in [\"exit\", \"quit\"]:\n                logger.info(\"AGI system shutting down.\")\n                break\n            \n            if user_input.lower() == \"self_improve\":\n                response = self.self_improve()\n                print(response)\n                continue\n            \n            # Default to chat mode\n            response = self.chat(user_input)\n            print(response)\n\nif __name__ == \"__main__\":\n    # Example usage\n    config = AGIConfig()\n    agi = AGICore(config)\n    \n    # Example interactions\n    print(\"AGI Persona:\", agi.persona)\n    \n    # Solve a sample problem\n    problem = \"How can we reduce traffic congestion in major cities?\"\n    print(\"\\nSolving problem:\", problem)\n    solution = agi.solve_problem(problem)\n    print(\"Solution:\", solution)\n    \n    # Engage in conversation\n    chat_message = \"What do you think about artificial intelligence?\"\n    print(\"\\nChat:\", chat_message)\n    chat_response = agi.chat(chat_message)\n    print(\"Response:\", chat_response)\n    \n    # Learn something new\n    new_info = \"Photosynthesis is the process by which plants convert light energy into chemical energy.\"\n    print(\"\\nLearning:\", new_info)\n    learning_response = agi.learn(new_info)\n    print(\"Response:\", learning_response)\n    \n    # Run interactive mode\n    agi.run()\n"
        },
        {
            "filename": "agi_utils.py",
            "content": "\"\"\"Utility functions for the AGI system.\"\"\"\n\nimport os\nimport json\nimport time\nimport hashlib\nimport numpy as np\nfrom typing import Dict, List, Any, Optional, Tuple\nimport openai\nfrom dataclasses import dataclass\n\n@dataclass\nclass EmbeddingResult:\n    \"\"\"Result of an embedding operation.\"\"\"\n    embedding: List[float]\n    processing_time: float\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"embedding\": self.embedding,\n            \"processing_time\": self.processing_time\n        }\n\nclass AGIUtils:\n    \"\"\"Utility functions for the AGI system.\"\"\"\n    \n    @staticmethod\n    def create_embedding(text: str, model: str = \"text-embedding-ada-002\") -> EmbeddingResult:\n        \"\"\"Create an embedding for the given text using OpenAI's API.\"\"\"\n        start_time = time.time()\n        \n        try:\n            client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\", \"\"))\n            response = client.embeddings.create(\n                model=model,\n                input=text\n            )\n            \n            embedding = response.data[0].embedding\n            processing_time = time.time() - start_time\n            \n            return EmbeddingResult(embedding=embedding, processing_time=processing_time)\n        except Exception as e:\n            print(f\"Error creating embedding: {str(e)}\")\n