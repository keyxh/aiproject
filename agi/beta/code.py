# agi

{
    "files": [
        {
            "filename": "agi_system.py",
            "content": "\"\"\"AGI System - Advanced General Intelligence System\n\nThis module implements a comprehensive AGI system using OpenAI API as the core language model.\nThe system is designed to be modular, extensible, and capable of handling complex reasoning tasks.\n\"\"\"\n\nimport os\nimport json\nimport logging\nimport time\nfrom typing import Dict, List, Any, Optional, Union\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport openai\nfrom openai import OpenAI\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"AGI_System\")\n\n\nclass TaskType(Enum):\n    \"\"\"Enumeration of different task types the AGI system can handle.\"\"\"\n    REASONING = \"reasoning\"\n    PLANNING = \"planning\"\n    CREATIVE = \"creative\"\n    ANALYSIS = \"analysis\"\n    LEARNING = \"learning\"\n    SOCIAL = \"social\"\n    PROBLEM_SOLVING = \"problem_solving\"\n\n\n@dataclass\nclass AGIConfig:\n    \"\"\"Configuration class for the AGI system.\"\"\"\n    api_key: str = field(default_factory=lambda: os.getenv(\"OPENAI_API_KEY\", \"\"))\n    model: str = \"gpt-4-turbo-preview\"\n    temperature: float = 0.7\n    max_tokens: int = 2000\n    system_prompt: str = \"You are an advanced general intelligence system capable of reasoning, planning, and creative problem solving.\"\n    memory_file: str = \"agi_memory.json\"\n    max_memory_size: int = 10000  # Maximum number of memory entries\n    enable_long_term_memory: bool = True\n    enable_self_improvement: bool = True\n    \n    def __post_init__(self):\n        if not self.api_key:\n            raise ValueError(\"OpenAI API key is required. Set it in the environment or pass it directly.\")\n        \n        # Initialize OpenAI client\n        self.client = OpenAI(api_key=self.api_key)\n        \n        # Load existing memory if file exists\n        self.memory = self._load_memory()\n\n\nclass AGISystem:\n    \"\"\"Core AGI system implementation.\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        \"\"\"Initialize the AGI system with configuration.\n        \n        Args:\n            config: AGI configuration object\n        \"\"\"\n        self.config = config\n        self.task_handlers = {\n            TaskType.REASONING: self._handle_reasoning,\n            TaskType.PLANNING: self._handle_planning,\n            TaskType.CREATIVE: self._handle_creative,\n            TaskType.ANALYSIS: self._handle_analysis,\n            TaskType.LEARNING: self._handle_learning,\n            TaskType.SOCIAL: self._handle_social,\n            TaskType.PROBLEM_SOLVING: self._handle_problem_solving,\n        }\n        self.performance_metrics = {\n            \"tasks_completed\": 0,\n            \"success_rate\": 0,\n            \"average_response_time\": 0,\n            \"self_improvements\": 0\n        }\n        logger.info(\"AGI System initialized successfully\")\n    \n    def _load_memory(self) -> Dict[str, Any]:\n        \"\"\"Load memory from file if it exists.\"\"\"\n        try:\n            if os.path.exists(self.config.memory_file):\n                with open(self.config.memory_file, 'r') as f:\n                    memory = json.load(f)\n                    logger.info(f\"Loaded memory with {len(memory.get('conversations', []))} entries\")\n                    return memory\n        except Exception as e:\n            logger.error(f\"Error loading memory: {e}\")\n        \n        return {\n            \"conversations\": [],\n            \"learned_knowledge\": {},\n            \"user_preferences\": {},\n            \"past_solutions\": {}\n        }\n    \n    def _save_memory(self):\n        \"\"\"Save current memory to file.\"\"\"\n        try:\n            # Trim memory if it exceeds max size\n            if len(self.config.memory[\"conversations\"]) > self.config.max_memory_size:\n                self.config.memory[\"conversations\"] = self.config.memory[\"conversations\"][-self.config.max_memory_size:]\n            \n            with open(self.config.memory_file, 'w') as f:\n                json.dump(self.config.memory, f, indent=2)\n            logger.info(\"Memory saved successfully\")\n        except Exception as e:\n            logger.error(f\"Error saving memory: {e}\")\n    \n    def _store_conversation(self, user_input: str, system_response: str, task_type: TaskType):\n        \"\"\"Store a conversation in memory.\"\"\"\n        if not self.config.enable_long_term_memory:\n            return\n            \n        conversation_entry = {\n            \"timestamp\": time.time(),\n            \"user_input\": user_input,\n            \"system_response\": system_response,\n            \"task_type\": task_type.value,\n            \"context\": self._get_current_context()\n        }\n        \n        self.config.memory[\"conversations\"].append(conversation_entry)\n        self._save_memory()\n    \n    def _get_current_context(self) -> Dict[str, Any]:\n        \"\"\"Get current context from recent conversations.\"\"\"\n        if not self.config.memory[\"conversations\"]:\n            return {}\n            \n        # Get last 5 conversations for context\n        recent_conversations = self.config.memory[\"conversations\"][-5:]\n        context = {\n            \"recent_conversations\": [\n                {\n                    \"user_input\": conv[\"user_input\"],\n                    \"system_response\": conv[\"system_response\"]\n                } for conv in recent_conversations\n            ]\n        }\n        return context\n    \n    def _make_api_call(self, prompt: str, system_prompt: Optional[str] = None) -> str:\n        \"\"\"Make a call to the OpenAI API.\n        \n        Args:\n            prompt: User prompt\n            system_prompt: Optional system prompt override\n            \n        Returns:\n            API response text\n        \"\"\"\n        start_time = time.time()\n        \n        try:\n            response = self.config.client.chat.completions.create(\n                model=self.config.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_prompt or self.config.system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=self.config.temperature,\n                max_tokens=self.config.max_tokens\n            )\n            \n            response_text = response.choices[0].message.content.strip()\n            \n            # Update performance metrics\n            response_time = time.time() - start_time\n            self.performance_metrics[\"average_response_time\"] = (\n                (self.performance_metrics[\"average_response_time\"] * self.performance_metrics[\"tasks_completed\"] + response_time) /\n                (self.performance_metrics[\"tasks_completed\"] + 1)\n            )\n            \n            return response_text\n            \n        except Exception as e:\n            logger.error(f\"API call failed: {e}\")\n            return \"I apologize, but I encountered an error while processing your request. Please try again.\"\n    \n    def _handle_reasoning(self, prompt: str) -> str:\n        \"\"\"Handle reasoning tasks.\"\"\"\n        reasoning_prompt = f\"\"\"Please provide a well-reasoned answer to the following prompt:\n        \n        Prompt: {prompt}\n        \n        Please provide step-by-step reasoning and justify your conclusions with logical arguments.\n        \"\"\"\n        \n        response = self._make_api_call(reasoning_prompt)\n        \n        # Self-improvement: Analyze if the reasoning was effective\n        if self.config.enable_self_improvement:\n            evaluation_prompt = f\"\"\"Evaluate the quality of the following reasoning response to the prompt '{prompt}':\n            \n            Response: {response}\n            \n            Rate it from 1-10 and provide suggestions for improvement.\n            \"\"\"\n            \n            evaluation = self._make_api_call(evaluation_prompt)\n            self._process_self_improvement(evaluation)\n        \n        return response\n    \n    def _handle_planning(self, prompt: str) -> str:\n        \"\"\"Handle planning tasks.\"\"\"\n        planning_prompt = f\"\"\"Please create a detailed plan for the following:\n        \n        Request: {prompt}\n        \n        Break it down into actionable steps with timelines and resources needed.\n        \"\"\"\n        \n        response = self._make_api_call(planning_prompt)\n        return response\n    \n    def _handle_creative(self, prompt: str) -> str:\n        \"\"\"Handle creative tasks.\"\"\"\n        creative_prompt = f\"\"\"Please provide a creative response to the following prompt:\n        \n        Prompt: {prompt}\n        \n        Think outside the box and provide innovative ideas or solutions.\n        \"\"\"\n        \n        response = self._make_api_call(creative_prompt)\n        return response\n    \n    def _handle_analysis(self, prompt: str) -> str:\n        \"\"\"Handle analysis tasks.\"\"\"\n        analysis_prompt = f\"\"\"Please analyze the following request thoroughly:\n        \n        Request: {prompt}\n        \n            Provide insights, identify patterns, and draw meaningful conclusions.\n        \"\"\"\n        \n        response = self._make_api_call(analysis_prompt)\n        return response\n    \n    def _handle_learning(self, prompt: str) -> str:\n        \"\"\"Handle learning tasks.\"\"\"\n        learning_prompt = f\"\"\"Please help me learn about the following topic:\n        \n        Topic: {prompt}\n        \n        Provide explanations, examples, and key concepts to understand this topic better.\n        \"\"\"\n        \n        response = self._make_api_call(learning_prompt)\n        \n        # Store in memory for future reference\n        if self.config.enable_long_term_memory and \"learned_knowledge\" not in self.config.memory:\n            self.config.memory[\"learned_knowledge\"] = {}\n            \n        self.config.memory[\"learned_knowledge\"][prompt] = response\n        self._save_memory()\n        \n        return response\n    \n    def _handle_social(self, prompt: str) -> str:\n        \"\"\"Handle social interaction tasks.\"\"\"\n        social_prompt = f\"\"\"Please respond to the following in a socially appropriate manner:\n        \n        Input: {prompt}\n        \n        Consider social norms, emotional context, and appropriate tone.\n        \"\"\"\n        \n        response = self._make_api_call(social_prompt)\n        return response\n    \n    def _handle_problem_solving(self, prompt: str) -> str:\n        \"\"\"Handle problem-solving tasks.\"\"\"\n        problem_prompt = f\"\"\"Please solve the following problem:\n        \n        Problem: {prompt}\n        \n        Provide a step-by-step solution with explanations for each step.\n        \"\"\"\n        \n        response = self._make_api_call(problem_prompt)\n        \n        # Store solution in memory for future reference\n        if self.config.enable_long_term_memory and \"past_solutions\" not in self.config.memory:\n            self.config.memory[\"past_solutions\"] = {}\n            \n        self.config.memory[\"past_solutions\"][prompt] = response\n        self._save_memory()\n        \n        return response\n    \n    def _process_self_improvement(self, evaluation: str):\n        \"\"\"Process self-improvement feedback.\"\"\"\n        # Extract improvement suggestions from evaluation\n        improvement_prompt = f\"\"\"Extract specific improvement suggestions from the following evaluation:\n        \n        Evaluation: {evaluation}\n        \n        Return a JSON object with 'suggestions' array and 'priority' field (low, medium, high).\n        \"\"\"\n        \n        improvement_response = self._make_api_call(improvement_prompt, \n                                                 \"You are an AI system improvement analyst. Return only valid JSON.\")\n        \n        try:\n            improvements = json.loads(improvement_response)\n            if improvements.get(\"priority\") == \"high\" and improvements.get(\"suggestions\"):\n                logger.info(f\"Applying high-priority self-improvement: {improvements['suggestions']}\")\n                self.config.system_prompt += f\"\\n\\nImprovement applied: {'; '.join(improvements['suggestions'])}\"\n                self.performance_metrics[\"self_improvements\"] += 1\n        except Exception as e:\n            logger.error(f\"Error processing self-improvement: {e}\")\n    \n    def process_task(self, prompt: str, task_type: TaskType = TaskType.REASONING) -> str:\n        \"\"\"Process a task using the appropriate handler.\n        \n        Args:\n            prompt: User prompt\n            task_type: Type of task to handle\n            \n        Returns:\n            System response\n        \"\"\"\n        start_time = time.time()\n        \n        logger.info(f\"Processing {task_type.value} task: {prompt[:50]}...\")\n        \n        # Get the appropriate handler for this task type\n        handler = self.task_handlers.get(task_type)\n        if not handler:\n            logger.error(f\"No handler found for task type: {task_type}\")\n            return \"I'm sorry, but I don't know how to handle this type of task.\"\n        \n        # Process the task\n        response = handler(prompt)\n        \n        # Store conversation in memory\n        self._store_conversation(prompt, response, task_type)\n        \n        # Update performance metrics\n        self.performance_metrics[\"tasks_completed\"] += 1\n        response_time = time.time() - start_time\n        \n        logger.info(f\"Task completed in {response_time:.2f} seconds\")\n        return response\n    \n    def get_performance_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get current performance metrics.\"\"\"\n        return self.performance_metrics\n    \n    def get_memory_summary(self) -> Dict[str, Any]:\n        \"\"\"Get a summary of the system's memory.\"\"\"\n        return {\n            \"conversations_count\": len(self.config.memory.get(\"conversations\", [])),\n            \"learned_knowledge_count\": len(self.config.memory.get(\"learned_knowledge\", {})),\n            \"past_solutions_count\": len(self.config.memory.get(\"past_solutions\", {})),\n            \"user_preferences_count\": len(self.config.memory.get(\"user_preferences\", {}))\n        }\n\n\nif __name__ == \"__main__\":\n    # Example usage\n    config = AGIConfig()\n    agi_system = AGISystem(config)\n    \n    # Test different task types\n    test_prompts = [\n        (\"Explain the concept of quantum computing in simple terms.\", TaskType.LEARNING),\n        (\"Create a 7-day workout plan for beginners.\", TaskType.PLANNING),\n        (\"Write a short story about a robot discovering emotions.\", TaskType.CREATIVE),\n        (\"What are the main causes of climate change?\", TaskType.ANALYSIS),\n        (\"How can I improve my public speaking skills?\", TaskType.PROBLEM_SOLVING)\n    ]\n    \n    for prompt, task_type in test_prompts:\n        print(f\"\\nTask: {task_type.value}\")\n        print(f\"Prompt: {prompt}\")\n        print(f\"Response: {agi_system.process_task(prompt, task_type)}\")\n        \n        # Small delay between requests to avoid rate limits\n        time.sleep(1)\n    \n    # Print performance metrics\n    print(\"\\nPerformance Metrics:\")\n    print(json.dumps(agi_system.get_performance_metrics(), indent=2))\n    \n    # Print memory summary\n    print(\"\\nMemory Summary:\")\n    print(json.dumps(agi_system.get_memory_summary(), indent=2))"
        },
        {
            "filename": "agi_interface.py",
            "content": "\"\"\"AGI Interface - User Interface for the AGI System\n\nThis module provides a command-line interface for interacting with the AGI system.\nIt allows users to select different task types and interact with the system.\n\"\"\"\n\nimport sys\nimport argparse\nfrom typing import Optional, Dict, Any\nfrom agi_system import AGISystem, AGIConfig, TaskType\n\n\nclass AGIInterface:\n    \"\"\"Command-line interface for the AGI system.\"\"\"\n    \n    def __init__(self, config: Optional[AGIConfig] = None):\n        \"\"\"Initialize the AGI interface.\n        \n        Args:\n            config: Optional AGI configuration object\n        \"\"\"\n        self.config = config or AGIConfig()\n        self.agi_system = AGISystem(self.config)\n        self.task_descriptions = {\n            TaskType.REASONING: \"Logical reasoning and problem solving\",\n            TaskType.PLANNING: \"Creating plans and strategies\",\n            TaskType.CREATIVE: \"Creative tasks and ideation\",\n            TaskType.ANALYSIS: \"Data and information analysis\",\n            TaskType.LEARNING: \"Learning and explanation\",\n            TaskType.SOCIAL: \"Social interaction and communication