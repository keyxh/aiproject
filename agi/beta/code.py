# agi

{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "'''\nAGI Core: Implementation of a General Artificial Intelligence system using OpenAI API\n\nThis module provides the foundational architecture for a true AGI system that leverages OpenAI's models\nthrough their API endpoints. The design emphasizes adaptability, self-improvement, and reasoning capabilities.\n'''\n\nimport asyncio\nimport json\nimport logging\nimport time\nfrom typing import Dict, List, Optional, Any, Callable\n\nimport openai\nfrom openai import AsyncOpenAI\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass AGIEngine:\n    \"\"\"\n    A General Artificial Intelligence engine powered by OpenAI API.\n    This class manages core cognitive functions including reasoning, planning,\n    learning, memory, and self-reflection.\n    \"\"\"\n\n    def __init__((\n        self,\n        api_key: str,\n        model_name: str = \"gpt-4o\",\n        max_retries: int = 3,\n        timeout: int = 30,\n        temperature: float = 0.7,\n        top_p: float = 1.0\n    ):\n        \n        # Initialize OpenAI client\n        self.client = AsyncOpenAI(api_key=api_key)\n        self.model_name = model_name\n        self.max_retries = max_retries\n        self.timeout = timeout\n        self.temperature = temperature\n        self.top_p = top_p\n\n        # Internal state\n        self.memory: List[Dict[str, Any]] = []\n        self.knowledge_base: Dict[str, Any] = {}\n        self.planning_stack: List[str] = []\n        self.current_task: Optional[str] = None\n        self.is_active = False\n\n        # Cognitive modules\n        self.reasoning_module = ReasoningModule()\n        self.planning_module = PlanningModule()\n        self.learning_module = LearningModule(self)\n        self.self_reflection_module = SelfReflectionModule()\n\n        logger.info(f\"AGI Engine initialized with model {model_name}\")\n\n    async def start(self) -> None:\n        \"\"\"Initialize the AGI engine and prepare for tasks.\"\"\"\n        self.is_active = True\n        logger.info(\"AGI Engine started\")\n\n    async def stop(self) -> None:\n        \"\"\"Shut down the AGI engine gracefully.\"\"\"\n        self.is_active = False\n        logger.info(\"AGI Engine stopped\")\n\n    async def execute_task(self, task: str, context: Optional[Dict] = None) -> Dict[str, Any]:\n        \"\"\"\n        Execute a high-level task using the AGI's cognitive pipeline.\n\n        Args:\n            task (str): The task to be executed\n            context (dict, optional): Additional context for the task\n\n        Returns:\n            dict: Result containing output, reasoning trace, and metadata\n        \"\"\"\n        if not self.is_active:\n            raise RuntimeError(\"AGI Engine is not running. Call start() first.\")\n\n        logger.info(f\"Executing task: {task}\")\n        self.current_task = task\n\n        # Step 1: Task decomposition and planning\n        plan = await self.planning_module.plan(task, context)\n        logger.debug(f\"Generated plan: {plan}\")\n\n        # Step 2: Execute each step in the plan\n        results = []\n        for step in plan.get(\"steps\", []):\n            step_result = await self._execute_step(step, context)\n            results.append(step_result)\n\n        # Step 3: Synthesize final output\n        final_output = await self._synthesize_results(results)\n\n        # Step 4: Store in memory and learn from experience\n        memory_entry = {\n            \"task\": task,\n            \"plan\": plan,\n            \"results\": results,\n            \"final_output\": final_output,\n            \"timestamp\": time.time(),\n            \"context\": context\n        }\n        self.memory.append(memory_entry)\n        await self.learning_module.learn_from_experience(memory_entry)\n\n        # Step 5: Self-reflection on performance\n        reflection = await self.self_reflection_module.reflect_on_performance(\n            task, results, final_output\n        )\n\n        return {\n            \"task\": task,\n            \"plan\": plan,\n            \"results\": results,\n            \"final_output\": final_output,\n            \"reflection\": reflection,\n            \"metadata\": {\n                \"execution_time\": time.time() - time.time(),\n                \"memory_size\": len(self.memory)\n            }\n        }\n\n    async def _execute_step(self, step: str, context: Optional[Dict] = None) -> Dict[str, Any]:\n        \"\"\"Execute a single step of a plan using the OpenAI API.\"\"\"\n        prompt = f\"{step}\"\n        if context:\n            prompt += f\"\\nContext: {json.dumps(context)}\"\n\n        # Use GPT-4 for complex reasoning steps\n        response = await self._call_openai_api(prompt, model=self.model_name)\n\n        return {\n            \"step\": step,\n            \"input\": prompt,\n            \"output\": response,\n            \"status\": \"completed\"\n        }\n\n    async def _synthesize_results(self, results: List[Dict]) -> str:\n        \"\"\"Synthesize multiple results into a coherent final output.\"\"\"\n        synthesis_prompt = \"\"\"Combine the following results into a single, coherent answer:\\n\"\"\"\n        for i, result in enumerate(results):\n            synthesis_prompt += f\"Step {i+1}: {result['output']}\\n\"\n\n        synthesis_prompt += \"\\nFinal synthesized response:\"\"\n\n        response = await self._call_openai_api(synthesis_prompt, model=self.model_name)\n        return response\n\n    async def _call_openai_api(self, prompt: str, model: str = None) -> str:\n        \"\"\"Call OpenAI API with retry logic and error handling.\"\"\"\n        model = model or self.model_name\n\n        for attempt in range(self.max_retries):\n            try:\n                response = await self.client.chat.completions.create(\n                    model=model,\n                    messages=[{\"role\": \"user\", \"content\": prompt}],\n                    temperature=self.temperature,\n                    top_p=self.top_p,\n                    timeout=self.timeout\n                )\n                return response.choices[0].message.content\n\n            except Exception as e:\n                logger.warning(f\"API call failed (attempt {attempt + 1}): {e}\")\n                if attempt == self.max_retries - 1:\n                    raise RuntimeError(f\"Failed to call OpenAI API after {self.max_retries} attempts\")\n                await asyncio.sleep(2 ** attempt)  # Exponential backoff\n\n        return \"Error: Could not generate response\"\n\n    async def query_knowledge(self, query: str) -> List[Dict]:\n        \"\"\"Query the internal knowledge base for relevant information.\"\"\"\n        # Simple semantic search via LLM\n        search_prompt = f\"Search your knowledge base for information related to: {query}\\nReturn all relevant facts, concepts, or previous experiences.\"\n        response = await self._call_openai_api(search_prompt)\n\n        # Parse response into structured data\n        try:\n            # Assume response contains JSON-like structure\n            return json.loads(response)\n        except json.JSONDecodeError:\n            # Fallback: return as plain text\n            return [{\"text\": response, \"source\": \"internal_knowledge\"}]\n\n    async def update_knowledge(self, key: str, value: Any) -> None:\n        \"\"\"Update or add knowledge to the knowledge base.\"\"\"\n        self.knowledge_base[key] = value\n        logger.info(f\"Knowledge updated: {key}\")\n\n    async def get_status(self) -> Dict[str, Any]:\n        \"\"\"Get current status of the AGI engine.\"\"\"\n        return {\n            \"is_active\": self.is_active,\n            \"current_task\": self.current_task,\n            \"memory_size\": len(self.memory),\n            \"knowledge_size\": len(self.knowledge_base),\n            \"model\": self.model_name\n        }"
        },
        {
            "filename": "modules/reasoning.py",
            "content": "'''\nReasoning Module: Advanced cognitive processing for AGI\n\nThis module implements sophisticated reasoning patterns including logical deduction,\nsymbolic reasoning, analogical thinking, and causal inference.\n'''\n\nfrom typing import List, Dict, Any\nimport asyncio\n\n\nclass ReasoningModule:\n    \"\"\"\n    A reasoning engine that applies various cognitive strategies to solve problems.\n    \"\"\"\n\n    async def deductive_reasoning(self, premises: List[str], conclusion: str) -> Dict[str, Any]:\n        \"\"\"\n        Perform deductive reasoning: given premises, verify if conclusion logically follows.\n\n        Args:\n            premises (list): List of premise statements\n            conclusion (str): The conclusion to evaluate\n\n        Returns:\n            dict: Evaluation result with confidence score\n        \"\"\"\n        prompt = f\"Given the following premises:\\n\"\n        for p in premises:\n            prompt += f\"- {p}\\n\"\n        prompt += f\"Does the conclusion '{conclusion}' logically follow? Answer only 'Yes' or 'No'.\"\n\n        response = await self._call_openai_api(prompt)\n        confidence = 0.9 if \"yes\" in response.lower() else 0.1\n\n        return {\n            \"type\": \"deductive\",\n            \"premises\": premises,\n            \"conclusion\": conclusion,\n            \"valid\": \"yes\" in response.lower(),\n            \"confidence\": confidence,\n            \"explanation\": response\n        }\n\n    async def analogical_reasoning(self, source: str, target: str) -> Dict[str, Any]:\n        \"\"\"\n        Find analogies between two domains or concepts.\n\n        Args:\n            source (str): Source domain/concept\n            target (str): Target domain/concept\n\n        Returns:\n            dict: Analogy mapping and explanation\n        \"\"\"\n        prompt = f\"Find an analogy between '{source}' and '{target}'. Describe how they are similar and what insights can be drawn.\"\n\n        response = await self._call_openai_api(prompt)\n\n        return {\n            \"type\": \"analogical\",\n            \"source\": source,\n            \"target\": target,\n            \"analogy\": response,\n            \"insights\": self._extract_insights(response)\n        }\n\n    async def causal_inference(self, event_sequence: List[str]) -> Dict[str, Any]:\n        \"\"\"\n        Infer causal relationships from a sequence of events.\n\n        Args:\n            event_sequence (list): Sequence of events\n\n        Returns:\n            dict: Causal chain and confidence scores\n        \"\"\"\n        prompt = f\"Analyze the following sequence of events and identify causal relationships:\\n\"\n        for i, event in enumerate(event_sequence):\n            prompt += f\"{i+1}. {event}\\n\"\n        prompt += \"\\nIdentify which events cause others and provide confidence levels (0-1).\"\n\n        response = await self._call_openai_api(prompt)\n\n        return {\n            \"type\": \"causal\",\n            \"events\": event_sequence,\n            \"causal_chain\": response,\n            \"confidence_scores\": self._parse_confidence_scores(response)\n        }\n\n    def _extract_insights(self, text: str) -> List[str]:\n        \"\"\"Extract key insights from reasoning text.\"\"\"\n        # Simple heuristic: split by sentence and filter meaningful ones\n        sentences = [s.strip() for s in text.split('.') if s.strip()]\n        insights = []\n        for sent in sentences:\n            if any(word in sent.lower() for word in ['thus', 'therefore', 'hence', 'insight', 'lesson']):\n                insights.append(sent)\n        return insights[:3]  # Return top 3 insights\n\n    def _parse_confidence_scores(self, text: str) -> Dict[str, float]:\n        \"\"\"Parse confidence scores from text.\"\"\"\n        # Extract numbers followed by % or decimals\n        import re\n        matches = re.findall(r'(?:\\d+\\.?\\d*|\\d+)%?', text)\n        scores = {}\n        for match in matches:\n            try:\n                val = float(match.replace('%', '')) / 100 if '%' in match else float(match)\n                scores[f\"score_{len(scores)+1}\" ] = min(max(val, 0.0), 1.0)\n            except:\n                continue\n        return scores if scores else {\"default\": 0.5}\n\n    async def _call_openai_api(self, prompt: str) -> str:\n        \"\"\"Placeholder method for external API calls - should be implemented in parent class.\"\"\"\n        # This would be replaced with actual API call in the main AGIEngine\n        return \"Sample reasoning response\"\n\n    async def perform_complex_reasoning(self, problem: str, constraints: List[str] = None) -> Dict[str, Any]:\n        \"\"\"\n        Perform multi-step complex reasoning combining different strategies.\n\n        Args:\n            problem (str): The problem to solve\n            constraints (list): Constraints or limitations\n\n        Returns:\n            dict: Comprehensive reasoning analysis\n        \"\"\"\n        if not constraints:\n            constraints = []\n\n        # Generate a reasoning plan\n        plan_prompt = f\"Break down the following problem into logical steps: {problem}\\nConstraints: {', '.join(constraints)}\"\n        plan_response = await self._call_openai_api(plan_prompt)\n\n        # Apply different reasoning types\n        reasoning_steps = [\n            await self.deductive_reasoning([problem], \"Solution exists\"),\n            await self.analogical_reasoning(problem, \"similar known problem\"),\n            await self.causal_inference([f\"Problem: {problem}\", f\"Possible solution: {plan_response}\"])\n        ]\n\n        return {\n            \"problem\": problem,\n            \"constraints\": constraints,\n            \"reasoning_plan\": plan_response,\n            \"reasoning_steps\": reasoning_steps,\n            \"synthesis\": \"Combining insights from multiple reasoning types to form a comprehensive solution\"\n        }"
        },
        {
            "filename": "modules/planning.py",
            "content": "'''\nPlanning Module: Strategic task decomposition and execution planning\n\nThis module handles goal-oriented planning, breaking down complex tasks into actionable steps\nwith consideration for dependencies, resources, and potential obstacles.\n'''\n\nfrom typing import List, Dict, Any\nimport asyncio\nimport json\n\n\nclass PlanningModule:\n    \"\"\"\n    A strategic planning engine that decomposes high-level goals into executable plans.\n    \"\"\"\n\n    async def plan(self, goal: str, context: Dict[str, Any] = None) -> Dict[str, Any]:\n        \"\"\"\n        Create a detailed action plan for achieving a given goal.\n\n        Args:\n            goal (str): The high-level objective\n            context (dict): Contextual information about the environment\n\n        Returns:\n            dict: Detailed plan with steps, dependencies, and estimated resources\n        \"\"\"\n        prompt = f\"Create a detailed plan to achieve the following goal: {goal}\\n\"\n        if context:\n            prompt += f\"Context: {json.dumps(context)}\\n\"\n        prompt += \"\\nBreak this down into specific, sequential steps with clear objectives. Include dependencies between steps and required resources. Format as JSON with keys: 'goal', 'steps', 'dependencies', 'resources', 'estimated_time', 'risk_assessment'.\"\n\n        response = await self._call_openai_api(prompt)\n\n        # Parse the response\n        try:\n            plan_data = json.loads(response)\n            # Ensure required keys exist\n            if \"steps\" not in plan_data:\n                plan_data[\"steps\"] = []\n            if \"dependencies\" not in plan_data:\n                plan_data[\"dependencies\"] = {}\n            if \"resources\" not in plan_data:\n                plan_data[\"resources\"] = []\n            if \"estimated_time\" not in plan_data:\n                plan_data[\"estimated_time\"] = \"unknown\"\n            if \"risk_assessment\" not in plan_data:\n                plan_data[\"risk_assessment\"] = []\n\n            return plan_data\n        except json.JSONDecodeError:\n            # Fallback: create a simple plan\n            return {\n                \"goal\": goal,\n                \"steps\": [f\"Begin working on {goal}\"],\n                \"dependencies\": {},\n                \"resources\": [],\n                \"estimated_time\": \"unknown\",\n                \"risk_assessment\": [\"Unclear risks due to incomplete analysis\"]\n            }\n\n    async def revise_plan(self, original_plan: Dict[str, Any], feedback: str) -> Dict[str, Any]:\n        \"\"\"\n        Revise an existing plan based on feedback.\n\n        Args:\n            original_plan (dict): The original plan\n            feedback (str): Feedback on the plan\n\n        Returns:\n            dict: Revised plan\n        \"\"\"\n        prompt = f\"Revise the following plan based on this feedback: {feedback}\\nOriginal plan: {json.dumps(original_plan)}\\nMake improvements while maintaining feasibility. Output revised plan in JSON format.\"\n\n        response = await self._call_openai_api(prompt)\n\n        try:\n            return json.loads(response)\n        except json.JSONDecodeError:\n            # If parsing fails, return original plan with feedback\n            return {**original_plan, \"re