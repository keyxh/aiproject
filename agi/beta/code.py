# agi

```json
{
    "files": [
        {
            "filename": "agi_system.py",
            "content": "\"\"\"\nAGI (Artificial General Intelligence) System\n\nThis module implements a framework for building an AGI system using OpenAI's API.\nIt provides a modular architecture with different components working together to achieve general intelligence.\n\"\"\"\n\nimport os\nimport json\nimport time\nimport logging\nfrom typing import Dict, List, Any, Optional, Union\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport openai\nfrom openai import OpenAI\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"AGI_System\")\n\n\nclass CognitiveProcess(Enum):\n    \"\"\"Enum representing different cognitive processes in AGI\"\"\"\n    PERCEPTION = \"perception\"\n    REASONING = \"reasoning\"\n    LEARNING = \"learning\"\n    MEMORY = \"memory\"\n    PLANNING = \"planning\"\n    ACTION = \"action\"\n    SELF_AWARENESS = \"self_awareness\"\n\n\n@dataclass\nclass AGIConfig:\n    \"\"\"Configuration for the AGI system\"\"\"\n    openai_api_key: str = field(default_factory=lambda: os.getenv(\"OPENAI_API_KEY\"))\n    model_name: str = \"gpt-4-turbo\"\n    max_tokens: int = 4096\n    temperature: float = 0.7\n    system_prompt: str = \"You are an AGI system with general intelligence capabilities.\"\n    memory_file: str = \"agi_memory.json\"\n    enable_self_reflection: bool = True\n    max_reflection_depth: int = 3\n    \n    def __post_init__(self):\n        if not self.openai_api_key:\n            raise ValueError(\"OpenAI API key must be provided either directly or through OPENAI_API_KEY environment variable\")\n\n\nclass AGIMemory:\n    \"\"\"Memory system for the AGI\"\"\"\n    \n    def __init__(self, memory_file: str, max_size: int = 1000):\n        self.memory_file = memory_file\n        self.max_size = max_size\n        self.short_term_memory: List[Dict[str, Any]] = []\n        self.long_term_memory: Dict[str, Any] = {}\n        self.load_memory()\n    \n    def load_memory(self) -> None:\n        \"\"\"Load memory from file\"\"\"\n        try:\n            with open(self.memory_file, 'r') as f:\n                data = json.load(f)\n                self.short_term_memory = data.get('short_term', [])\n                self.long_term_memory = data.get('long_term', {})\n            logger.info(\"Memory loaded successfully\")\n        except FileNotFoundError:\n            logger.info(\"No existing memory file found, starting with empty memory\")\n        except json.JSONDecodeError:\n            logger.error(\"Error decoding memory file, starting with empty memory\")\n    \n    def save_memory(self) -> None:\n        \"\"\"Save memory to file\"\"\"\n        data = {\n            'short_term': self.short_term_memory,\n            'long_term': self.long_term_memory\n        }\n        with open(self.memory_file, 'w') as f:\n            json.dump(data, f, indent=2)\n        logger.info(\"Memory saved successfully\")\n    \n    def add_to_short_term(self, entry: Dict[str, Any]) -> None:\n        \"\"\"Add an entry to short-term memory\"\"\"\n        self.short_term_memory.append({\n            'timestamp': time.time(),\n            'data': entry\n        })\n        \n        # Keep only the most recent entries\n        if len(self.short_term_memory) > self.max_size:\n            self.short_term_memory = self.short_term_memory[-self.max_size:]\n    \n    def add_to_long_term(self, key: str, value: Any) -> None:\n        \"\"\"Add an entry to long-term memory\"\"\"\n        self.long_term_memory[key] = {\n            'timestamp': time.time(),\n            'data': value\n        }\n    \n    def retrieve_from_memory(self, query: str, memory_type: str = \"both\") -> Dict[str, Any]:\n        \"\"\"Retrieve relevant information from memory based on query\"\"\"\n        # This is a simplified retrieval mechanism\n        # In a real AGI, this would be much more sophisticated\n        results = {\n            'short_term': [],\n            'long_term': []\n        }\n        \n        if memory_type in ['short_term', 'both']:\n            for entry in self.short_term_memory:\n                if query.lower() in str(entry['data']).lower():\n                    results['short_term'].append(entry)\n        \n        if memory_type in ['long_term', 'both']:\n            for key, entry in self.long_term_memory.items():\n                if query.lower() in str(entry['data']).lower():\n                    results['long_term'].append({'key': key, 'data': entry})\n        \n        return results\n\n\nclass CognitiveModule:\n    \"\"\"Base class for cognitive modules\"\"\"\n    \n    def __init__(self, name: CognitiveProcess, agi_system):\n        self.name = name\n        self.agi_system = agi_system\n        self.client = OpenAI(api_key=agi_system.config.openai_api_key)\n    \n    def process(self, input_data: Any) -> Dict[str, Any]:\n        \"\"\"Process input data and return results\"\"\"\n        raise NotImplementedError(\"Subclasses must implement the process method\")\n    \n    def _call_openai(self, prompt: str, system_prompt: str = None) -> str:\n        \"\"\"Helper method to call OpenAI API\"\"\"\n        try:\n            response = self.client.chat.completions.create(\n                model=self.agi_system.config.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_prompt or self.agi_system.config.system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                max_tokens=self.agi_system.config.max_tokens,\n                temperature=self.agi_system.config.temperature\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            logger.error(f\"Error calling OpenAI API: {e}\")\n            return \"Error processing request.\"\n\n\nclass PerceptionModule(CognitiveModule):\n    \"\"\"Handles perception of the environment and input data\"\"\"\n    \n    def __init__(self, agi_system):\n        super().__init__(CognitiveProcess.PERCEPTION, agi_system)\n    \n    def process(self, input_data: Any) -> Dict[str, Any]:\n        \"\"\"Process raw input data into structured information\"\"\"\n        prompt = f\"Process and interpret the following input data:\\n\\n{input_data}\"\n        \n        # Store in short-term memory\n        self.agi_system.memory.add_to_short_term({\n            'module': self.name.value,\n            'input': input_data,\n            'timestamp': time.time()\n        })\n        \n        # Process with OpenAI\n        interpretation = self._call_openai(prompt)\n        \n        # Store interpretation in memory\n        self.agi_system.memory.add_to_short_term({\n            'module': self.name.value,\n            'interpretation': interpretation,\n            'timestamp': time.time()\n        })\n        \n        return {\n            'interpretation': interpretation,\n            'timestamp': time.time()\n        }\n\n\nclass ReasoningModule(CognitiveModule):\n    \"\"\"Handles logical reasoning and problem solving\"\"\"\n    \n    def __init__(self, agi_system):\n        super().__init__(CognitiveProcess.REASONING, agi_system)\n    \n    def process(self, input_data: Any, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"Process input data using logical reasoning\"\"\"\n        context_str = \"\\n\\nContext:\\n\" + json.dumps(context, indent=2) if context else \"\"\n        prompt = f\"Apply logical reasoning to the following input data:{context_str}\\n\\nInput Data:\\n{input_data}\"\n        \n        # Store in short-term memory\n        self.agi_system.memory.add_to_short_term({\n            'module': self.name.value,\n            'input': input_data,\n            'timestamp': time.time()\n        })\n        \n        # Process with OpenAI\n        reasoning_result = self._call_openai(prompt)\n        \n        # Store reasoning result in memory\n        self.agi_system.memory.add_to_short_term({\n            'module': self.name.value,\n            'reasoning': reasoning_result,\n            'timestamp': time.time()\n        })\n        \n        return {\n            'reasoning': reasoning_result,\n            'timestamp': time.time()\n        }\n\n\nclass LearningModule(CognitiveModule):\n    \"\"\"Handles learning and adaptation\"\"\"\n    \n    def __init__(self, agi_system):\n        super().__init__(CognitiveProcess.LEARNING, agi_system)\n    \n    def process(self, input_data: Any, feedback: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"Process input data to extract learning\"\"\"\n        feedback_str = \"\\n\\nFeedback:\\n\" + json.dumps(feedback, indent=2) if feedback else \"\"\n        prompt = f\"Extract learning from the following input data and any provided feedback:{feedback_str}\\n\\nInput Data:\\n{input_data}\"\n        \n        # Store in short-term memory\n        self.agi_system.memory.add_to_short_term({\n            'module': self.name.value,\n            'input': input_data,\n            'timestamp': time.time()\n        })\n        \n        # Process with OpenAI\n        learning_insights = self._call_openai(prompt)\n        \n        # Store learning insights in long-term memory\n        self.agi_system.memory.add_to_long_term(\n            f\"learning_{int(time.time())}\",\n            {\n                'input': input_data,\n                'insights': learning_insights,\n                'timestamp': time.time()\n            }\n        )\n        \n        return {\n            'learning': learning_insights,\n            'timestamp': time.time()\n        }\n\n\nclass PlanningModule(CognitiveModule):\n    \"\"\"Handles planning and decision making\"\"\"\n    \n    def __init__(self, agi_system):\n        super().__init__(CognitiveProcess.PLANNING, agi_system)\n    \n    def process(self, goal: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"Create a plan to achieve a given goal\"\"\"\n        context_str = \"\\n\\nContext:\\n\" + json.dumps(context, indent=2) if context else \"\"\n        prompt = f\"Create a detailed plan to achieve the following goal:{context_str}\\n\\nGoal:\\n{goal}\"\n        \n        # Store in short-term memory\n        self.agi_system.memory.add_to_short_term({\n            'module': self.name.value,\n            'goal': goal,\n            'timestamp': time.time()\n        })\n        \n        # Process with OpenAI\n        plan = self._call_openai(prompt)\n        \n        # Store plan in memory\n        self.agi_system.memory.add_to_short_term({\n            'module': self.name.value,\n            'plan': plan,\n            'timestamp': time.time()\n        })\n        \n        return {\n            'plan': plan,\n            'timestamp': time.time()\n        }\n\n\nclass SelfAwarenessModule(CognitiveModule):\n    \"\"\"Handles self-awareness and meta-cognition\"\"\"\n    \n    def __init__(self, agi_system):\n        super().__init__(CognitiveProcess.SELF_AWARENESS, agi_system)\n    \n    def process(self, internal_state: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Process internal state to enhance self-awareness\"\"\"\n        prompt = f\"Analyze the following internal state and provide insights about the AGI's current capabilities, limitations, and potential improvements:\\n\\nInternal State:\\n{json.dumps(internal_state, indent=2)}\"\n        \n        # Store in short-term memory\n        self.agi_system.memory.add_to_short_term({\n            'module': self.name.value,\n            'internal_state': internal_state,\n            'timestamp': time.time()\n        })\n        \n        # Process with OpenAI\n        self_analysis = self._call_openai(prompt)\n        \n        # Store self-analysis in memory\n        self.agi_system.memory.add_to_long_term(\n            f\"self_analysis_{int(time.time())}\",\n            {\n                'internal_state': internal_state,\n                'analysis': self_analysis,\n                'timestamp': time.time()\n            }\n        )\n        \n        return {\n            'self_analysis': self_analysis,\n            'timestamp': time.time()\n        }\n\n\nclass AGISystem:\n    \"\"\"Main AGI system class that coordinates all modules\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        self.config = config\n        self.memory = AGIMemory(config.memory_file)\n        self.modules = {\n            CognitiveProcess.PERCEPTION: PerceptionModule(self),\n            CognitiveProcess.REASONING: ReasoningModule(self),\n            CognitiveProcess.LEARNING: LearningModule(self),\n            CognitiveProcess.PLANNING: PlanningModule(self),\n            CognitiveProcess.SELF_AWARENESS: SelfAwarenessModule(self)\n        }\n        self.internal_state = {\n            'active_modules': [],\n            'last_processed_input': None,\n            'performance_metrics': {\n                'processing_time': [],\n                'accuracy': []\n            }\n        }\n    \n    def process_input(self, input_data: Any) -> Dict[str, Any]:\n        \"\"\"Process input through the AGI system\"\"\"\n        start_time = time.time()\n        \n        # Update internal state\n        self.internal_state['last_processed_input'] = input_data\n        self.internal_state['active_modules'] = [CognitiveProcess.PERCEPTION, CognitiveProcess.REASONING]\n        \n        # Step 1: Perception\n        perception_result = self.modules[CognitiveProcess.PERCEPTION].process(input_data)\n        \n        # Step 2: Reasoning\n        reasoning_result = self.modules[CognitiveProcess.REASONING].process(\n            perception_result['interpretation'],\n            {'perception': perception_result}\n        )\n        \n        # Step 3: Planning (if goal is evident)\n        plan_result = None\n        if \"goal\" in str(input_data).lower() or \"objective\" in str(input_data).lower():\n            self.internal_state['active_modules'].append(CognitiveProcess.PLANNING)\n            plan_result = self.modules[CognitiveProcess.PLANNING].process(\n                input_data,\n                {'perception': perception_result, 'reasoning': reasoning_result}\n            )\n        \n        # Step 4: Self-reflection (if enabled)\n        self_analysis_result = None\n        if self.config.enable_self_reflection:\n            self.internal_state['active_modules'].append(CognitiveProcess.SELF_AWARENESS)\n            self_analysis_result = self.modules[CognitiveProcess.SELF_AWARENESS].process(self.internal_state)\n        \n        # Compile final response\n        final_response = self._compile_response(\n            perception_result=perception_result,\n            reasoning_result=reasoning_result,\n            plan_result=plan_result,\n            self_analysis_result=self_analysis_result\n        )\n        \n        # Update performance metrics\n        processing_time = time.time() - start_time\n        self.internal_state['performance_metrics']['processing_time'].append(processing_time)\n        \n        # Save memory\n        self.memory.save_memory()\n        \n        return {\n            'response': final_response,\n            'perception': perception_result,\n            'reasoning': reasoning_result,\n            'plan': plan_result,\n            'self_analysis': self_analysis_result,\n            'processing_time': processing_time,\n            'active_modules': self.internal_state['active_modules'],\n            'timestamp': time.time()\n        }\n    \n    def _compile_response(self, **kwargs) -> str:\n        \"\"\"Compile results from all modules into a coherent response\"\"\"\n        response_parts = []\n        \n        if kwargs.get('perception'):\n            response_parts.append(f\"Perception: {kwargs['perception']['interpretation']}\")\n        \n        if kwargs.get('reasoning'):\n            response_parts.append(f\"Reasoning: {kwargs['reasoning']['reasoning']}\")\n        \n        if kwargs.get('plan'):\n            response_parts.append(f\"Plan: {kwargs['plan']['plan']}\")\n        \n        if kwargs.get('self_analysis'):\n            response_parts.append(f\"Self-Analysis: {kwargs['self_analysis']['self_analysis']}\")\n        \n        return \"\\n\\n\".join(response_parts)\n    \n    def learn_from_feedback(self, feedback: Dict[str, Any]) -> Dict[str, Any]:\n       