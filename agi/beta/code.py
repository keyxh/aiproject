# agi

```json
{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "\"\"\"AGI核心实现模块，整合各种组件实现真正的通用人工智能\"\"\"\n\nimport os\nimport json\nimport time\nimport logging\nfrom typing import Dict, List, Any, Optional, Union\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nimport openai\nfrom openai import OpenAI\n\n# 配置日志\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass AGIConfig:\n    \"\"\"AGI系统配置\"\"\"\n    openai_api_key: str = field(default_factory=lambda: os.getenv(\"OPENAI_API_KEY\"))\n    openai_model: str = \"gpt-4-turbo-preview\"\n    max_tokens: int = 4000\n    temperature: float = 0.7\n    system_prompt: str = \"你是一个真正的人工通用智能(AGI)，能够理解、学习和解决各种问题。\"\n    memory_file: str = \"agi_memory.json\"\n    max_memory_size: int = 1000  # 最大记忆条目数\n    \n    def __post_init__(self):\n        if not self.openai_api_key:\n            raise ValueError(\"OpenAI API key is required. Set OPENAI_API_KEY environment variable or provide it directly.\")\n\n@dataclass\nclass MemoryEntry:\n    \"\"\"记忆条目数据结构\"\"\"\n    id: str\n    content: str\n    timestamp: float\n    importance: float = 1.0  # 0-1之间，重要性分数\n    category: str = \"general\"\n    \nclass AGIMemorySystem:\n    \"\"\"AGI记忆系统，用于存储和检索相关信息\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        self.config = config\n        self.memories: Dict[str, MemoryEntry] = {}\n        self.load_memory()\n    \n    def add_memory(self, content: str, importance: float = 1.0, category: str = \"general\") -> str:\n        \"\"\"添加新记忆\"\"\"\n        memory_id = str(time.time())  # 使用时间戳作为ID\n        entry = MemoryEntry(\n            id=memory_id,\n            content=content,\n            timestamp=time.time(),\n            importance=importance,\n            category=category\n        )\n        \n        # 如果记忆数量超过最大限制，移除最旧的记忆\n        if len(self.memories) >= self.config.max_memory_size:\n            oldest_key = min(self.memories.keys(), key=lambda k: self.memories[k].timestamp)\n            del self.memories[oldest_key]\n        \n        self.memories[memory_id] = entry\n        self.save_memory()\n        return memory_id\n    \n    def retrieve_memories(self, query: str, top_k: int = 5) -> List[MemoryEntry]:\n        \"\"\"检索相关记忆\"\"\"\n        # 这里简化实现，实际应用中可以使用更复杂的向量检索\n        # 按照重要性和相关性排序\n        sorted_memories = sorted(\n            self.memories.values(),\n            key=lambda m: (m.importance, -abs(m.timestamp - time.time())),\n            reverse=True\n        )\n        return sorted_memories[:top_k]\n    \n    def save_memory(self):\n        \"\"\"保存记忆到文件\"\"\"\n        try:\n            with open(self.config.memory_file, 'w') as f:\n                json.dump({k: v.__dict__ for k, v in self.memories.items()}, f)\n        except Exception as e:\n            logger.error(f\"Error saving memory: {e}\")\n    \n    def load_memory(self):\n        \"\"\"从文件加载记忆\"\"\"\n        if os.path.exists(self.config.memory_file):\n            try:\n                with open(self.config.memory_file, 'r') as f:\n                    data = json.load(f)\n                    self.memories = {\n                        k: MemoryEntry(**v) for k, v in data.items()\n                    }\n            except Exception as e:\n                logger.error(f\"Error loading memory: {e}\")\n\nclass AGIReasoningEngine:\n    \"\"\"AGI推理引擎，负责复杂逻辑推理和问题解决\"\"\"\n    \n    def __init__(self, client: OpenAI, config: AGIConfig):\n        self.client = client\n        self.config = config\n    \n    def solve_problem(self, problem: str, context: List[str] = None) -> Dict[str, Any]:\n        \"\"\"解决复杂问题\"\"\"\n        context_str = \"\\n\".join(context) if context else \"\"\n        \n        prompt = f\"\"\"\n        问题: {problem}\n        \n        上下文信息:\n        {context_str}\n        \n        请分析并解决这个问题。提供以下信息:\n        1. 问题分析\n        2. 解决方案\n        3. 推理过程\n        4. 可能的挑战和应对策略\n        \"\"\"\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=self.config.openai_model,\n                messages=[\n                    {\"role\": \"system\", \"content\": self.config.system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                max_tokens=self.config.max_tokens,\n                temperature=self.config.temperature\n            )\n            \n            return {\n                \"problem\": problem,\n                \"solution\": response.choices[0].message.content,\n                \"timestamp\": datetime.now().isoformat(),\n                \"model\": self.config.openai_model\n            }\n        except Exception as e:\n            logger.error(f\"Error in problem solving: {e}\")\n            return {\n                \"problem\": problem,\n                \"error\": str(e),\n                \"timestamp\": datetime.now().isoformat()\n            }\n    \n    def learn_from_interaction(self, interaction: str, feedback: str) -> str:\n        \"\"\"从交互中学习\"\"\"\n        prompt = f\"\"\"\n        交互记录:\n        {interaction}\n        \n        反馈:\n        {feedback}\n        \n        请分析这次交互并提取学习要点，以便未来改进。\n        \"\"\"\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=self.config.openai_model,\n                messages=[\n                    {\"role\": \"system\", \"content\": self.config.system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                max_tokens=self.config.max_tokens,\n                temperature=self.config.temperature\n            )\n            \n            return response.choices[0].message.content\n        except Exception as e:\n            logger.error(f\"Error in learning from interaction: {e}\")\n            return \"\"\n\nclass AGIInterface:\n    \"\"\"AGI用户界面，提供与用户交互的接口\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        self.config = config\n        self.client = OpenAI(api_key=config.openai_api_key)\n        self.memory_system = AGIMemorySystem(config)\n        self.reasoning_engine = AGIReasoningEngine(self.client, config)\n    \n    def process_input(self, user_input: str) -> str:\n        \"\"\"处理用户输入并返回响应\"\"\"\n        # 1. 检索相关记忆\n        relevant_memories = self.memory_system.retrieve_memories(user_input)\n        context = [m.content for m in relevant_memories]\n        \n        # 2. 保存用户输入到记忆\n        self.memory_system.add_memory(f\"User: {user_input}\", importance=0.8)\n        \n        # 3. 处理输入\n        result = self.reasoning_engine.solve_problem(user_input, context)\n        \n        # 4. 保存响应到记忆\n        self.memory_system.add_memory(f\"AGI Response: {result['solution']}\", importance=0.7)\n        \n        return result[\"solution\"]\n    \n    def learn_from_feedback(self, interaction: str, feedback: str):\n        \"\"\"从反馈中学习\"\"\"\n        learning_points = self.reasoning_engine.learn_from_interaction(interaction, feedback)\n        if learning_points:\n            self.memory_system.add_memory(f\"Learning: {learning_points}\", importance=0.9, category=\"learning\")\n            return learning_points\n        return \"\"\n    \n    def get_memory_summary(self) -> Dict[str, Any]:\n        \"\"\"获取记忆系统摘要\"\"\"\n        categories = set(entry.category for entry in self.memory_system.memories.values())\n        return {\n            \"total_memories\": len(self.memory_system.memories),\n            \"categories\": list(categories),\n            \"recent_memories\": [\n                m.content for m in \n                sorted(self.memory_system.memories.values(), key=lambda x: x.timestamp, reverse=True)[:5]\n            ]\n        }\n\nclass AGI:\n    \"\"\"AGI主类，整合所有组件\"\"\"\n    \n    def __init__(self, config: Optional[AGIConfig] = None):\n        self.config = config or AGIConfig()\n        self.interface = AGIInterface(self.config)\n        \n    def run(self):\n        \"\"\"运行AGI系统\"\"\"\n        print(\"AGI系统已启动。输入'exit'退出。\\n\")\n        \n        while True:\n            user_input = input(\"你: \")\n            \n            if user_input.lower() in [\"exit\", \"quit\"]:\n                print(\"再见！\")\n                break\n            \n            response = self.interface.process_input(user_input)\n            print(f\"AGI: {response}\\n\")\n            \n            # 简单的反馈循环\n            feedback = input(\"这个回答有帮助吗？(y/n): \")\n            if feedback.lower() == \"n\":\n                improvement = input(\"请提供反馈: \")\n                if improvement:\n                    self.interface.learn_from_feedback(f\"User: {user_input}\\nAGI: {response}\", improvement)\n                    print(\"感谢您的反馈！我会记住这个。\\n\")\n\nif __name__ == \"__main__\":\n    # 创建并运行AGI系统\n    agi = AGI()\n    agi.run()\n"
        },
        {
            "filename": "agi_utils.py",
            "content": "\"\"\"AGI系统工具函数\"\"\"\n\nimport os\nimport json\nimport hashlib\nfrom typing import Dict, List, Any, Optional\nfrom datetime import datetime\n\ndef load_config(config_path: str = \"agi_config.json\") -> Dict[str, Any]:\n    \"\"\"加载配置文件\"\"\"\n    if os.path.exists(config_path):\n        with open(config_path, 'r') as f:\n            return json.load(f)\n    return {}\n\ndef save_config(config: Dict[str, Any], config_path: str = \"agi_config.json\") -> None:\n    \"\"\"保存配置到文件\"\"\"\n    with open(config_path, 'w') as f:\n        json.dump(config, f, indent=4)\n\ndef generate_id(content: str) -> str:\n    \"\"\"基于内容生成唯一ID\"\"\"\n    return hashlib.md5(content.encode()).hexdigest()\n\ndef format_timestamp(timestamp: float) -> str:\n    \"\"\"格式化时间戳\"\"\"\n    return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n\ndef truncate_text(text: str, max_length: int = 100) -> str:\n    \"\"\"截断文本到指定长度\"\"\"\n    if len(text) <= max_length:\n        return text\n    return text[:max_length-3] + \"...\"\n\ndef safe_openai_request(client, **kwargs) -> Optional[Dict[str, Any]]:\n    \"\"\"安全地执行OpenAI API请求\"\"\"\n    try:\n        response = client.chat.completions.create(**kwargs)\n        return response\n    except Exception as e:\n        print(f\"OpenAI API请求错误: {e}\")\n        return None\n\ndef analyze_text_complexity(text: str) -> Dict[str, float]:\n    \"\"\"分析文本复杂度（简化版）\"\"\"\n    words = text.split()\n    sentences = text.split('.')\n    \n    return {\n        \"word_count\": len(words),\n        \"sentence_count\": len(sentences),\n        \"avg_words_per_sentence\": len(words) / len(sentences) if sentences else 0,\n        \"lexical_diversity\": len(set(words)) / len(words) if words else 0\n    }\n\ndef categorize_content(content: str) -> str:\n    \"\"\"对内容进行简单分类\"\"\"\n    lower_content = content.lower()\n    \n    if any(word in lower_content for word in [\"问题\", \"解决\", \"怎么办\"]):\n        return \"question\"\n    elif any(word in lower_content for word in [\"学习\", \"知识\", \"了解\"]):\n        return \"learning\"\n    elif any(word in lower_content for word in [\"计划\", \"目标\", \"未来\"]):\n        return \"planning\"\n    elif any(word in lower_content for word in [\"分析\", \"评估\", \"判断\"]):\n        return \"analysis\"\n    else:\n        return \"general\"\n"
        },
        {
            "filename": "requirements.txt",
            "content": "openai>=1.0.0\npython-dotenv>=0.19.0\n"
        },
        {
            "filename": "agi_config.json",
            "content": "{\n    \"openai_api_key\": \"YOUR_OPENAI_API_KEY\",\n    \"openai_model\": \"gpt-4-turbo-preview\",\n    \"max_tokens\": 4000,\n    \"temperature\": 0.7,\n    \"system_prompt\": \"你是一个真正的人工通用智能(AGI)，能够理解、学习和解决各种问题。\",\n    \"memory_file\": \"agi_memory.json\",\n    \"max_memory_size\": 1000\n}\n"
        },
        {
            "filename": "run_agi.py",
            "content": "#!/usr/bin/env python3\n\"\"\"AGI系统启动脚本\"\"\"\n\nimport os\nimport sys\nfrom dotenv import load_dotenv\n\n# 加载环境变量\nload_dotenv()\n\n# 添加项目根目录到Python路径\nsys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n\nfrom agi_core import AGI, AGIConfig\n\ndef main():\n    \"\"\"主函数\"\"\"\n    # 检查API密钥\n    if not os.getenv(\"OPENAI_API_KEY\"):\n        print(\"错误: 请设置OPENAI_API_KEY环境变量或在agi_config.json中提供API密钥\")\n        sys.exit(1)\n    \n    # 创建AGI实例\n    agi = AGI()\n    \n    # 运行AGI系统\n    agi.run()\n\nif __name__ == \"__main__\":\n    main()\n"
        },
        {
            "filename": ".env.example",
            "content": "# OpenAI API Key\nOPENAI_API_KEY=your_openai_api_key_here\n\n# Optional: Custom model name\n# OPENAI_MODEL=gpt-4-turbo-preview\n\n# Optional: Maximum tokens per response\n# MAX_TOKENS=4000\n\n# Optional: Temperature for response randomness\n# TEMPERATURE=0.7\n"
        },
        {
            "filename": "README.md",
            "content": "# AGI (Artificial General Intelligence)\n\n这是一个真正意义上的人工通用智能(AGI)系统实现，旨在理解、学习和解决各种问题。\n\n## 特性\n\n- **通用智能**: 能够理解和解决广泛领域的问题\n- **学习能力**: 从交互中持续学习和改进\n- **记忆系统**: 存储和检索相关信息\n- **推理能力**: 进行复杂逻辑推理和问题解决\n- **可扩展性**: 模块化设计，易于扩展和定制\n\n## 安装\n\n1. 克隆仓库\n\n```bash\ngit clone https://github.com/yourusername/agi.git\ncd agi\n```\n\n2. 创建虚拟环境\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\nvenv\\Scripts\\activate     # Windows\n```\n\n3. 安装依赖\n\n```bash\npip install -r requirements.txt\n```\n\n4. 设置API密钥\n\n有两种方式设置OpenAI API密钥:\n\n- 复制`.env.example`为`.env`并填入你的API密钥\n- 或直接在`agi_config.json`中设置`openai_api_key`\n\n## 使用\n\n启动AGI系统:\n\n```bash\npython run_agi.py\n```\n\n在交互式界面中与AGI对话。输入'exit'退出系统。\n\n## 配置\n\n主要配置在`agi_config.json`中:\n\n```json\n{\n    \"openai_api_key\": \"YOUR_OPENAI_API_KEY\",\n    \"openai_model\": \"gpt-4-turbo-preview\",\n    \"max_tokens\": 4000,\n    \"temperature\": 0.7,\n    \"system_prompt\": \"你是一个真正的人工通用智能(AGI)，能够理解、学习和