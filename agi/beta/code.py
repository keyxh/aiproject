# agi

{
    "files": [
        {
            "filename": "agi/__init__.py",
            "content": "# agi package initialization\n"
        },
        {
            "filename": "agi/config.py",
            "content": "import os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\n# Load environment variables from a .env file located at the project root\nBASE_DIR = Path(__file__).resolve().parent.parent\nENV_PATH = BASE_DIR / \".env\"\nif ENV_PATH.exists():\n    load_dotenv(dotenv_path=ENV_PATH)\n\n# Retrieve the OpenAI API key from environment variables\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nif not OPENAI_API_KEY:\n    raise RuntimeError(\"OPENAI_API_KEY not found in environment variables. Please set it in .env or your system environment.\")\n"
        },
        {
            "filename": "agi/agi_engine.py",
            "content": "import openai\nfrom typing import List, Dict, Any\nfrom .config import OPENAI_API_KEY\n\n# Configure the OpenAI client once at import time\nopenai.api_key = OPENAI_API_KEY\n\n\nclass AGIEngine:\n    \"\"\"A minimal wrapper around OpenAI's ChatCompletion API.\n\n    This class maintains a conversational history and provides a simple\n    interface for sending user messages and receiving model responses.\n    It is deliberately lightweight – the idea is to give a solid\n    foundation that can be extended into a more sophisticated AGI system.\n    \"\"\"\n\n    def __init__(self, model: str = \"gpt-4o-mini\") -> None:\n        \"\"\"Create a new AGIEngine instance.\n\n        Args:\n            model: The identifier of the OpenAI model to use. Defaults to\n                ``gpt-4o-mini`` which balances capability and cost.\n        \"\"\"\n        self.model = model\n        self._messages: List[Dict[str, str]] = []\n\n    def add_user_message(self, content: str) -> None:\n        \"\"\"Append a user message to the conversation history.\n\n        Args:\n            content: The raw text sent by the user.\n        \"\"\"\n        self._messages.append({\"role\": \"user\", \"content\": content})\n\n    def add_system_message(self, content: str) -> None:\n        \"\"\"Append a system message (instructions) to the conversation history.\n\n        System messages are useful for setting the behavior of the assistant.\n        \"\"\"\n        self._messages.append({\"role\": \"system\", \"content\": content})\n\n    def get_response(self, temperature: float = 0.7, max_tokens: int = 1024) -> str:\n        \"\"\"Call OpenAI's ChatCompletion endpoint and return the assistant's reply.\n\n        Args:\n            temperature: Sampling temperature; higher values increase randomness.\n            max_tokens: The maximum number of tokens to generate.\n\n        Returns:\n            The text content of the model's reply.\n        \"\"\"\n        if not self._messages:\n            raise ValueError(\"Conversation history is empty. Add at least one user or system message before calling get_response().\")\n\n        response = openai.ChatCompletion.create(\n            model=self.model,\n            messages=self._messages,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            n=1,\n            stop=None,\n        )\n        # Extract the assistant's message\n        assistant_message = response.choices[0].message[\"content\"].strip()\n        # Store the assistant's reply in history for continuity\n        self._messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n        return assistant_message\n\n    def reset_conversation(self) -> None:\n        \"\"\"Clear the conversation history.\n        \"\"\"\n        self._messages.clear()\n\n    def get_history(self) -> List[Dict[str, str]]:\n        \"\"\"Return a copy of the current message history.\n        \"\"\"\n        return self._messages.copy()\n"
        },
        {
            "filename": "agi/main.py",
            "content": "import argparse\nimport sys\nfrom .agi_engine import AGIEngine\n\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(description=\"Simple CLI for the AGIEngine using OpenAI API.\")\n    parser.add_argument(\"--model\", default=\"gpt-4o-mini\", help=\"OpenAI model identifier (default: gpt-4o-mini)\")\n    parser.add_argument(\"--system\", default=None, help=\"Optional system prompt to set behavior\")\n    parser.add_argument(\"--temperature\", type=float, default=0.7, help=\"Sampling temperature (default: 0.7)\")\n    parser.add_argument(\"--max-tokens\", type=int, default=1024, help=\"Maximum tokens per response (default: 1024)\")\n    return parser.parse_args()\n\n\ndef interactive_loop(engine: AGIEngine, temperature: float, max_tokens: int) -> None:\n    print(\"\\n=== AGI Interactive Session ===\")\n    print(\"Type 'exit' or press Ctrl+C to quit.\\n\")\n    try:\n        while True:\n            user_input = input(\"You: \")\n            if user_input.strip().lower() in {\"exit\", \"quit\"}:\n                print(\"Goodbye!\")\n                break\n            engine.add_user_message(user_input)\n            try:\n                response = engine.get_response(temperature=temperature, max_tokens=max_tokens)\n                print(f\"AGI: {response}\\n\")\n            except Exception as e:\n                print(f\"[Error] Failed to get response: {e}\\n\")\n    except KeyboardInterrupt:\n        print(\"\\nInterrupted. Exiting.\")\n        sys.exit(0)\n\n\ndef main() -> None:\n    args = parse_args()\n    engine = AGIEngine(model=args.model)\n    if args.system:\n        engine.add_system_message(args.system)\n    interactive_loop(engine, temperature=args.temperature, max_tokens=args.max_tokens)\n\n\nif __name__ == \"__main__\":\n    main()\n"
        },
        {
            "filename": ".env",
            "content": "# Rename this file to .env (no extension) and insert your OpenAI API key.\n# Example:\n# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"
        },
        {
            "filename": "requirements.txt",
            "content": "openai>=1.30.0\npython-dotenv>=1.0.0\n"
        },
        {
            "filename": "README.md",
            "content": "# AGI Project (Prototype)\n\n## Overview\nThis repository provides a **very lightweight prototype** of an autonomous‑agent framework that leverages the OpenAI API. While it does **not** implement a true Artificial General Intelligence, it establishes a clean, extensible code base that can be built upon for more sophisticated reasoning, tool‑use, or multi‑modal capabilities.\n\n## Features\n- Simple Python wrapper (`AGIEngine`) around `openai.ChatCompletion`.\n- Conversation history management.\n- CLI for interactive chatting.\n- Configurable model, system prompt, temperature, and token limits.\n- Environment‑based API‑key handling (`python-dotenv`).\n\n## Getting Started\n\n1. **Clone the repository**\n   ```bash\n   git clone https://github.com/your-org/agi.git\n   cd agi