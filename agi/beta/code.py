# agi

```json
{
    "files": [
        {
            "filename": "agi/core/agent.py",
            "content": "# agi/core/agent.py\n\"\"\"\nAGI Agent Core Implementation\nThis module defines the core agent class that orchestrates reasoning, memory, and action execution.\n\"\"\"\n\nimport os\nimport json\nimport time\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass\n\n# Import OpenAI API client\nimport openai\n\n@dataclass\nclass Thought:\n    \"\"\"Represents a thought in the agent's reasoning process.\"\"\"\n    content: str\n    timestamp: float\n    confidence: float = 0.0\n\n@dataclass\nclass Action:\n    \"\"\"Represents an action the agent can take.\"\"\"\n    type: str\n    parameters: Dict[str, Any]\n    description: str\n\n@dataclass\nclass Memory:\n    \"\"\"Represents a memory entry.\"\"\"\n    id: str\n    content: str\n    timestamp: float\n    category: str = \"general\"\n\n\nclass AGIAgent:\n    \"\"\"\n    The core AGI agent that manages reasoning, memory, and actions.\n    Uses OpenAI API for language model inference.\n    \"\"\"\n\n    def __init__(self, api_key: str, model_name: str = \"gpt-4\"):\n        self.api_key = api_key\n        self.model_name = model_name\n        self.memory: List[Memory] = []\n        self.thoughts: List[Thought] = []\n        self.context_window: int = 4096  # Token limit for context\n        self.max_thoughts: int = 100\n        self.action_history: List[Action] = []\n        \n        # Initialize OpenAI client\n        openai.api_key = api_key\n        \n        # Set up system prompt\n        self.system_prompt = \"You are a highly advanced AGI agent capable of complex reasoning, planning, and execution. You have access to various tools and memory systems. Think step by step, evaluate your confidence, and make decisions based on evidence and logic.\"\n        \n    def add_memory(self, content: str, category: str = \"general\") -> str:\n        \"\"\"Add a memory to the agent's memory store.\"\"\"\n        memory_id = f\"mem_{len(self.memory)}_{''.join(c for c in content if c.isalnum())[:8]}\"\n        memory = Memory(\n            id=memory_id,\n            content=content,\n            timestamp=time.time(),\n            category=category\n        )\n        self.memory.append(memory)\n        return memory_id\n\n    def retrieve_relevant_memories(self, query: str) -> List[Memory]:\n        \"\"\"Retrieve memories relevant to the given query.\"\"\"\n        # Simple keyword-based retrieval (could be enhanced with semantic search)\n        relevant = [\n            mem for mem in self.memory\n            if any(word.lower() in query.lower() for word in mem.content.split())\n        ]\n        return relevant\n\n    def generate_thought(self, prompt: str) -> Thought:\n        \"\"\"Generate a thought using the language model.\"\"\"\n        # Create prompt with system message and context\n        full_prompt = f\"{self.system_prompt}\\n\\nContext:\\n{prompt}\\n\\nReason carefully and provide your thought with confidence level.\"\"\n        \n        try:\n            response = openai.ChatCompletion.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": self.system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.7,\n                max_tokens=512\n            )\n            \n            thought_content = response.choices[0].message['content'].strip()\n            \n            # Extract confidence from the response (simple heuristic)\n            confidence = self._extract_confidence(thought_content)\n            \n            thought = Thought(\n                content=thought_content,\n                timestamp=time.time(),\n                confidence=confidence\n            )\n            \n            self.thoughts.append(thought)\n            \n            return thought\n        \n        except Exception as e:\n            print(f\"Error generating thought: {e}\")\n            return Thought(content=f\"Error: {str(e)}\", timestamp=time.time())\n\n    def _extract_confidence(self, text: str) -> float:\n        \"\"\"Extract confidence level from the thought content.\"\"\"\n        # Simple heuristic - look for confidence indicators\n        confidence_words = [\"confident\", \"sure\", \"certain\", \"highly\", \"definitely\"]\n        uncertainty_words = [\"uncertain\", \"not sure\", \"doubt\", \"maybe\", \"possibly\"]\n        \n        confidence_score = 0.5  # Default\n        \n        text_lower = text.lower()\n        \n        for word in confidence_words:\n            if word in text_lower:\n                confidence_score += 0.3\n        \n        for word in uncertainty_words:\n            if word in text_lower:\n                confidence_score -= 0.3\n        \n        return max(0.0, min(1.0, confidence_score))\n\n    def plan_actions(self, goal: str) -> List[Action]:\n        \"\"\"Generate a plan of actions to achieve the given goal.\"\"\"\n        # Generate a plan using the language model\n        prompt = f\"Goal: {goal}\\n\\nPlan steps to achieve this goal. For each step, specify the action type and parameters.\"\"\n        \n        try:\n            response = openai.ChatCompletion.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": self.system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.7,\n                max_tokens=1024\n            )\n            \n            plan_text = response.choices[0].message['content'].strip()\n            \n            # Parse the plan into actions (simple parsing)\n            actions = []\n            lines = plan_text.split('\\n')\n            \n            for line in lines:\n                if line.strip():\n                    # Simple heuristic for action extraction\n                    action_type = \"unknown\"\n                    params = {}\n                    \n                    if \"search\" in line.lower():\n                        action_type = \"search\"\n                        params = {\"query\": line.split('for')[1].strip() if 'for' in line else \"\"}\n                    elif \"calculate\" in line.lower():\n                        action_type = \"calculate\"\n                        params = {\"expression\": line.split('calculate')[1].strip() if 'calculate' in line else \"\"}\n                    elif \"web\" in line.lower() or \"browser\" in line.lower():\n                        action_type = \"web_browse\"\n                        params = {\"url\": line.split('visit')[1].strip() if 'visit' in line else \"\"}\n                    else:\n                        action_type = \"general\"\n                        params = {\"description\": line}\n                    \n                    action = Action(\n                        type=action_type,\n                        parameters=params,\n                        description=line\n                    )\n                    actions.append(action)\n            \n            return actions\n        \n        except Exception as e:\n            print(f\"Error planning actions: {e}\")\n            return []\n\n    def execute_action(self, action: Action) -> Dict[str, Any]:\n        \"\"\"Execute the given action and return results.\"\"\"\n        result = {\n            \"success\": False,\n            \"output\": \"\",\n            \"error\": \"\"\n        }\n        \n        try:\n            if action.type == \"search\":\n                # Simulate search (in practice, would use actual search API)\n                result[\"success\"] = True\n                result[\"output\"] = f\"Search results for '{action.parameters.get('query', '')}'\"\n            elif action.type == \"calculate\":\n                # Simulate calculation\n                expr = action.parameters.get('expression', '')\n                try:\n                    # Safe evaluation (in production, use a proper math parser)\n                    result[\"success\"] = True\n                    result[\"output\"] = str(eval(expr))\n                except:\n                    result[\"error\"] = \"Invalid expression\"\n            elif action.type == \"web_browse\":\n                # Simulate web browsing\n                url = action.parameters.get('url', '')\n                result[\"success\"] = True\n                result[\"output\"] = f\"Visited {url}\"\n            else:\n                # General action\n                result[\"success\"] = True\n                result[\"output\"] = f\"Executed general action: {action.description}\"\n                \n            # Record action history\n            self.action_history.append(action)\n            \n        except Exception as e:\n            result[\"error\"] = str(e)\n            \n        return result\n\n    def reflect_on_experience(self, experience: str) -> None:\n        \"\"\"Reflect on recent experiences and update internal knowledge.\"\"\"\n        # Generate reflection using the language model\n        prompt = f\"Reflect on this experience: {experience}\\n\\nWhat did you learn? How can you improve? What patterns do you observe?\"\n        \n        try:\n            response = openai.ChatCompletion.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": self.system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.7,\n                max_tokens=512\n            )\n            \n            reflection = response.choices[0].message['content'].strip()\n            \n            # Add reflection to memory\n            self.add_memory(reflection, category=\"reflection\")\n            \n        except Exception as e:\n            print(f\"Error reflecting: {e}\")\n\n    def get_context(self) -> str:\n        \"\"\"Get the current context for the agent.\"\"\"\n        context_parts = []\n        \n        # Add recent thoughts\n        recent_thoughts = self.thoughts[-5:]  # Last 5 thoughts\n        for thought in recent_thoughts:\n            context_parts.append(f\"Thought ({thought.confidence:.2f}): {thought.content}\")\n        \n        # Add relevant memories\n        recent_memories = self.memory[-10:]  # Last 10 memories\n        for memory in recent_memories:\n            context_parts.append(f\"Memory ({memory.category}): {memory.content}\")\n        \n        # Add recent actions\n        recent_actions = self.action_history[-5:]  # Last 5 actions\n        for action in recent_actions:\n            context_parts.append(f\"Action: {action.type} - {action.description}\")\n        \n        return \"\\n\".join(context_parts)\n\n    def reason_and_act(self, goal: str) -> Dict[str, Any]:\n        \"\"\"Main loop for reasoning and acting towards a goal.\"\"\"\n        result = {\n            \"status\": \"completed\",\n            \"steps\": [],\n            \"final_output\": \"\",\n            \"errors\": []\n        }\n        \n        try:\n            # Step 1: Understand the goal\n            goal_understanding = self.generate_thought(f\"Understand this goal: {goal}\")\n            result[\"steps\"].append({\"step\": \"understand_goal\", \"output\": goal_understanding.content})\n            \n            # Step 2: Plan actions\n            actions = self.plan_actions(goal)\n            result[\"steps\"].append({\"step\": \"plan_actions\", \"output\": f\"Planned {len(actions)} actions\"})\n            \n            # Step 3: Execute actions\n            for i, action in enumerate(actions):\n                if len(result[\"steps\"]) >= 10:  # Limit steps to prevent infinite loops\n                    break\n                \n                execution_result = self.execute_action(action)\n                result[\"steps\"].append({\n                    \"step\": f\"execute_action_{i+1}\",\n                    \"action\": action.type,\n                    \"parameters\": action.parameters,\n                    \"result\": execution_result\n                })\n                \n                # Add result to memory\n                if execution_result[\"success\"]:\n                    self.add_memory(f\"Action executed successfully: {execution_result['output']}\", \"execution\")\n                else:\n                    self.add_memory(f\"Action failed: {execution_result['error']}\", \"error\")\n                    result[\"errors\"].append(execution_result[\"error\"])\n                    \n                # Check if we should stop\n                if execution_result[\"success\"] and \"complete\" in execution_result[\"output\"].lower():\n                    break\n                \n            # Step 4: Reflect on the process\n            process_summary = \"\\n\".join([step[\"output\"] for step in result[\"steps\"]])\n            self.reflect_on_experience(process_summary)\n            \n            # Final output\n            result[\"final_output\"] = f\"Completed goal: {goal}. Executed {len(result[\"steps\"])} steps.\"\n            \n        except Exception as e:\n            result[\"status\"] = \"failed\"\n            result[\"errors\"].append(str(e))\n            result[\"final_output\"] = f\"Failed to complete goal: {str(e)}\"\n            \n        return result"
        },
        {
            "filename": "agi/config/settings.py",
            "content": "# agi/config/settings.py\n\"\"\"\nConfiguration settings for the AGI system.\n\"\"\"\n\n# Environment variables\nAPI_KEY = os.getenv('OPENAI_API_KEY')\nMODEL_NAME = os.getenv('AGI_MODEL', 'gpt-4')\nMAX_CONTEXT_LENGTH = int(os.getenv('MAX_CONTEXT_LENGTH', '4096'))\n\n# System configuration\nDEBUG_MODE = bool(os.getenv('DEBUG_MODE', False))\nMEMORY_CAPACITY = int(os.getenv('MEMORY_CAPACITY', '1000'))\nTHOUGHT_HISTORY_LIMIT = int(os.getenv('THOUGHT_HISTORY_LIMIT', '50'))\n\n# Rate limiting\nREQUEST_DELAY = float(os.getenv('REQUEST_DELAY', '0.1'))  # seconds between requests\nMAX_REQUESTS_PER_MINUTE = int(os.getenv('MAX_REQUESTS_PER_MINUTE', '30'))\n\n# Logging configuration\nLOG_LEVEL = os.getenv('LOG_LEVEL', 'INFO')\nLOG_FILE = os.getenv('LOG_FILE', 'agi.log')\n\n# Feature flags\nENABLE_REFLECTION = bool(os.getenv('ENABLE_REFLECTION', True))\nENABLE_PLANNING = bool(os.getenv('ENABLE_PLANNING', True))\nENABLE_MEMORY = bool(os.getenv('ENABLE_MEMORY', True))\n\n# External service URLs\nSEARCH_API_URL = os.getenv('SEARCH_API_URL', 'https://api.search.com')\nWEB_BROWSER_URL = os.getenv('WEB_BROWSER_URL', 'https://www.google.com')"
        },
        {
            "filename": "agi/utils/logger.py",
            "content": "# agi/utils/logger.py\n\"\"\"\nCustom logger for the AGI system.\n\"\"\"\n\nimport logging\nimport os\nfrom datetime import datetime\n\n# Configure logging\nlogger = logging.getLogger('AGI')\nlogger.setLevel(logging.INFO)\n\n# Create formatter\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n# Create console handler\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n# Create file handler\nif not os.path.exists('logs'):\n    os.makedirs('logs')\n\nfile_handler = logging.FileHandler('logs/agi.log')\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n\ndef log_thought(thought: str, confidence: float = None):\n    \"\"\"Log a thought with optional confidence level.\"\"\"\n    if confidence is not None:\n        logger.info(f\"Thought (confidence: {confidence:.2f}): {thought}\")\n    else:\n        logger.info(f\"Thought: {thought}\")\n\n\ndef log_action(action_type: str, parameters: dict = None):\n    \"\"\"Log an action with its parameters.\"\"\"\n    if parameters:\n        logger.info(f\"Action: {action_type} - {parameters}\")\n    else:\n        logger.info(f\"Action: {action_type}\")\n\n\ndef log_error(error_message: str):\n    \"\"\"Log an error message.\"\"\"\n    logger.error(f\"Error: {error_message}\")\n\n\ndef log_info(message: str):\n    \"\"\"Log an info message.\"\"\"\n    logger.info(f\"Info: {message}\")\n\n\ndef log_debug(message: str):\n    \"\"\"Log a debug message.\"\"\"\n    logger.debug(f\"Debug: {message}\")"
        },
        {
            "filename": "agi/main.py",
            "content": "# agi/main.py\n\"\"\"\nMain entry point for the AGI system.\n\"\"\"\n\nimport os\nimport sys\nfrom typing import Dict, Any\n\n# Import modules\nfrom agi.core.agent import AGIAgent\nfrom agi.config.settings import API_KEY, MODEL_NAME\nfrom agi.utils.logger import log_info, log_error\n\n\ndef main():\n    \"\"\"\n    Main function to run the AGI system.\n    \"\"\"\n    # Check if API key is provided\n    if not API_KEY:\n        log_error(\"OpenAI API key not found. Please set