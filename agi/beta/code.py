# agi

{
    "files": [
        {
            "filename": "README.md",
            "content": "# AGI (Artificial General Intelligence) Project\n\n## Overview\nThis project aims to implement an Artificial General Intelligence system using OpenAI API as the underlying model interface. The architecture is designed to be modular, scalable, and capable of handling multiple cognitive tasks.\n\n## Architecture\nThe AGI system consists of several core components:\n- Memory Management System\n- Reasoning Engine\n- Task Planning Module\n- Multi-modal Processing\n- Self-improvement Mechanism\n\n## Components\n1. Core AGI Controller\n2. Memory Manager\n3. Reasoning Engine\n4. Task Planner\n5. Learning Module\n6. Communication Interface\n\n## Technologies Used\n- Python 3.9+\n- OpenAI API\n- Vector Databases (for memory)\n- AsyncIO for concurrency\n\n## Setup Instructions\nSee setup.py and requirements.txt for dependencies."
        },
        {
            "filename": "agi/core/controller.py",
            "content": "import asyncio\nfrom typing import Dict, Any, List\nfrom agi.core.memory import MemoryManager\nfrom agi.core.reasoning import ReasoningEngine\nfrom agi.core.planning import TaskPlanner\nfrom agi.core.learning import LearningModule\nfrom agi.interfaces.openai_api import OpenAIAPIInterface\n\nclass AGIController:\n    \"\"\"\n    Main controller class for the AGI system.\n    Orchestrates all components and manages high-level decision making.\n    \"\"\"\n    \n    def __init__(self, api_key: str):\n        self.api_interface = OpenAIAPIInterface(api_key)\n        self.memory_manager = MemoryManager()\n        self.reasoning_engine = ReasoningEngine(self.api_interface)\n        self.task_planner = TaskPlanner(self.api_interface)\n        self.learning_module = LearningModule(self.api_interface)\n        \n        # System state and goals\n        self.current_goals: List[str] = []\n        self.long_term_goals: List[str] = []\n        \n    async def process_input(self, user_input: str) -> str:\n        \"\"\"\n        Process user input and generate response based on AGI capabilities\n        \"\"\"\n        # Store input in memory\n        await self.memory_manager.store_interaction(user_input)\n        \n        # Analyze input and determine required actions\n        analysis_result = await self.reasoning_engine.analyze_input(user_input)\n        \n        # Plan necessary tasks\n        tasks = await self.task_planner.plan_tasks(analysis_result)\n        \n        # Execute tasks\n        results = []\n        for task in tasks:\n            result = await self.execute_task(task)\n            results.append(result)\n            \n        # Synthesize final response\n        final_response = await self.synthesize_response(results)\n        \n        # Update learning module with interaction results\n        await self.learning_module.update_from_interaction(\n            user_input, final_response, results\n        )\n        \n        return final_response\n    \n    async def execute_task(self, task: Dict[str, Any]) -> Any:\n        \"\"\"\n        Execute a single task using appropriate components\n        \"\"\"\n        if task['type'] == 'reasoning':\n            return await self.reasoning_engine.perform_reasoning(\n                task['query'],\n                context=task.get('context', {})\n            )\n        elif task['type'] == 'memory_search':\n            return await self.memory_manager.search_memory(\n                task['query'],\n                tags=task.get('tags', [])\n            )\n        elif task['type'] == 'learning':\n            return await self.learning_module.learn_new_concept(\n                task['concept'],\n                task['examples']\n            )\n        else:\n            raise ValueError(f\"Unknown task type: {task['type']}\")\n    \n    async def synthesize_response(self, results: List[Any]) -> str:\n        \"\"\"\n        Synthesize a coherent response from multiple task results\n        \"\"\"\n        # Use reasoning engine to combine results into a coherent response\n        synthesis_prompt = f\"Synthesize these results into a coherent response: {results}\"\n        response = await self.reasoning_engine.perform_reasoning(synthesis_prompt)\n        return response\n    \n    async def set_goals(self, goals: List[str], long_term: bool = False):\n        \"\"\"\n        Set current or long-term goals for the AGI system\n        \"\"\"\n        if long_term:\n            self.long_term_goals = goals\n        else:\n            self.current_goals = goals\n        \n        # Store goals in memory\n        await self.memory_manager.store_goals(goals, long_term)\n    \n    async def update_system_state(self):\n        \"\"\"\n        Periodically update system state based on interactions and learning\n        \"\"\"\n        # Update goals based on learning\n        new_goals = await self.learning_module.suggest_new_goals()\n        if new_goals:\n            await self.set_goals(new_goals, long_term=True)\n            \n        # Clean up memory periodically\n        await self.memory_manager.cleanup_expired_entries()"
        },
        {
            "filename": "agi/core/memory.py",
            "content": "import asyncio\nimport json\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n@dataclass\nclass MemoryEntry:\n    id: str\n    content: str\n    timestamp: datetime\n    tags: List[str]\n    importance: float  # 0.0 to 1.0\n    metadata: Dict[str, Any]\n\n\nclass MemoryType(Enum):\n    EPISODIC = \"episodic\"      # Personal experiences\n    SEMANTIC = \"semantic\"      # Factual knowledge\n    PROCEDURAL = \"procedural\"  # Skills and procedures\n    WORKING = \"working\"        # Short-term memory\n\n\nclass MemoryManager:\n    \"\"\"\n    Manages all forms of memory for the AGI system.\n    Handles storage, retrieval, and forgetting of information.\n    \"\"\"\n    \n    def __init__(self):\n        self.memories: Dict[str, MemoryEntry] = {}\n        self.tags_index: Dict[str, List[str]] = {}  # tag -> list of memory IDs\n        self.type_index: Dict[MemoryType, List[str]] = {\n            mt: [] for mt in MemoryType\n        }\n        self.importance_threshold = 0.3  # Minimum importance to keep in long-term memory\n        \n    async def store_interaction(self, interaction: str, tags: List[str] = None):\n        \"\"\"\n        Store a user interaction in memory\n        \"\"\"\n        import uuid\n        \n        entry = MemoryEntry(\n            id=str(uuid.uuid4()),\n            content=interaction,\n            timestamp=datetime.now(),\n            tags=tags or [],\n            importance=self._calculate_importance(interaction),\n            metadata={'type': 'interaction'}\n        )\n        \n        self.memories[entry.id] = entry\n        self._update_indexes(entry)\n        \n        # Cleanup old memories if needed\n        await self._cleanup_old_memories()\n        \n    async def store_goals(self, goals: List[str], long_term: bool):\n        \"\"\"\n        Store goals in memory with appropriate tagging\n        \"\"\"\n        import uuid\n        \n        for goal in goals:\n            entry = MemoryEntry(\n                id=str(uuid.uuid4()),\n                content=goal,\n                timestamp=datetime.now(),\n                tags=['goal', 'long_term' if long_term else 'short_term'],\n                importance=1.0 if long_term else 0.7,\n                metadata={'type': 'goal', 'long_term': long_term}\n            )\n            \n            self.memories[entry.id] = entry\n            self._update_indexes(entry)\n    \n    async def search_memory(self, query: str, tags: List[str] = None, memory_type: MemoryType = None) -> List[MemoryEntry]:\n        \"\"\"\n        Search memory for relevant entries\n        \"\"\"\n        results = []\n        \n        # Filter by type if specified\n        candidate_ids = self.type_index[memory_type] if memory_type else list(self.memories.keys())\n        \n        # Filter by tags if specified\n        if tags:\n            tag_filtered_ids = set()\n            for tag in tags:\n                tag_filtered_ids.update(self.tags_index.get(tag, []))\n            candidate_ids = [id for id in candidate_ids if id in tag_filtered_ids]\n        \n        # Score and rank results\n        scored_results = []\n        for mem_id in candidate_ids:\n            memory = self.memories[mem_id]\n            score = self._calculate_relevance_score(query, memory)\n            if score > 0.1:  # Only include relevant memories\n                scored_results.append((score, memory))\n        \n        # Sort by relevance score\n        scored_results.sort(key=lambda x: x[0], reverse=True)\n        \n        return [memory for _, memory in scored_results[:10]]  # Return top 10\n    \n    async def retrieve_context(self, time_window_hours: int = 8) -> str:\n        \"\"\"\n        Retrieve recent context from memory\n        \"\"\"\n        cutoff_time = datetime.now() - timedelta(hours=time_window_hours)\n        recent_memories = [\n            mem for mem in self.memories.values() \n            if mem.timestamp > cutoff_time\n        ]\n        \n        recent_memories.sort(key=lambda x: x.timestamp, reverse=True)\n        \n        context_parts = []\n        for memory in recent_memories[:20]:  # Limit to 20 most recent\n            context_parts.append(f\"[{memory.timestamp.strftime('%H:%M:%S')}] {memory.content}\")\n        \n        return \"\\n\".join(context_parts)\n    \n    async def cleanup_expired_entries(self):\n        \"\"\"\n        Remove expired or low-importance entries\n        \"\"\"\n        now = datetime.now()\n        expired_ids = []\n        \n        for mem_id, memory in self.memories.items():\n            # Check if memory has expiration or if it's below importance threshold\n            if (memory.metadata.get('expires_at') and \n                datetime.fromisoformat(memory.metadata['expires_at']) < now) or \\\n               (memory.importance < self.importance_threshold and \n                now - memory.timestamp > timedelta(days=7)):  # Older than 7 days and low importance\n                expired_ids.append(mem_id)\n        \n        for mem_id in expired_ids:\n            del self.memories[mem_id]\n            self._remove_from_indexes(mem_id)\n    \n    def _calculate_importance(self, content: str) -> float:\n        \"\"\"\n        Calculate importance score for a memory entry\n        \"\"\"\n        # Simple heuristic - can be improved with more sophisticated methods\n        length_importance = min(len(content) / 1000, 0.5)  # Longer content might be more important\n        keyword_importance = sum([\n            0.2 if word in content.lower() else 0 \n            for word in ['important', 'critical', 'urgent', 'goal', 'plan']\n        ])\n        \n        return min(length_importance + keyword_importance, 1.0)\n    \n    def _calculate_relevance_score(self, query: str, memory: MemoryEntry) -> float:\n        \"\"\"\n        Calculate relevance score between query and memory\n        \"\"\"\n        query_lower = query.lower()\n        content_lower = memory.content.lower()\n        \n        # Simple word overlap scoring\n        query_words = set(query_lower.split())\n        content_words = set(content_lower.split())\n        \n        overlap = len(query_words.intersection(content_words))\n        total_unique = len(query_words.union(content_words))\n        \n        if total_unique == 0:\n            return 0.0\n        \n        overlap_score = overlap / total_unique\n        \n        # Boost score for memories with matching tags\n        tag_boost = 0.2 if any(tag.lower() in query_lower for tag in memory.tags) else 0\n        \n        # Boost score for more recent memories\n        time_decay = max(0, 1 - ((datetime.now() - memory.timestamp).total_seconds() / (86400 * 30)))  # 30 day decay\n        \n        return min(overlap_score * 0.7 + tag_boost * 0.2 + memory.importance * 0.1, 1.0) * time_decay\n    \n    def _update_indexes(self, entry: MemoryEntry):\n        \"\"\"\n        Update indexes for a new memory entry\n        \"\"\"\n        # Update tag index\n        for tag in entry.tags:\n            if tag not in self.tags_index:\n                self.tags_index[tag] = []\n            self.tags_index[tag].append(entry.id)\n        \n        # Update type index\n        memory_type = self._determine_memory_type(entry)\n        self.type_index[memory_type].append(entry.id)\n    \n    def _remove_from_indexes(self, mem_id: str):\n        \"\"\"\n        Remove a memory ID from all indexes\n        \"\"\"\n        # Remove from tag indexes\n        for tag_list in self.tags_index.values():\n            if mem_id in tag_list:\n                tag_list.remove(mem_id)\n        \n        # Remove from type indexes\n        for type_list in self.type_index.values():\n            if mem_id in type_list:\n                type_list.remove(mem_id)\n    \n    def _determine_memory_type(self, entry: MemoryEntry) -> MemoryType:\n        \"\"\"\n        Determine memory type based on content and metadata\n        \"\"\"\n        if 'type' in entry.metadata:\n            if entry.metadata['type'] == 'interaction':\n                return MemoryType.EPISODIC\n            elif entry.metadata['type'] == 'knowledge':\n                return MemoryType.SEMANTIC\n            elif entry.metadata['type'] == 'skill':\n                return MemoryType.PROCEDURAL\n        \n        # Default to episodic for general interactions\n        return MemoryType.EPISODIC\n    \n    async def _cleanup_old_memories(self):\n        \"\"\"\n        Periodic cleanup of old memories\n        \"\"\"\n        # Implementation would remove memories based on importance and age\n        pass"
        },
        {
            "filename": "agi/core/reasoning.py",
            "content": "import asyncio\nimport json\nfrom typing import Dict, Any, List\nfrom agi.interfaces.openai_api import OpenAIAPIInterface\n\n\nclass ReasoningEngine:\n    \"\"\"\n    Performs logical reasoning and complex thought processes.\n    Uses LLM to simulate human-like reasoning capabilities.\n    \"\"\"\n    \n    def __init__(self, api_interface: OpenAIAPIInterface):\n        self.api_interface = api_interface\n        self.reasoning_history = []\n        \n    async def analyze_input(self, user_input: str) -> Dict[str, Any]:\n        \"\"\"\n        Analyze user input to understand intent and context\n        \"\"\"\n        prompt = f\"\"\"\n        Analyze this user input and provide structured analysis:\n        \n        Input: {user_input}\n        \n        Provide your analysis in the following JSON format:\n        {{\n          \"intent\": \"primary intent of the user\",\n          \"entities\": [\"list\", \"of\", \"recognized\", \"entities\"],\n          \"complexity\": \"simple|moderate|complex\",\n          \"required_knowledge\": [\"types\", \"of\", \"knowledge\", \"needed\"],\n          \"potential_actions\": [\"possible\", \"actions\", \"to\", \"take\"]\n        }}\n        \n        Be concise but thorough in your analysis.\n        \"\"\"\n        \n        response = await self.api_interface.generate_text(prompt, max_tokens=500)\n        try:\n            analysis = json.loads(response.strip())\n        except json.JSONDecodeError:\n            # If parsing fails, create a basic structure\n            analysis = {\n                \"intent\": \"unknown\",\n                \"entities\": [],\n                \"complexity\": \"moderate\",\n                \"required_knowledge\": [\"general\"],\n                \"potential_actions\": [\"respond\"]\n            }\n        \n        self.reasoning_history.append({\n            \"input\": user_input,\n            \"analysis\": analysis,\n            \"timestamp\": \"now\"\n        })\n        \n        return analysis\n    \n    async def perform_reasoning(self, query: str, context: Dict[str, Any] = None) -> str:\n        \"\"\"\n        Perform logical reasoning on a given query with optional context\n        \"\"\"\n        # Build comprehensive prompt with context\n        full_context = \"\"\n        if context:\n            full_context += f\"Context: {json.dumps(context, indent=2)}\\n\\n\"\n        \n        prompt = f\"\"\"\n        {full_context}\n        Question/Task: {query}\n        \n        Please think step-by-step and provide your reasoning:\n        1. What are the key components of this problem?\n        2. What information do I need to solve this?\n        3. What approach should I take?\n        4. What is my conclusion or solution?\n        \n        Be thorough in your reasoning but concise in your final answer.\n        \"\"\"\n        \n        response = await self.api_interface.generate_text(prompt, max_tokens=1000)\n        \n        self.reasoning_history.append({