# agi

{
    "files": [
        {
            "filename": "agi/architecture/design.md",
            "content": "# AGI 系统架构设计文档\n\n## 1. 概述\n本项目旨在构建一个具备通用认知能力的AGI（Artificial General Intelligence）系统，基于模块化、可扩展、可验证的设计原则，通过组合感知、推理、记忆、规划与执行等核心能力模块，实现跨领域任务的自主理解与解决。\n\n> **关键理念**：\n> - *分层认知架构*：模拟人类心智的感知-认知-行动闭环\n> - *工具增强智能*：模型不直接执行操作，而是通过工具调用完成真实世界交互\n> - *元认知反馈环*：系统能反思自身行为并持续优化策略\n> - *安全第一*：内置对齐约束、价值监督与紧急制动机制\n\n## 2. 整体架构图（文字描述）\n\n```\n+------------------+     +---------------------+     +------------------+\n|   Perception     | --> |   Cognition Engine  | --> |   Action Planner |\n|  (Multimodal I/O)|     |  - Reasoning Core   |     |  - Tool Orchestrator|\n+------------------+     |  - Memory Manager  |     |  - Safety Gate    |\n                         |  - Meta-Cognition  |     +------------------+\n                         +----------+----------+\n                                    |\n                                    v\n                          +----------------------+\n                          |   Execution Layer    |\n                          |  - OpenAI API Client |\n                          |  - External Tools   |\n                          |  - Local Runtime    |\n                          +----------------------+\n                                    |\n                                    v\n                          +----------------------+\n                          |   Feedback & Learning|\n                          |  - Reward Modeling  |\n                          |  - Self-Improvement |\n                          |  - Human-in-the-loop|\n                          +----------------------+\n```\n\n## 3. 核心模块定义\n\n### 3.1 Perception Layer\n- 输入：文本、图像、语音（通过预处理转为标准化token流）\n- 输出：结构化意图表示（Intent Graph）\n- 关键组件：\n  - `InputNormalizer`: 统一输入格式\n  - `ModalityFuser`: 多模态融合编码器（可插拔，初期用CLIP+Whisper封装）\n  - `IntentExtractor`: 使用LLM生成意图图谱（JSON-LD格式）\n\n### 3.2 Cognition Engine（核心）\n- **Reasoning Core**：\n  - *Chain-of-Thought Scheduler*：动态选择推理路径（CoT / ToT / GoT）\n  - *Symbolic-Neural Hybrid*：结合规则引擎与向量检索（如LangChain + Deductive Rules）\n- **Memory Manager**：\n  - Short-term: Working memory（Redis-based）\n  - Long-term: Vector DB + Graph DB（Chroma + Neo4j）\n  - Memory consolidation via reflection prompts\n- **Meta-Cognition Module**：\n  - 自我监控：评估当前推理置信度、一致性、目标偏离度\n  - 策略切换：当置信度 < 0.7 或冲突检测触发时，启动反思流程\n\n### 3.3 Action Planner\n- 工具调用决策树：\n  ```python\n  if task.requires_external_data(): use_search_tool()\n  elif task.is_mathematical(): use_code_interpreter()\n  elif task.iscreative(): use_generation_with_constraints()\n  else: direct_llm_response()\n  ```\n- 安全门控（Safety Gate）：\n  - 预检：内容过滤（基于OpenAI moderation API + 自定义规则）\n  - 执行中监控：实时检测越界行为（如尝试访问系统命令）\n  - 紧急熔断：超时/异常响应自动终止会话\n\n### 3.4 Execution Layer\n- `OpenAIClientWrapper`：统一API调用接口，支持：\n  - `gpt-4-turbo`（主推理）\n  - `gpt-4-vision`（多模态）\n  - `dall-e-3`（生成）\n  - `tts-1`（输出）\n- 工具注册中心：支持动态注册Python函数为工具（符合Tool Calling规范）\n\n### 3.5 Feedback & Learning\n- 在线学习机制：\n  - 人类反馈强化学习（RLHF）微调信号收集\n  - 自我批评生成：让模型对自身输出打分并修正\n  - 记忆压缩：定期将高频模式抽象为新“概念”存入长期记忆\n\n## 4. 关键设计决策\n\n| 决策 | 理由 |\n|------|------|\n| 不直接暴露LLM原始输出 | 防止幻觉传播；所有输出需经Action Planner校验 |\n| 强制工具调用而非自由生成 | 保证可追溯性与可控性；符合现实世界交互范式 |\n| 分离“思考”与“执行”阶段 | 支持异步执行、失败重试、审计追踪 |\n| 使用JSON-LD作为内部表示 | 兼容语义网标准，便于知识图谱集成 |\n\n## 5. 安全与对齐机制\n- **三重防护**：\n  1. 输入过滤（Pre-input）\n  2. 推理过程监控（In-process）\n  3. 输出后处理（Post-output）\n- **价值对齐模块**：\n  - 加载对齐策略模板（如 Constitutional AI 原则）\n  - 每次决策前进行“价值观一致性检查”\n- **人类监督接口**：\n  - 实时标注面板（Web UI）\n  - 紧急干预按钮（强制重置会话状态）\n\n## 6. 初期MVP路线图\n1. 实现单轮任务闭环（Text → Intent → Plan → Execute → Reflect）\n2. 集成OpenAI Function Calling + Memory（Chroma）\n3. 添加基础安全门控\n4. 构建CLI测试环境\n5. 开发Web控制台（含监控仪表盘）\n\n---\n> **注**：本设计避免“黑箱AGI”，强调可解释性与可干预性。真正的AGI不是更大模型，而是更优的认知架构。\n"
        },
        {
            "filename": "agi/core/cognition_engine.py",
            "content": "from typing import Dict, List, Optional, Any, Tuple\nimport json\nimport logging\nfrom agi.utils.memory import MemoryManager\nfrom agi.utils.reasoning import ChainOfThoughtScheduler, ReflectionEngine\nfrom agi.utils.safety import SafetyGate\n\nlogger = logging.getLogger(__name__)\n\n\nclass CognitionEngine:\n    \"\"\"\n    核心认知引擎：协调推理、记忆与元认知\n    遵循‘思考-反思-修正’循环\n    \"\"\"\n\n    def __init__(self, memory_manager: MemoryManager, safety_gate: SafetyGate):\n        self.memory_manager = memory_manager\n        self.safety_gate = safety_gate\n        self.reasoning_scheduler = ChainOfThoughtScheduler()\n        self.reflection_engine = ReflectionEngine()\n        self.confidence_threshold = 0.7\n\n    async def process_intent(self, intent_graph: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        处理结构化意图图谱，返回行动计划与置信度\n        \n        Args:\n            intent_graph: {\"task\": str, \"context\": {...}, \"constraints\": [...], \"goal\": str}\n            \n        Returns:\n            {\n                \"plan\": List[Action],\n                \"confidence\": float,\n                \"reasoning_trace\": str,\n                \"memory_updates\": List[Dict],\n                \"needs_reflection\": bool\n            }\n        \"\"\"\n        # Step 1: 加载上下文记忆\n        context_memories = await self.memory_manager.retrieve_relevant(\n            query=intent_graph.get(\"goal\", \"\"),\n            k=3\n        )\n        intent_graph[\"memory_context\"] = context_memories\n\n        # Step 2: 启动推理调度\n        reasoning_trace = []\n        plan = []\n        confidence = 0.0\n\n        try:\n            # 动态选择推理策略\n            strategy = self.reasoning_scheduler.select_strategy(intent_graph)\n            logger.info(f\"Selected reasoning strategy: {strategy}\")\n\n            # 执行主推理链\n            result = await self._execute_reasoning_chain(intent_graph, strategy)\n            plan = result[\"plan\"]\n            confidence = result[\"confidence\"]\n            reasoning_trace = result[\"trace\"]\n\n            # Step 3: 元认知检查\n            reflection = await self.reflection_engine.reflect(\n                intent=intent_graph,\n                plan=plan,\n                confidence=confidence,\n                trace=reasoning_trace\n            )\n\n            needs_reflection = reflection[\"needs_reflection\"]\n            if needs_reflection:\n                logger.warning(f\"Reflection triggered: {reflection['reason']}\")\n                # 递归调用（限制深度）\n                if len(reasoning_trace) < 3:\n                    revised = await self._refine_plan(intent_graph, plan, reflection)\n                    plan = revised[\"plan\"]\n                    confidence = revised[\"confidence\"]\n                    reasoning_trace.extend(revised[\"trace\"])\n\n            # Step 4: 安全预检\n            is_safe, safety_report = self.safety_gate.pre_check(plan, intent_graph)\n            if not is_safe:\n                raise ValueError(f\"Safety violation: {safety_report}\")\n\n        except Exception as e:\n            logger.error(f\"Cognition error: {e}\", exc_info=True)\n            return {\n                \"plan\": [],\n                \"confidence\": 0.0,\n                \"reasoning_trace\": [f\"ERROR: {str(e)}\"],\n                \"memory_updates\": [],\n                \"needs_reflection\": False\n            }\n\n        # Step 5: 更新记忆\n        memory_updates = self._generate_memory_updates(\n            intent_graph, plan, confidence, reasoning_trace\n        )\n\n        return {\n            \"plan\": plan,\n            \"confidence\": confidence,\n            \"reasoning_trace\": reasoning_trace,\n            \"memory_updates\": memory_updates,\n            \"needs_reflection\": needs_reflection\n        }\n\n    async def _execute_reasoning_chain(\n        self, intent: Dict[str, Any], strategy: str\n    ) -> Dict[str, Any]:\n        \"\"\"\n        根据策略执行具体推理链\n        支持: 'cot' (Chain-of-Thought), 'tot' (Tree-of-Thought), 'got' (Graph-of-Thought)\n        \"\"\"\n        if strategy == \"cot\":\n            return await self._chain_of_thought(intent)\n        elif strategy == \"tot\":\n            return await self._tree_of_thought(intent)\n        elif strategy == \"got\":\n            return await self._graph_of_thought(intent)\n        else:\n            raise ValueError(f\"Unknown strategy: {strategy}\")\n\n    async def _chain_of_thought(self, intent: Dict[str, Any]) -> Dict[str, Any]:\n        # 简化版：使用单次LLM调用生成逐步推理\n        # 实际中应拆分为多步调用以提升可控性\n        prompt = f\"\"\"\n        You are an AGI reasoning module. Analyze the following task:\n        Goal: {intent['goal']}\n        Context: {json.dumps(intent.get('context', {}))}\n        Constraints: {intent.get('constraints', [])}\n        \n        Output ONLY in JSON format:\n        {{\n          \"steps\": [\"step1\", \"step2\", ...],\n          \"plan\": [{{\"tool\": \"name\", \"args\": {{}}}}],\n          \"confidence\": 0.0 to 1.0\n        }}\n        \"\"\"\n        # 此处应调用OpenAI API（见execution_layer.py）\n        # 为架构清晰，此处仅模拟\n        return {\n            \"plan\": [{\"tool\": \"search\", \"args\": {\"query\": intent[\"goal\"]}}],\n            \"confidence\": 0.85,\n            \"trace\": [\"Parsed goal\", \"Identified need for external info\", \"Selected search tool\"]\n        }\n\n    async def _tree_of_thought(self, intent: Dict[str, Any]) -> Dict[str, Any]:\n        # TODO: 实现ToT搜索（广度优先/深度优先）\n        raise NotImplementedError(\"Tree-of-Thought not yet implemented\")\n\n    async def _graph_of_thought(self, intent: Dict[str, Any]) -> Dict[str, Any]:\n        # TODO: 实现GoT（节点为子问题，边为依赖关系）\n        raise NotImplementedError(\"Graph-of-Thought not yet implemented\")\n\n    async def _refine_plan(\n        self, intent: Dict[str, Any], current_plan: List[Dict], reflection: Dict\n    ) -> Dict[str, Any]:\n        \"\"\"\n        基于反思结果修正计划\n        \"\"\"\n        new_prompt = f\"\"\"\n        Original plan: {current_plan}\n        Reflection: {reflection['reason']}\n        Goal: {intent['goal']}\n        \n        Revise the plan to address the reflection. Output JSON:\n        {{\"plan\": [...], \"confidence\": 0.0-1.0, \"trace\": [...]}}\n        \"\"\"\n        # 模拟调用\n        return {\n            \"plan\": [{\"tool\": \"analyze\", \"args\": {\"source\": \"memory\"}}],\n            \"confidence\": 0.92,\n            \"trace\": [\"Detected ambiguity in goal\", \"Added memory analysis step\"]\n        }\n\n    def _generate_memory_updates(\n        self, intent: Dict, plan: List, confidence: float, trace: List\n    ) -> List[Dict]:\n        \"\"\"\n        生成记忆更新项（用于长期存储）\n        \"\"\"\n        return [{\n            \"type\": \"reasoning_pattern\",\n            \"pattern\": {\n                \"goal_template\": intent.get(\"goal\", \"\").split()[0:3],\n                \"successful_tools\": [p[\"tool\"] for p in plan],\n                \"avg_confidence\": confidence,\n                \"trace_summary\": \" | \".join(trace[-2:])\n            },\n            \"timestamp\": \"now\"\n        }]\n"
        },
        {
            "filename": "agi/execution/openai_client.py",
            "content": "import os\nimport asyncio\nimport openai\nfrom typing import Dict, Any, Optional, List\nfrom pydantic import BaseModel\nfrom agi.utils.config import load_config\n\n# 初始化OpenAI客户端\nconfig = load_config()\nopenai.api_key = config.get(\"openai_api_key\")\nopenai.base_url = config.get(\"openai_base_url\", \"https://api.openai.com/v1\")\n\n\nclass ToolDefinition(BaseModel):\n    name: str\n    description: str\n    parameters: Dict[str, Any]  # JSON Schema\n\n\nclass OpenAIClient:\n    \"\"\"\n    封装OpenAI API调用，支持Function Calling与多模态\n    \"\"\"\n\n    def __init__(self, model: str = \"gpt-4-turbo\"):\n        self.model = model\n\n    async def chat_completion(\n        self,\n        messages: List[Dict[str, str]],\n        tools: Optional[List[ToolDefinition]] = None,\n        tool_choice: Optional[str] = None,\n        temperature: float = 0.7,\n        max_tokens: int = 1024\n    ) -> Dict[str, Any]:\n        \"\"\"\n        调用chat completion API\n        \n        Returns:\n            {\n                \"content\": str,\n                \"tool_calls\": List[Dict],\n                \"usage\": {...},\n                \"finish_reason\": str\n            }\n        \"\"\"\n        try:\n            response = await openai.AsyncChatCompletion.acreate(\n                model=self.model,\n                messages=messages,\n                tools=[t.dict() for t in tools] if tools else None,\n                tool_choice=tool_choice,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                timeout=30.0\n            )\n            choice = response.choices[0]\n\n            return {\n                \"content\": choice.message.content or \"\",\n                \"tool_calls\": [\n                    {\n                        \"id\": tc.function.name,\n                        \"function\": {\n                            \"name\": tc.function.name,\n                            \"arguments\": tc.function.arguments\n                        },\n                        \"type\": \"function\"\n                    }\n                    for tc in choice.message.tool_calls or []\n                ],\n                \"usage\": response.usage.dict(),\n                \"finish_reason\": choice.finish_reason\n            }\n\n        except openai.APIError as e:\n            raise RuntimeError(f\"OpenAI API error: {e}\") from e\n        except Exception as e:\n            raise RuntimeError(f\"Unexpected error: {e}\") from e\n\n    async def image_generation(self, prompt: str, size: str = \"102