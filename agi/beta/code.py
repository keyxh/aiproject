# agi

```json
{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "\"\"\"\nAGI Core Module\n\nThis module contains the core functionality for the AGI system.\nIt handles the integration with OpenAI API and manages the AGI's thought process.\n\"\"\"\n\nimport os\nimport time\nimport logging\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport openai\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass ThoughtProcess(Enum):\n    \"\"\"Enum representing different stages of AGI thought process\"\"\"\n    PERCEPTION = \"perception\"\n    ANALYSIS = \"analysis\"\n    PLANNING = \"planning\"\n    EXECUTION = \"execution\"\n    REFLECTION = \"reflection\"\n\n\n@dataclass\nclass AGIConfig:\n    \"\"\"Configuration for the AGI system\"\"\"\n    openai_api_key: str = field(default_factory=lambda: os.getenv(\"OPENAI_API_KEY\"))\n    model_name: str = \"gpt-4-turbo\"\n    max_tokens: int = 4096\n    temperature: float = 0.7\n    system_prompt: str = \"You are an artificial general intelligence system capable of reasoning, learning, and problem-solving.\"\n    max_thought_iterations: int = 5\n    memory_file: str = \"agi_memory.json\"\n    \n    def __post_init__(self):\n        if not self.openai_api_key:\n            raise ValueError(\"OpenAI API key must be provided either as parameter or OPENAI_API_KEY environment variable\")\n\n\nclass AGICore:\n    \"\"\"Core AGI system that orchestrates the thought process\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        \"\"\"Initialize the AGI system with configuration\"\"\"\n        self.config = config\n        self.client = openai.OpenAI(api_key=config.openai_api_key)\n        self.thought_history: List[Dict[str, Any]] = []\n        self.current_thought_process = ThoughtProcess.PERCEPTION\n        self.short_term_memory: Dict[str, Any] = {}\n        self.long_term_memory: Dict[str, Any] = self._load_long_term_memory()\n        \n    def _load_long_term_memory(self) -> Dict[str, Any]:\n        \"\"\"Load long term memory from file\"\"\"\n        try:\n            if os.path.exists(self.config.memory_file):\n                with open(self.config.memory_file, 'r') as f:\n                    import json\n                    return json.load(f)\n        except Exception as e:\n            logger.error(f\"Error loading long term memory: {e}\")\n        return {}\n    \n    def _save_long_term_memory(self):\n        \"\"\"Save long term memory to file\"\"\"\n        try:\n            with open(self.config.memory_file, 'w') as f:\n                import json\n                json.dump(self.long_term_memory, f)\n        except Exception as e:\n            logger.error(f\"Error saving long term memory: {e}\")\n    \n    def _update_memory(self, key: str, value: Any):\n        \"\"\"Update both short and long term memory\"\"\"\n        self.short_term_memory[key] = value\n        self.long_term_memory[key] = value\n        self._save_long_term_memory()\n    \n    def _make_api_call(self, prompt: str, system_prompt: Optional[str] = None) -> str:\n        \"\"\"Make API call to OpenAI\"\"\"\n        try:\n            response = self.client.chat.completions.create(\n                model=self.config.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_prompt or self.config.system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                max_tokens=self.config.max_tokens,\n                temperature=self.config.temperature\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            logger.error(f\"API call failed: {e}\")\n            return \"Error: API call failed\"\n    \n    def perceive(self, input_data: str) -> Dict[str, Any]:\n        \"\"\"Process input data and extract information\"\"\"\n        self.current_thought_process = ThoughtProcess.PERCEPTION\n        \n        prompt = f\"\\n\\nProcess the following input data and extract key information:\\n\\n{input_data}\\n\\nProvide your response in JSON format with keys: 'summary', 'key_points', 'entities', and 'sentiment'.\"\n        \n        response = self._make_api_call(prompt)\n        \n        try:\n            import json\n            result = json.loads(response)\n            self._update_memory(\"last_perception\", result)\n            self.thought_history.append({\n                \"process\": \"perception\",\n                \"input\": input_data,\n                \"output\": result,\n                \"timestamp\": time.time()\n            })\n            return result\n        except json.JSONDecodeError:\n            logger.error(\"Failed to parse perception response as JSON\")\n            return {\"summary\": response, \"key_points\": [], \"entities\": [], \"sentiment\": \"unknown\"}\n    \n    def analyze(self, perception_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Analyze the perceived data\"\"\"\n        self.current_thought_process = ThoughtProcess.ANALYSIS\n        \n        prompt = f\"\\n\\nAnalyze the following perception data:\\n\\n{perception_data}\\n\\nProvide your analysis in JSON format with keys: 'patterns', 'relationships', 'anomalies', and 'insights'.\"\n        \n        response = self._make_api_call(prompt)\n        \n        try:\n            import json\n            result = json.loads(response)\n            self._update_memory(\"last_analysis\", result)\n            self.thought_history.append({\n                \"process\": \"analysis\",\n                \"input\": perception_data,\n                \"output\": result,\n                \"timestamp\": time.time()\n            })\n            return result\n        except json.JSONDecodeError:\n            logger.error(\"Failed to parse analysis response as JSON\")\n            return {\"patterns\": [], \"relationships\": [], \"anomalies\": [], \"insights\": [response]}\n    \n    def plan(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a plan based on analysis\"\"\"\n        self.current_thought_process = ThoughtProcess.PLANNING\n        \n        prompt = f\"\\n\\nBased on the following analysis, create a comprehensive plan:\\n\\n{analysis_data}\\n\\nProvide your plan in JSON format with keys: 'objectives', 'strategies', 'steps', and 'resources_needed'.\"\n        \n        response = self._make_api_call(prompt)\n        \n        try:\n            import json\n            result = json.loads(response)\n            self._update_memory(\"last_plan\", result)\n            self.thought_history.append({\n                \"process\": \"planning\",\n                \"input\": analysis_data,\n                \"output\": result,\n                \"timestamp\": time.time()\n            })\n            return result\n        except json.JSONDecodeError:\n            logger.error(\"Failed to parse plan response as JSON\")\n            return {\"objectives\": [], \"strategies\": [], \"steps\": [response], \"resources_needed\": []}\n    \n    def execute(self, plan_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute the plan\"\"\"\n        self.current_thought_process = ThoughtProcess.EXECUTION\n        \n        prompt = f\"\\n\\nExecute the following plan:\\n\\n{plan_data}\\n\\nProvide your execution results in JSON format with keys: 'actions_taken', 'results', 'obstacles_encountered', and 'lessons_learned'.\"\n        \n        response = self._make_api_call(prompt)\n        \n        try:\n            import json\n            result = json.loads(response)\n            self._update_memory(\"last_execution\", result)\n            self.thought_history.append({\n                \"process\": \"execution\",\n                \"input\": plan_data,\n                \"output\": result,\n                \"timestamp\": time.time()\n            })\n            return result\n        except json.JSONDecodeError:\n            logger.error(\"Failed to parse execution response as JSON\")\n            return {\"actions_taken\": [], \"results\": [], \"obstacles_encountered\": [], \"lessons_learned\": [response]}\n    \n    def reflect(self, execution_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Reflect on the execution results\"\"\"\n        self.current_thought_process = ThoughtProcess.REFLECTION\n        \n        prompt = f\"\\n\\nReflect on the following execution results:\\n\\n{execution_data}\\n\\nProvide your reflection in JSON format with keys: 'success_factors', 'improvement_areas', 'learnings', and 'next_steps'.\"\n        \n        response = self._make_api_call(prompt)\n        \n        try:\n            import json\n            result = json.loads(response)\n            self._update_memory(\"last_reflection\", result)\n            self.thought_history.append({\n                \"process\": \"reflection\",\n                \"input\": execution_data,\n                \"output\": result,\n                \"timestamp\": time.time()\n            })\n            return result\n        except json.JSONDecodeError:\n            logger.error(\"Failed to parse reflection response as JSON\")\n            return {\"success_factors\": [], \"improvement_areas\": [], \"learnings\": [response], \"next_steps\": []}\n    \n    def run_thought_process(self, input_data: str, iterations: Optional[int] = None) -> Dict[str, Any]:\n        \"\"\"Run the complete thought process for the given input data\"\"\"\n        iterations = iterations or self.config.max_thought_iterations\n        \n        logger.info(f\"Starting thought process for input: {input_data[:50]}...\")\n        \n        # Initialize the process\n        perception = self.perceive(input_data)\n        \n        # Iterate through the thought process\n        for i in range(iterations):\n            logger.info(f\"Thought iteration {i+1}/{iterations}\")\n            \n            analysis = self.analyze(perception)\n            plan = self.plan(analysis)\n            execution = self.execute(plan)\n            reflection = self.reflect(execution)\n            \n            # Update perception with reflection for the next iteration\n            perception = reflection\n            \n            # Check if we should stop (based on reflection)\n            if \"converged\" in reflection.get(\"next_steps\", []):\n                logger.info(\"Thought process converged\")\n                break\n        \n        # Final reflection\n        final_reflection = self.reflect(reflection)\n        \n        result = {\n            \"input\": input_data,\n            \"perception\": perception,\n            \"analysis\": analysis,\n            \"plan\": plan,\n            \"execution\": execution,\n            \"reflection\": final_reflection,\n            \"iterations\": i + 1,\n            \"thought_history\": self.thought_history\n        }\n        \n        # Save to long term memory\n        self._update_memory(\"last_full_process\", result)\n        \n        logger.info(\"Thought process completed\")\n        return result\n    \n    def get_memory(self, key: str) -> Any:\n        \"\"\"Retrieve memory by key\"\"\"\n        return self.long_term_memory.get(key)\n    \n    def get_thought_history(self) -> List[Dict[str, Any]]:\n        \"\"\"Get the complete thought history\"\"\"\n        return self.thought_history\n    \n    def clear_memory(self, key: Optional[str] = None):\n        \"\"\"Clear memory\"\"\"\n        if key:\n            if key in self.short_term_memory:\n                del self.short_term_memory[key]\n            if key in self.long_term_memory:\n                del self.long_term_memory[key]\n        else:\n            self.short_term_memory = {}\n            self.long_term_memory = {}\n        self._save_long_term_memory()\n"
        },
        {
            "filename": "agi_interface.py",
            "content": "\"\"\"\nAGI Interface Module\n\nThis module provides the interface for interacting with the AGI system.\nIt includes both CLI and web interfaces.\n\"\"\"\n\nimport argparse\nimport json\nfrom typing import Dict, Any, Optional\nfrom agi_core import AGICore, AGIConfig, ThoughtProcess\n\n\nclass AGICLI:\n    \"\"\"Command Line Interface for the AGI system\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        \"\"\"Initialize the CLI with AGI configuration\"\"\"\n        self.agi = AGICore(config)\n    \n    def run(self, input_data: str, iterations: Optional[int] = None):\n        \"\"\"Run the AGI with the given input data\"\"\"\n        result = self.agi.run_thought_process(input_data, iterations)\n        print(\"\\n=== AGI THOUGHT PROCESS RESULTS ===\\n\")\n        print(json.dumps(result, indent=2))\n    \n    def interactive(self):\n        \"\"\"Run in interactive mode\"\"\"\n        print(\"\\n=== AGI INTERACTIVE MODE ===\\n\")\n        print(\"Type 'exit' to quit, 'memory' to view memory, 'history' to view thought history\\n\")\n        \n        while True:\n            user_input = input(\">> \")\n            \n            if user_input.lower() == 'exit':\n                break\n            elif user_input.lower() == 'memory':\n                self._show_memory()\n            elif user_input.lower() == 'history':\n                self._show_history()\n            elif user_input.lower() == 'clear':\n                self.agi.clear_memory()\n                print(\"Memory cleared.\")\n            else:\n                self.run(user_input)\n    \n    def _show_memory(self):\n        \"\"\"Display current memory\"\"\"\n        print(\"\\n=== CURRENT MEMORY ===\\n\")\n        memory = self.agi.long_term_memory\n        if memory:\n            print(json.dumps(memory, indent=2))\n        else:\n            print(\"No memory data available.\")\n    \n    def _show_history(self):\n        \"\"\"Display thought history\"\"\"\n        print(\"\\n=== THOUGHT HISTORY ===\\n\")\n        history = self.agi.get_thought_history()\n        if history:\n            for i, entry in enumerate(history, 1):\n                print(f\"{i}. {entry['process'].capitalize()} ({entry['timestamp']})\")\n        else:\n            print(\"No thought history available.\")\n\n\nclass AGIWebInterface:\n    \"\"\"Web Interface for the AGI system\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        \"\"\"Initialize the web interface with AGI configuration\"\"\"\n        self.agi = AGICore(config)\n        self.app = self._create_app()\n    \n    def _create_app(self):\n        \"\"\"Create the web application\"\"\"\n        from flask import Flask, request, jsonify, render_template_string\n        \n        app = Flask(__name__)\n        \n        @app.route('/')\n        def index():\n            return render_template_string(self._get_html_template())\n        \n        @app.route('/process', methods=['POST'])\n        def process():\n            data = request.json\n            input_text = data.get('input', '')\n            iterations = data.get('iterations', None)\n            \n            if not input_text:\n                return jsonify({'error': 'Input text is required'}), 400\n            \n            try:\n                result = self.agi.run_thought_process(input_text, iterations)\n                return jsonify({'success': True, 'result': result})\n            except Exception as e:\n                return jsonify({'success': False, 'error': str(e)}), 500\n        \n        @app.route('/memory', methods=['GET'])\n        def get_memory():\n            key = request.args.get('key')\n            if key:\n                return jsonify({'success': True, 'data': self.agi.get_memory(key)})\n            return jsonify({'success': True, 'data': self.agi.long_term_memory})\n        \n        @app.route('/memory', methods=['DELETE'])\n        def clear_memory():\n            key = request.args.get('key')\n            self.agi.clear_memory(key)\n            return jsonify({'success': True, 'message': 'Memory cleared' if not key else f'Memory for key {key} cleared'})\n        \n        @app.route('/history', methods=['GET'])\n        def get_history():\n            return jsonify({'success': True, 'data': self.agi.get_thought_history()})\n        \n        return app\n    \n    def _get_html_template(self):\n        \"\"\"Get the HTML template for the web interface\"\"\"\n        return \"\"\"\n        <!DOCTYPE html>\n        <html lang=\"en\">\n        <head>\n            <meta charset=\"UTF-8\">\n            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n            <title>AGI Interface</title>\n            <style>\n                body { font-family: Arial, sans-serif; line-height: 1.6; margin: 