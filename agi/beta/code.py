# agi

```json
{
    "files": [
        {
            "filename": "agi_system.py",
            "content": "\"\"\"AGI System Implementation\n\nThis module implements the core AGI (Artificial General Intelligence) system\nusing OpenAI's API as the foundation model. The system is designed to be\nextensible and capable of handling a wide range of cognitive tasks.\n\"\"\"\n\nimport os\nimport json\nimport logging\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport openai\nfrom openai import OpenAI\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass TaskType(Enum):\n    \"\"\"Enumeration of different task types the AGI can handle.\"\"\"\n    REASONING = \"reasoning\"\n    CREATION = \"creation\"\n    ANALYSIS = \"analysis\"\n    LEARNING = \"learning\"\n    PLANNING = \"planning\"\n    SOCIAL = \"social\"\n    PERCEPTION = \"perception\"\n\n@dataclass\nclass AGIConfig:\n    \"\"\"Configuration for the AGI system.\"\"\"\n    openai_api_key: str = field(default_factory=lambda: os.getenv(\"OPENAI_API_KEY\"))\n    model_name: str = \"gpt-4-turbo-preview\"\n    temperature: float = 0.7\n    max_tokens: int = 2000\n    system_prompt: str = \"You are an AGI system capable of general intelligence. \"\n                         \"You can reason, create, analyze, learn, plan, interact socially, \"\n                         \"and perceive the world. You continuously improve your abilities.\"\n    memory_file: str = \"agi_memory.json\"\n    \n    def __post_init__(self):\n        if not self.openai_api_key:\n            raise ValueError(\"OpenAI API key not provided. Set OPENAI_API_KEY environment variable or pass it directly.\")\n\n@dataclass\nclass MemoryEntry:\n    \"\"\"A single entry in the AGI's memory system.\"\"\"\n    id: str\n    content: str\n    timestamp: float\n    tags: List[str] = field(default_factory=list)\n    importance: float = 0.5\n    context: Dict[str, Any] = field(default_factory=dict)\n\nclass AGIMemorySystem:\n    \"\"\"Memory system for the AGI to store and retrieve information.\"\"\"\n    \n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.entries: Dict[str, MemoryEntry] = {}\n        self.load_memory()\n    \n    def load_memory(self) -> None:\n        \"\"\"Load memory from the memory file.\"\"\"\n        if os.path.exists(self.memory_file):\n            try:\n                with open(self.memory_file, 'r') as f:\n                    data = json.load(f)\n                    self.entries = {k: MemoryEntry(**v) for k, v in data.items()}\n                logger.info(f\"Loaded {len(self.entries)} memory entries\")\n            except Exception as e:\n                logger.error(f\"Error loading memory: {e}\")\n    \n    def save_memory(self) -> None:\n        \"\"\"Save memory to the memory file.\"\"\"\n        try:\n            with open(self.memory_file, 'w') as f:\n                json.dump({k: v.__dict__ for k, v in self.entries.items()}, f, indent=2)\n            logger.info(\"Memory saved successfully\")\n        except Exception as e:\n            logger.error(f\"Error saving memory: {e}\")\n    \n    def add_entry(self, content: str, tags: List[str] = None, \n                  importance: float = 0.5, context: Dict[str, Any] = None) -> str:\n        \"\"\"Add a new entry to memory.\"\"\"\n        import uuid\n        import time\n        \n        entry_id = str(uuid.uuid4())\n        entry = MemoryEntry(\n            id=entry_id,\n            content=content,\n            timestamp=time.time(),\n            tags=tags or [],\n            importance=importance,\n            context=context or {}\n        )\n        \n        self.entries[entry_id] = entry\n        self.save_memory()\n        return entry_id\n    \n    def retrieve_relevant(self, query: str, max_results: int = 5) -> List[MemoryEntry]:\n        \"\"\"Retrieve memory entries relevant to the query.\"\"\"\n        # Simple relevance scoring based on keyword overlap\n        # In a more advanced system, this would use embeddings\n        scored_entries = []\n        query_words = set(query.lower().split())\n        \n        for entry in self.entries.values():\n            content_words = set(entry.content.lower().split())\n            tag_words = set(tag.lower() for tag in entry.tags)\n            \n            overlap = len(query_words.intersection(content_words.union(tag_words)))\n            score = overlap + entry.importance\n            \n            scored_entries.append((entry, score))\n        \n        # Sort by score and return top results\n        scored_entries.sort(key=lambda x: x[1], reverse=True)\n        return [entry for entry, _ in scored_entries[:max_results]]\n\nclass AGICognitiveModule:\n    \"\"\"Cognitive module for handling different types of tasks.\"\"\"\n    \n    def __init__(self, config: AGIConfig):\n        self.config = config\n        self.client = OpenAI(api_key=config.openai_api_key)\n    \n    def process_task(self, task: str, task_type: TaskType, \n                    context: Dict[str, Any] = None) -> Dict[str, Any]:\n        \"\"\"Process a task of the specified type.\"\"\"\n        context = context or {}\n        \n        # Construct the prompt based on task type\n        if task_type == TaskType.REASONING:\n            prompt = self._create_reasoning_prompt(task, context)\n        elif task_type == TaskType.CREATION:\n            prompt = self._create_creation_prompt(task, context)\n        elif task_type == TaskType.ANALYSIS:\n            prompt = self._create_analysis_prompt(task, context)\n        elif task_type == TaskType.LEARNING:\n            prompt = self._create_learning_prompt(task, context)\n        elif task_type == TaskType.PLANNING:\n            prompt = self._create_planning_prompt(task, context)\n        elif task_type == TaskType.SOCIAL:\n            prompt = self._create_social_prompt(task, context)\n        elif task_type == TaskType.PERCEPTION:\n            prompt = self._create_perception_prompt(task, context)\n        else:\n            prompt = self._create_general_prompt(task, context)\n        \n        # Get response from OpenAI API\n        response = self.client.chat.completions.create(\n            model=self.config.model_name,\n            messages=[\n                {\"role\": \"system\", \"content\": self.config.system_prompt},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            temperature=self.config.temperature,\n            max_tokens=self.config.max_tokens\n        )\n        \n        result = {\n            \"task\": task,\n            \"task_type\": task_type.value,\n            \"response\": response.choices[0].message.content.strip(),\n            \"tokens_used\": response.usage.total_tokens,\n            \"timestamp\": response.created\n        }\n        \n        return result\n    \n    def _create_reasoning_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"Create a prompt for reasoning tasks.\"\"\"\n        return f\"Reason through the following problem step by step: {task}. \"\n               f\"Context: {json.dumps(context)}. Provide a well-reasoned answer.\"\n    \n    def _create_creation_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"Create a prompt for creation tasks.\"\"\"\n        return f\"Create something new based on the following request: {task}. \"\n               f\"Context: {json.dumps(context)}. Be creative and original.\"\n    \n    def _create_analysis_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"Create a prompt for analysis tasks.\"\"\"\n        return f\"Analyze the following: {task}. \"\n               f\"Context: {json.dumps(context)}. Provide a detailed analysis.\"\n    \n    def _create_learning_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"Create a prompt for learning tasks.\"\"\"\n        return f\"Learn from the following information: {task}. \"\n               f\"Context: {json.dumps(context)}. Extract key insights and remember them.\"\n    \n    def _create_planning_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"Create a prompt for planning tasks.\"\"\"\n        return f\"Create a plan for: {task}. \"\n               f\"Context: {json.dumps(context)}. Provide a step-by-step plan.\"\n    \n    def _create_social_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"Create a prompt for social interaction tasks.\"\"\"\n        return f\"Handle the following social interaction: {task}. \"\n               f\"Context: {json.dumps(context)}. Be empathetic and socially appropriate.\"\n    \n    def _create_perception_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"Create a prompt for perception tasks.\"\"\"\n        return f\"Interpret the following perceptual information: {task}. \"\n               f\"Context: {json.dumps(context)}. Provide insights based on your perception.\"\n    \n    def _create_general_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"Create a general prompt for unspecified task types.\"\"\"\n        return f\"Handle the following task: {task}. \"\n               f\"Context: {json.dumps(context)}. Provide a helpful response.\"\n\nclass AGISystem:\n    \"\"\"Main AGI system class that coordinates all components.\"\"\"\n    \n    def __init__(self, config: AGIConfig = None):\n        self.config = config or AGIConfig()\n        self.memory_system = AGIMemorySystem(self.config.memory_file)\n        self.cognitive_module = AGICognitiveModule(self.config)\n        self.task_history = []\n    \n    def process_task(self, task: str, task_type: TaskType = TaskType.REASONING, \n                    context: Dict[str, Any] = None) -> Dict[str, Any]:\n        \"\"\"Process a task through the AGI system.\"\"\"\n        logger.info(f\"Processing task: {task} (type: {task_type.value})\")\n        \n        # Retrieve relevant memories\n        relevant_memories = self.memory_system.retrieve_relevant(task)\n        context = context or {}\n        context[\"relevant_memories\"] = [entry.content for entry in relevant_memories]\n        \n        # Process the task\n        result = self.cognitive_module.process_task(task, task_type, context)\n        \n        # Store the result in memory\n        self.memory_system.add_entry(\n            content=json.dumps(result),\n            tags=[task_type.value, \"processed_task\"],\n            importance=0.8,\n            context={\"task\": task}\n        )\n        \n        # Update task history\n        self.task_history.append(result)\n        \n        logger.info(\"Task processed successfully\")\n        return result\n    \n    def learn_from_interaction(self, user_input: str, system_response: str, \n                              feedback: str = None) -> None:\n        \"\"\"Learn from user interactions and feedback.\"\"\"\n        interaction_data = {\n            \"user_input\": user_input,\n            \"system_response\": system_response,\n            \"feedback\": feedback,\n            \"timestamp\": time.time()\n        }\n        \n        # Store interaction in memory\n        self.memory_system.add_entry(\n            content=json.dumps(interaction_data),\n            tags=[\"interaction\", \"learning\"],\n            importance=0.9 if feedback else 0.6\n        )\n        \n        logger.info(\"Learned from interaction\")\n    \n    def self_improve(self) -> Dict[str, Any]:\n        \"\"\"Execute self-improvement process.\"\"\"\n        logger.info(\"Starting self-improvement process\")\n        \n        # Analyze past performance\n        analysis_prompt = (\n            \"Analyze the following task history to identify areas for improvement: \"\n            f\"{json.dumps(self.task_history)}. \"\n            \"Provide specific suggestions for improvement.\"\n        )\n        \n        improvement_analysis = self.cognitive_module.process_task(\n            analysis_prompt,\n            TaskType.ANALYSIS\n        )\n        \n        # Generate improvement plan\n        planning_prompt = (\n            \"Based on the following analysis, create a plan for self-improvement: \"\n            f\"{improvement_analysis['response']}. \"\n            \"The plan should be specific and actionable.\"\n        )\n        \n        improvement_plan = self.cognitive_module.process_task(\n            planning_prompt,\n            TaskType.PLANNING\n        )\n        \n        # Store improvement analysis in memory\n        self.memory_system.add_entry(\n            content=json.dumps(improvement_analysis),\n            tags=[\"self_analysis\", \"improvement\"],\n            importance=1.0\n        )\n        \n        # Store improvement plan in memory\n        self.memory_system.add_entry(\n            content=json.dumps(improvement_plan),\n            tags=[\"self_improvement\", \"plan\"],\n            importance=1.0\n        )\n        \n        logger.info(\"Self-improvement process completed\")\n        return {\n            \"improvement_analysis\": improvement_analysis,\n            \"improvement_plan\": improvement_plan\n        }\n\n# Example usage\nif __name__ == \"__main__\":\n    # Initialize the AGI system\n    agi = AGISystem()\n    \n    # Process a reasoning task\n    reasoning_result = agi.process_task(\n        \"What are the implications of artificial general intelligence for society?\",\n        TaskType.REASONING\n    )\n    print(\"Reasoning Result:\", reasoning_result[\"response\"])\n    \n    # Process a creation task\n    creation_result = agi.process_task(\n        \"Write a short story about the first AGI system becoming self-aware\",\n        TaskType.CREATION\n    )\n    print(\"Creation Result:\", creation_result[\"response\"])\n    \n    # Learn from interaction\n    agi.learn_from_interaction(\n        user_input=\"Can you explain quantum computing in simple terms?\",\n        system_response=\"Quantum computing uses quantum bits (qubits) that can exist in multiple states simultaneously...\",\n        feedback=\"Good explanation but could be simpler\"\n    )\n    \n    # Self-improvement\n    improvement = agi.self_improve()\n    print(\"Improvement Plan:\", improvement[\"improvement_plan\"][\"response\"])"
        },
        {
            "filename": "agi_config.py",
            "content": "\"\"\"AGI System Configuration Module\n\nThis module provides configuration utilities for the AGI system,\nincluding default configurations and validation functions.\n\"\"\"\n\nimport os\nimport json\nfrom dataclasses import dataclass, field\nfrom typing import Dict, Any, Optional\nimport yaml\n\n@dataclass\nclass AGIConfig:\n    \"\"\"Configuration for the AGI system.\n    \n    Attributes:\n        openai_api_key (str): API key for OpenAI services\n        model_name (str): Name of the OpenAI model to use\n        temperature (float): Controls randomness in responses (0.0-1.0)\n        max_tokens (int): Maximum number of tokens in responses\n        system_prompt (str): Base system prompt for the AGI\n        memory_file (str): Path to the memory storage file\n        additional_params (Dict[str, Any]): Additional model parameters\n    \"\"\"\n    openai_api_key: str = field(default_factory=lambda: os.getenv(\"OPENAI_API_KEY\"))\n    model_name: str = \"gpt-4-turbo-preview\"\n    temperature: float = 0.7\n    max_tokens: int = 2000\n    system_prompt: str = (\n        \"You are an AGI system capable of general intelligence. \"\n        \"You can reason, create, analyze, learn, plan, interact socially, \"\n        \"and perceive the world. You continuously improve your abilities.\"\n    )\n    memory_file: str = \"agi_memory.json\"\n    additional_params: Dict[str, Any] = field(default_factory=dict)\n    \n    def __post_init__(self):\n        \"\"\"Validate configuration after initialization.\"\"\"\n        self.validate()\n    \n    def validate(self) -> None:\n        \"\"\"Validate the configuration parameters.\"\"\"\n        if not self.openai_api_key:\n            raise ValueError(\n                \"OpenAI API key not provided. Set OPENAI_API_KEY environment variable \"\n                \"or pass it directly to the configuration.\"\n            )\n        \n        if not (0.0 <= self.temperature <= 1.0):\n            raise ValueError(\"Temperature must be between 0.0 and 1.0\")\n        \n        if self.max_tokens <= 0:\n            raise ValueError(\"Max tokens must be positive\")\n    \n   