# agi

{
    "files": [
        {
            "filename": "agi/__init__.py",
            "content": "# agi package initializer\n\n\"\"\"Top-level package for the AGI project.\n\nThis package provides a simple, extensible framework for building an\nArtificial General Intelligence (AGI) prototype using the OpenAI API.\nIt includes:\n- Configuration handling (`agi.config`)\n- Core agent implementation (`agi.agent`)\n- In‑memory vector memory (`agi.memory`)\n- Tool abstraction for external function calls (`agi.tools`)\n- Example entry point (`agi.main`)\n\nThe design is intentionally lightweight to keep the prototype\nreadable and runnable out‑of‑the‑box.\n\"\"\"\n\n__all__ = [\"config\", \"agent\", \"memory\", \"tools\", \"main\"]\n"
        },
        {
            "filename": "agi/config.py",
            "content": "import os\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n\n@dataclass(frozen=True)\nclass OpenAIConfig:\n    \"\"\"Configuration for OpenAI API access.\n\n    Attributes:\n        api_key: The secret key for OpenAI. It can be provided via the\n            ``OPENAI_API_KEY`` environment variable or directly when\n            constructing the config.\n        base_url: Optional custom base URL (useful for Azure OpenAI or\n            self‑hosted proxies).\n        model: The model name to use for completions (default: ``gpt-4o``).\n    \"\"\"\n    api_key: str\n    model: str = \"gpt-4o\"\n    base_url: Optional[str] = None\n\n    @staticmethod\n    def from_env() -> \"OpenAIConfig\":\n        \"\"\"Create a config instance from environment variables.\n\n        Required environment variables:\n            - ``OPENAI_API_KEY``\n        Optional environment variables:\n            - ``OPENAI_MODEL`` (defaults to ``gpt-4o``)\n            - ``OPENAI_BASE_URL``\n        \"\"\"\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        if not api_key:\n            raise EnvironmentError(\"OPENAI_API_KEY environment variable not set\")\n        model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n        base_url = os.getenv(\"OPENAI_BASE_URL\")\n        return OpenAIConfig(api_key=api_key, model=model, base_url=base_url)\n"
        },
        {
            "filename": "agi/memory.py",
            "content": "from __future__ import annotations\n\nimport numpy as np\nfrom typing import List, Tuple\n\n# Simple in‑memory vector store (FAISS could be swapped in later)\n\n\nclass InMemoryVectorStore:\n    \"\"\"A minimal vector store for storing and retrieving embeddings.\n\n    This class is deliberately simple: it keeps embeddings in a NumPy array\n    and performs a linear scan for similarity search. For a prototype this\n    is sufficient and keeps external dependencies low.\n    \"\"\"\n\n    def __init__(self, dimension: int):\n        self.dimension = dimension\n        self.vectors: List[np.ndarray] = []\n        self.metadata: List[dict] = []\n\n    def add(self, vector: np.ndarray, meta: dict) -> None:\n        \"\"\"Add a new embedding.\n\n        Args:\n            vector: A ``np.ndarray`` of shape ``(dimension,)``.\n            meta: Arbitrary metadata associated with the vector (e.g., text).\n        \"\"\"\n        if vector.shape != (self.dimension,):\n            raise ValueError(f\"Vector must be of shape ({self.dimension},)\")\n        self.vectors.append(vector)\n        self.metadata.append(meta)\n\n    def similarity_search(self, query: np.ndarray, top_k: int = 5) -> List[Tuple[dict, float]]:\n        \"\"\"Return the *top_k* most similar items to ``query``.\n\n        Uses cosine similarity.\n        \"\"\"\n        if not self.vectors:\n            return []\n        # Normalise vectors for cosine similarity\n        norm_query = query / np.linalg.norm(query)\n        norm_vectors = np.stack(self.vectors) / np.linalg.norm(np.stack(self.vectors), axis=1, keepdims=True)\n        scores = norm_vectors @ norm_query\n        # Get indices of top scores\n        top_indices = np.argsort(scores)[-top_k:][::-1]\n        return [(self.metadata[i], float(scores[i])) for i in top_indices]\n"
        },
        {
            "filename": "agi/tools.py",
            "content": "from __future__ import annotations\n\nfrom typing import Callable, Any, Dict\nimport json\n\n\nclass Tool:\n    \"\"\"Base class for all tools that the AGI can invoke.\n\n    A *tool* is a callable that performs an external action (e.g., web search,\n    database query, arithmetic). The AGI decides when to call a tool based on\n    the LLM's response.\n    \"\"\"\n\n    def __init__(self, name: str, description: str, func: Callable[[Dict[str, Any]], Any]):\n        self.name = name\n        self.description = description\n        self.func = func\n\n    def run(self, arguments: Dict[str, Any]) -> Any:\n        \"\"\"Execute the tool with the provided arguments.\n\n        Args:\n            arguments: A dictionary of arguments parsed from the LLM response.\n        \"\"\"\n        return self.func(arguments)\n\n    def to_openai_schema(self) -> Dict[str, Any]:\n        \"\"\"Return the JSON schema required by OpenAI's function calling API.\"\"\"\n        # In a real implementation we would introspect the function signature.\n        # For brevity we expect the tool author to provide a JSON schema via a\n        # ``json_schema`` attribute if needed.\n        schema = getattr(self.func, \"json_schema\", {})\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"parameters\": schema or {\"type\": \"object\", \"properties\": {}, \"required\": []},\n        }\n\n\n# Example tool implementations -------------------------------------------------\n\ndef arithmetic_tool(args: Dict[str, Any]) -> str:\n    \"\"\"Simple arithmetic evaluator.\n\n    Expected args: {\"expression\": \"2 + 3 * (7 - 4)\"}\n    \"\"\"\n    expr = args.get(\"expression\")\n    if not expr:\n        return \"Error: 'expression' argument missing\"\n    try:\n        # WARNING: ``eval`` is dangerous; here we restrict the globals/locals.\n        result = eval(expr, {\"__builtins__\": {}}, {})\n        return json.dumps({\"expression\": expr, \"result\": result})\n    except Exception as e:\n        return json.dumps({\"error\": str(e)})\n\n# Attach a minimal JSON schema for OpenAI function calling\narithmetic_tool.json_schema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"expression\": {\"type\": \"string\", \"description\": \"A valid Python arithmetic expression\"}\n    },\n    \"required\": [\"expression\"]\n}\n\n# Register the tool in a dictionary for easy lookup\nDEFAULT_TOOLS = {\n    \"arithmetic\": Tool(name=\"arithmetic\", description=\"Execute basic arithmetic expressions\", func=arithmetic_tool)\n}\n"
        },
        {
            "filename": "agi/agent.py",
            "content": "from __future__ import annotations\n\nimport json\nimport logging\nfrom typing import List, Dict, Any, Optional\n\nimport openai\nimport numpy as np\n\nfrom .config import OpenAIConfig\nfrom .memory import InMemoryVectorStore\nfrom .tools import Tool, DEFAULT_TOOLS\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO, format=\"[%(asctime)s] %(levelname)s %(name)s: %(message)s\")\n\n\nclass AGI:\n    \"\"\"Core AGI orchestrator