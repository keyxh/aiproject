# agi

 ```json
{
  "files": [
    {
      "filename": "main.py",
      "content": "#!/usr/bin/env python3\n\"\"\"\nAGI Project - ä¸»å…¥å£æ–‡ä»¶\nåˆçº§å·¥ç¨‹å¸ˆå®ç°çš„ç®€å•AGIåŸå‹\n\"\"\"\n\nimport asyncio\nimport sys\nfrom agent import AGIAgent\nfrom config import Config\n\nasync def main():\n    \"\"\"ä¸»å‡½æ•° - å¯åŠ¨AGIç³»ç»Ÿ\"\"\"\n    print(\"ğŸš€ æ­£åœ¨å¯åŠ¨ AGI ç³»ç»Ÿ...\")\n    print(\"âš ï¸  è­¦å‘Šï¼šè¿™æ˜¯åˆçº§ç‰ˆæœ¬ï¼Œä»…ç”¨äºå­¦ä¹ å’Œæµ‹è¯•\")\n    \n    try:\n        # åˆå§‹åŒ–é…ç½®\n        config = Config()\n        \n        # åˆ›å»ºAGIä»£ç†å®ä¾‹\n        agent = AGIAgent(config)\n        \n        print(\"âœ… AGI ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ\")\n        print(\"è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºç¨‹åº\\n\")\n        \n        # ä¸»å¾ªç¯\n        while True:\n            try:\n                # è·å–ç”¨æˆ·è¾“å…¥\n                user_input = input(\"ğŸ‘¤ ç”¨æˆ·: \").strip()\n                \n                if user_input.lower() in ['exit', 'quit', 'q']:\n                    print(\"ğŸ‘‹ æ­£åœ¨å…³é—­ AGI ç³»ç»Ÿ...\")\n                    break\n                \n                if not user_input:\n                    continue\n                \n                # å¤„ç†è¾“å…¥å¹¶è·å–å“åº”\n                response = await agent.process(user_input)\n                print(f\"ğŸ¤– AGI: {response}\\n\")\n                \n            except KeyboardInterrupt:\n                print(\"\\nğŸ‘‹ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...\")\n                break\n            except Exception as e:\n                print(f\"âŒ é”™è¯¯: {str(e)}\")\n                continue\n                \n    except Exception as e:\n        print(f\"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {str(e)}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°\n    asyncio.run(main())"
    },
    {
      "filename": "agent.py",
      "content": "\"\"\"\nAGI Agent æ ¸å¿ƒå®ç°\nåŒ…å«æ¨ç†ã€è®°å¿†ã€å·¥å…·è°ƒç”¨ç­‰åŸºç¡€åŠŸèƒ½\n\"\"\"\n\nimport json\nimport openai\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime\nfrom memory import MemorySystem\nfrom tools import ToolManager\n\nclass AGIAgent:\n    \"\"\"\n    åˆçº§AGIä»£ç†ç±»\n    å®ç°äº†åŸºäºReActæ¨¡å¼çš„åŸºç¡€æ¨ç†å¾ªç¯\n    \"\"\"\n    \n    def __init__(self, config):\n        self.config = config\n        self.client = openai.OpenAI(api_key=config.openai_api_key)\n        self.memory = MemorySystem()\n        self.tools = ToolManager()\n        self.conversation_history = []\n        self.max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯\n        \n        # ç³»ç»Ÿæç¤ºè¯ - å®šä¹‰AGIè¡Œä¸º\n        self.system_prompt = \"\"\"ä½ æ˜¯ä¸€ä¸ªAGIï¼ˆé€šç”¨äººå·¥æ™ºèƒ½ï¼‰åŠ©æ‰‹ã€‚ä½ çš„ç›®æ ‡æ˜¯ç†è§£ç”¨æˆ·çš„è¯·æ±‚ï¼Œå¹¶é€šè¿‡æ€è€ƒã€ä½¿ç”¨å·¥å…·å’Œè®°å¿†æ¥æä¾›æœ€ä½³å›ç­”ã€‚\n\nä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š\n- search: æœç´¢äº’è”ç½‘ä¿¡æ¯\n- calculator: è¿›è¡Œæ•°å­¦è®¡ç®—\n- memory_store: å­˜å‚¨é‡è¦ä¿¡æ¯åˆ°é•¿æœŸè®°å¿†\n- memory_recall: ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ä¿¡æ¯\n- code_execute: æ‰§è¡ŒPythonä»£ç ï¼ˆæ²™ç®±ç¯å¢ƒï¼‰\n\nè¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š\n1. æ€è€ƒï¼ˆThoughtï¼‰: åˆ†æç”¨æˆ·è¯·æ±‚å’Œå½“å‰çŠ¶æ€\n2. è¡ŒåŠ¨ï¼ˆActionï¼‰: å¦‚æœéœ€è¦ï¼Œä½¿ç”¨å·¥å…·\n3. è§‚å¯Ÿï¼ˆObservationï¼‰: è§‚å¯Ÿå·¥å…·è¿”å›çš„ç»“æœ\n4. æœ€ç»ˆå›ç­”ï¼ˆFinal Answerï¼‰: ç»™ç”¨æˆ·æä¾›ç­”æ¡ˆ\n\nå§‹ç»ˆä¿æŒè‡ªæˆ‘åæ€ï¼Œæ£€æŸ¥ä½ çš„æ¨ç†è¿‡ç¨‹æ˜¯å¦æ­£ç¡®ã€‚\"\"\"\n\n    async def process(self, user_input: str) -> str:\n        \"\"\"\n        å¤„ç†ç”¨æˆ·è¾“å…¥çš„ä¸»å‡½æ•°\n        \n        Args:\n            user_input: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬\n            \n        Returns:\n            str: ç”Ÿæˆçš„å›å¤\n        \"\"\"\n        # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å†å²è®°å½•\n        self.conversation_history.append({\n            \"role\": \"user\",\n            \"content\": user_input,\n            \"timestamp\": datetime.now().isoformat()\n        })\n        \n        # æ£€ç´¢ç›¸å…³è®°å¿†\n        relevant_memories = self.memory.recall(user_input, k=3)\n        memory_context = self._format_memories(relevant_memories)\n        \n        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨\n        messages = [\n            {\"role\": \"system\", \"content\": self.system_prompt},\n            {\"role\": \"system\", \"content\": f\"ç›¸å…³è®°å¿†:\\n{memory_context}\"},\n        ]\n        \n        # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆé™åˆ¶é•¿åº¦é¿å…tokenè¶…é™ï¼‰\n        messages.extend(self.conversation_history[-5:])\n        \n        # ReActå¾ªç¯\n        iteration = 0\n        final_response = None\n        \n        while iteration < self.max_iterations:\n            iteration += 1\n            \n            try:\n                # è°ƒç”¨OpenAI API\n                response = self.client.chat.completions.create(\n                    model=self.config.model_name,\n                    messages=messages,\n                    temperature=0.7,\n                    max_tokens=1000\n                )\n                \n                assistant_message = response.choices[0].message.content\n                \n                # è§£æå“åº”ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«è¡ŒåŠ¨æŒ‡ä»¤\n                if \"Action:\" in assistant_message:\n                    # æå–æ€è€ƒéƒ¨åˆ†\n                    thought = self._extract_thought(assistant_message)\n                    action = self._extract_action(assistant_message)\n                    \n                    print(f\"  [æ€è€ƒ] {thought}\")\n                    print(f\"  [è¡ŒåŠ¨] ä½¿ç”¨å·¥å…·: {action['name']}\")\n                    \n                    # æ‰§è¡Œå·¥å…·\n                    observation = await self.tools.execute(\n                        action['name'], \n                        action.get('params', {})\n                    )\n                    \n                    print(f\"  [è§‚å¯Ÿ] {observation}\")\n                    \n                    # å°†è§‚å¯Ÿå’Œç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­\n                    messages.append({\n                        \"role\": \"assistant\",\n                        \"content\": assistant_message\n                    })\n                    messages.append({\n                        \"role\": \"system\",\n                        \"content\": f\"Observation: {observation}\"\n                    })\n                    \n                elif \"Final Answer:\" in assistant_message:\n                    # æå–æœ€ç»ˆç­”æ¡ˆ\n                    final_response = assistant_message.split(\"Final Answer:\")[-1].strip()\n                    break\n                else:\n                    # æ²¡æœ‰æ˜ç¡®æ ‡è®°ï¼Œç›´æ¥ä½œä¸ºå›ç­”\n                    final_response = assistant_message\n                    break\n                    \n            except Exception as e:\n                return f\"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\"\n        \n        if final_response is None:\n            final_response = \"æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åœ¨æœ‰é™çš„æ­¥éª¤å†…å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚\"\n        \n        # ä¿å­˜åˆ°è®°å¿†ç³»ç»Ÿ\n        self.memory.store(\n            content=f\"ç”¨æˆ·é—®: {user_input}\\nå›ç­”: {final_response}\",\n            metadata={\"type\": \"conversation\", \"timestamp\": datetime.now().isoformat()}\n        )\n        \n        # æ·»åŠ åˆ°å†å²è®°å½•\n        self.conversation_history.append({\n            \"role\": \"assistant\",\n            \"content\": final_response,\n            \"timestamp\": datetime.now().isoformat()\n        })\n        \n        return final_response\n    \n    def _format_memories(self, memories: List[Dict]) -> str:\n        \"\"\"æ ¼å¼åŒ–è®°å¿†ä»¥ä¾›æç¤ºä½¿ç”¨\"\"