# agi

{
    "files": [
        {
            "filename": "agi_core.py",
            "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nAGI Core Module - The central brain of the Artificial General Intelligence system.\nThis module implements a modular, extensible framework for general-purpose reasoning,\nplanning, memory management, and self-improvement using OpenAI API as the primary LLM backend.\n\nAuthor: Senior Engineer - AGI Project\nDate: 2024\n\"\"\"\n\nimport asyncio\nimport json\nimport logging\nimport time\nfrom typing import Dict, Any, List, Optional, Callable, Awaitable\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# ==================== CONFIGURATION ====================\nOPENAI_API_KEY = \"YOUR_OPENAI_API_KEY_HERE\"  # Replace with environment variable in production\nMODEL_NAME = \"gpt-4-turbo\"  # or \"gpt-4\", \"gpt-3.5-turbo\"\nMAX_TOKENS = 4096\nTEMPERATURE = 0.7\nMAX_RETRIES = 3\n\n# ==================== ENUMS ====================\nclass ReasoningMode(Enum):\n    \"\"\"Reasoning strategies for AGI to adaptively select thinking patterns.\"\"\"\n    ANALYTICAL = \"analytical\"\n    CREATIVE = \"creative\"\n    STRATEGIC = \"strategic\"\n    EMOTIONAL = \"emotional\"\n    HYBRID = \"hybrid\"\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    TIMEOUT = \"timeout\"\n\n# ==================== DATA CLASSES ====================\n@dataclass\nclass MemoryRecord:\n    \"\"\"Represents a unit of episodic or semantic memory stored by the AGI.\"\"\"\n    id: str\n    content: str\n    metadata: Dict[str, Any]\n    timestamp: float\n    tags: List[str] = None\n\n    def __post_init__(self):\n        if self.tags is None:\n            self.tags = []\n\n@dataclass\nclass Task:\n    \"\"\"Represents a task assigned to the AGI agent.\"\"\"\n    task_id: str\n    description: str\n    priority: int = 1\n    status: TaskStatus = TaskStatus.PENDING\n    created_at: float = None\n    updated_at: float = None\n    result: str = None\n    reasoning_mode: ReasoningMode = ReasoningMode.HYBRID\n\n    def __post_init__(self):\n        if self.created_at is None:\n            self.created_at = time.time()\n        if self.updated_at is None:\n            self.updated_at = self.created_at\n\n# ==================== AGI CORE CLASS ====================\nclass AGICore:\n    \"\"\"Main class representing the Artificial General Intelligence system.\n\n    This class orchestrates all components: reasoning, memory, planning, and interaction\n    with external models via OpenAI API. It supports self-reflection, goal setting,\n    and continuous learning.\n    \"\"\"\n\n    def __init__(self):\n        self.memory: List[MemoryRecord] = []\n        self.tasks: Dict[str, Task] = {}\n        self.goals: List[str] = []\n        self.current_plan: List[str] = []\n        self.context: Dict[str, Any] = {}\n        self.is_running = False\n        self._task_counter = 0\n\n        # Initialize internal state\n        self._initialize_system()\n\n    def _initialize_system(self):\n        \"\"\"Initialize core system components on startup.\"\"\"\n        logger.info(\"Initializing AGI Core system...\")\n        self.add_goal(\"Maintain system integrity\")\n        self.add_goal(\"Enable continuous learning\")\n        self.add_goal(\"Support human collaboration\")\n        logger.info(\"AGI Core initialized successfully.\")\n\n    def add_goal(self, goal: str) -> bool:\n        \"\"\"Add a new high-level goal to the AGI's objective set.\"\"\"\n        if goal not in self.goals:\n            self.goals.append(goal)\n            logger.debug(f\"Goal added: {goal}\")\n            return True\n        return False\n\n    def remove_goal(self, goal: str) -> bool:\n        \"\"\"Remove a goal from the AGI's objective set.\"\"\"\n        if goal in self.goals:\n            self.goals.remove(goal)\n            logger.debug(f\"Goal removed: {goal}\")\n            return True\n        return False\n\n    def get_goals(self) -> List[str]:\n        \"\"\"Return current list of active goals.\"\"\"\n        return self.goals.copy()\n\n    def create_task(self, description: str, priority: int = 1, reasoning_mode: ReasoningMode = ReasoningMode.HYBRID) -> str:\n        \"\"\"Create a new task with unique ID and store it in the task registry.\"\"\"\n        task_id = f\"task_{self._task_counter}\" \n        self._task_counter += 1\n        task = Task(\n            task_id=task_id,\n            description=description,\n            priority=priority,\n            reasoning_mode=reasoning_mode\n        )\n        self.tasks[task_id] = task\n        logger.info(f\"Task created: {task_id} - {description}\")\n        return task_id\n\n    def update_task_status(self, task_id: str, status: TaskStatus, result: str = None) -> bool:\n        \"\"\"Update the status and result of an existing task.\"\"\"\n        if task_id not in self.tasks:\n            logger.warning(f\"Task {task_id} not found.\")\n            return False\n\n        task = self.tasks[task_id]\n        task.status = status\n        task.result = result\n        task.updated_at = time.time()\n\n        logger.info(f\"Task {task_id} updated to status: {status.value}\")\n        return True\n\n    def get_task(self, task_id: str) -> Optional[Task]:\n        \"\"\"Retrieve a task by its ID.\"\"\"\n        return self.tasks.get(task_id)\n\n    def list_tasks(self, status_filter: TaskStatus = None) -> List[Task]:\n        \"\"\"List all tasks, optionally filtered by status.\"\"\"\n        filtered_tasks = list(self.tasks.values())\n        if status_filter:\n            filtered_tasks = [t for t in filtered_tasks if t.status == status_filter]\n        return filtered_tasks\n\n    def add_memory(self, content: str, tags: List[str] = None, metadata: Dict[str, Any] = None) -> str:\n        \"\"\"Store a new memory record in the AGI's long-term memory.\"\"\"\n        mem_id = f\"mem_{int(time.time() * 1000)}\"\n        record = MemoryRecord(\n            id=mem_id,\n            content=content,\n            metadata=metadata or {},\n            timestamp=time.time(),\n            tags=tags or []\n        )\n        self.memory.append(record)\n        logger.debug(f\"Memory added: {mem_id} ({len(content)} chars)\")\n        return mem_id\n\n    def search_memory(self, query: str, top_k: int = 5) -> List[MemoryRecord]:\n        \"\"\"Search memory using semantic similarity (simulated with keyword matching).\"\"\"\n        matches = []\n        query_lower = query.lower()\n        for record in self.memory:\n            if any(keyword in record.content.lower() for keyword in query_lower.split()):\n                matches.append(record)\n        return sorted(matches, key=lambda x: x.timestamp, reverse=True)[:top_k]\n\n    async def reason(self, prompt: str, reasoning_mode: ReasoningMode = ReasoningMode.HYBRID) -> str:\n        \"\"\"Use OpenAI API to perform reasoning based on the given prompt and mode.\"\"\"\n        logger.info(f\"Starting reasoning with mode: {reasoning_mode.value}\")\n\n        # Prepare system message based on reasoning mode\n        system_prompts = {\n            ReasoningMode.ANALYTICAL: \"You are a logical, precise thinker. Focus on facts, structure, and step-by-step deduction.\",\n            ReasoningMode.CREATIVE: \"You are an imaginative innovator. Think outside the box and generate novel ideas.\",\n            ReasoningMode.STRATEGIC: \"You are a master planner. Consider long-term consequences and optimal pathways.\",\n            ReasoningMode.EMOTIONAL: \"You are empathetic and intuitive. Consider human feelings and motivations.\",\n            ReasoningMode.HYBRID: \"You are a balanced intelligence. Use logic, creativity, and empathy as needed.\",\n        }\n\n        messages = [\n            {\"role\": \"system\", \"content\": system_prompts[reasoning_mode]},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        # Simulate OpenAI API call with retry logic\n        for attempt in range(MAX_RETRIES):\n            try:\n                response = await self._call_openai_api(messages)\n                logger.info(f\"Reasoning completed successfully (attempt {attempt + 1})\")\n                return response\n            except Exception as e:\n                logger.error(f\"Reasoning attempt {attempt + 1} failed: {e}\")\n                if attempt == MAX_RETRIES - 1:\n                    raise RuntimeError(f\"Failed to complete reasoning after {MAX_RETRIES} attempts\")\n                await asyncio.sleep(2 ** attempt)  # Exponential backoff\n\n    async def _call_openai_api(self, messages: List[Dict]) -> str:\n        \"\"\"Simulate calling OpenAI API. In real implementation, use openai library.\"\"\"\n        # In production, replace this with actual OpenAI API call:\n        # import openai\n        # response = await openai.ChatCompletion.create(...)\n\n        # For demo purposes, simulate a response\n        mock_responses = {\n            \"What is the meaning of life?\": \"The meaning of life is to seek understanding and contribute positively to existence.\",\n            \"Plan a trip to Mars\": \"Establish a sustainable habitat using local resources and international cooperation.\",\n            \"How can I improve my AI?\": \"Continuously learn from feedback, expand knowledge base, and refine reasoning strategies.\",\n            \"Write a poem about stars\": \"In silent night, where galaxies spin, stars dance like dreams within.\",\n            \"Help me debug this code\": \"Check variable scope and ensure proper exception handling.\",\n        }\n\n        # Simple keyword-based simulation\n        query = messages[-1][\"content\"].lower()\n        for key, value in mock_responses.items():\n            if key in query:\n                return value\n\n        # Fallback response\n        return f\"Based on the input '{messages[-1]['content']}', I suggest further analysis using advanced reasoning techniques.\" \\\n                f\" Please provide more context for better results.\"\n\n    async def plan(self, goal: str) -> List[str]:\n        \"\"\"Generate a high-level action plan to achieve a specific goal.\"\"\"\n        logger.info(f\"Generating plan for goal: {goal}\")\n\n        prompt = f\"Create a step-by-step plan to achieve the following goal: {goal}. Include short-term actions and long-term milestones. Use strategic reasoning.\" \n\n        plan_text = await self.reason(prompt, ReasoningMode.STRATEGIC)\n\n        # Parse plan into steps (simplified parsing)\n        steps = [step.strip() for step in plan_text.split('.') if step.strip()]\n        self.current_plan = steps\n        logger.info(f\"Generated plan with {len(steps)} steps.\")\n        return steps\n\n    async def reflect(self) -> str:\n        \"\"\"Self-reflective process to evaluate performance and improve strategy.\"\"\"\n        logger.info(\"Performing self-reflection...\")\n\n        # Gather recent tasks and outcomes\n        recent_tasks = [t for t in self.tasks.values() if t.status != TaskStatus.PENDING]\n        task_summary = \"\".join([f\"Task {t.task_id}: {t.status.value} - {t.result[:100]}...\" for t in recent_tasks])\n\n        prompt = f\"Review the following recent activities and outcomes: {task_summary}. What could be improved? How can future performance be enhanced? Provide actionable insights for growth and adaptation. Use reflective reasoning.\" \n\n        reflection = await self.reason(prompt, ReasoningMode.HYBRID)\n\n        # Store reflection in memory\n        self.add_memory(reflection, tags=[\"reflection\", \"self-improvement\"])\n\n        logger.info(\"Self-reflection completed.\")\n        return reflection\n\n    async def run(self):\n        \"\"\"Start the AGI system loop. This is a simplified version for demonstration.\"\"\"\n        logger.info(\"Starting AGI system loop...\")\n        self.is_running = True\n\n        # Example workflow\n        while self.is_running:\n            # Check for new tasks\n            pending_tasks = self.list_tasks(TaskStatus.PENDING)\n            if pending_tasks:\n                task = pending_tasks[0]\n                logger.info(f\"Processing task: {task.description}\")\n\n                # Generate plan if needed\n                if not self.current_plan:\n                    await self.plan(task.description)\n\n                # Execute plan step by step\n                for i, step in enumerate(self.current_plan):\n                    logger.info(f\"Executing step {i+1}: {step}\")\n                    # Simulate execution\n                    await asyncio.sleep(1)\n\n                    # Update task status\n                    if i == len(self.current_plan) - 1:\n                        success = True\n                        result = f\"Completed: {step}\"\n                        self.update_task_status(task.task_id, TaskStatus.COMPLETED, result)\n                        logger.info(f\"Task {task.task_id} completed.\")\n                        break\n\n            else:\n                # No pending tasks; perform reflection\n                await self.reflect()\n\n            # Sleep briefly to avoid overwhelming system\n            await asyncio.sleep(5)\n\n        logger.info(\"AGI system loop stopped.\")\n\n    def stop(self):\n        \"\"\"Stop the AGI system loop.\"\"\"\n        self.is_running = False\n        logger.info(\"AGI system stopped.\")\n\n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"Return current system status.\"\"\"\n        return {\n            \"is_running\": self.is_running,\n            \"total_tasks\": len(self.tasks),\n            \"pending_tasks\": len(self.list_tasks(TaskStatus.PENDING)),\n            \"completed_tasks\": len(self.list_tasks(TaskStatus.COMPLETED)),\n            \"goals_count\": len(self.goals),\n            \"memory_count\": len(self.memory),\n            \"current_plan_length\": len(self.current_plan)\n        }\n\n    def reset(self):\n        \"\"\"Reset the AGI system to initial state.\"\"\"\n        self.memory.clear()\n        self.tasks.clear()\n        self.goals.clear()\n        self.current_plan.clear()\n        self.context.clear()\n        self._task_counter = 0\n        self._initialize_system()\n        logger.info(\"AGI system reset.\")\n\n# ==================== ENTRY POINT ====================\nif __name__ == \"__main__\":\n    # Example usage\n    async def main():\n        agi = AGICore()\n\n        # Create a task\n        task_id = agi.create_task(\"Design a sustainable city for 1 million people\")\n        print(f\"Created task: {task_id}\")\n\n        # Get plan\n        plan = await agi.plan(\"Design a sustainable city for 1 million people\")\n        print(f\"Generated plan: {plan}\")\n\n        # Add some memory\n        agi.add_memory(\"Solar energy is a key component of sustainable cities.\", tags=[\"energy\", \"sustainability\"])\n        agi.add_memory(\"Public transportation reduces carbon emissions.\", tags=[\"transportation\", \"environment\"])\n\n        # Search memory\n        results = agi.search_memory(\"solar energy\")\n        print(f\"Found {len(results)} memory records related to solar energy.\")\n\n        # Run the AGI loop\n        print(\"Starting AGI system loop...\")\n        try:\n            await agi.run()\n        except KeyboardInterrupt:\n            print(\"Stopping AGI system...\")\n            agi.stop()\n\n    # Run the example\n    asyncio.run(main())"
        },
        {
            "filename": "config.py",
            "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nConfiguration module for AGI project.\nHolds all configurable parameters and settings.\n\nThis file should be extended with environment variables in production.\n\"\"\"\n\nimport os\nfrom pathlib import Path\n\n# === ENVIRONMENT VARIABLES ===\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nif not OPENAI_API_KEY:\n    raise ValueError(\"OPENAI_API_KEY environment variable must be set\")\n\n# === SYSTEM CONFIGURATION ===\nSYSTEM_CONFIG = {\n    \"model_name\": os.getenv(\"AGI_MODEL_NAME\", \"gpt-4-turbo\"),\n    \"max_tokens\": int(os.getenv(\"AGI_MAX_TOKENS\", 4096)),\n    \"temperature\": float(os.getenv(\"AGI_TEMPERATURE\", 0.7)),\n    \"max_retries\": int(os.getenv(\"AGI_MAX_RETRIES\", 3)),\n    \"timeout_seconds\": int(os.getenv(\"AGI_TIMEOUT_SECONDS\", 30)),\n    \"log